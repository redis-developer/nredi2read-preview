[{"pageCount":73,"thumbnail":"http:\/\/books.google.com\/books\/content?id=uaSSAwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":25,"subtitle":null,"description":"Many applications process high volumes of streaming data, among them Internet traffic analysis, financial tickers, and transaction log mining. In general, a data stream is an unbounded data set that is produced incrementally over time, rather than being available in full before its processing begins. In this lecture, we give an overview of recent research in stream processing, ranging from answering simple queries on high-speed streams to loading real-time data feeds into a streaming warehouse for off-line analysis. We will discuss two types of systems for end-to-end stream processing: Data Stream Management Systems (DSMSs) and Streaming Data Warehouses (SDWs). A traditional database management system typically processes a stream of ad-hoc queries over relatively static data. In contrast, a DSMS evaluates static (long-running) queries on streaming data, making a single pass over the data and using limited working memory. In the first part of this lecture, we will discuss research problems in DSMSs, such as continuous query languages, non-blocking query operators that continually react to new data, and continuous query optimization. The second part covers SDWs, which combine the real-time response of a DSMS by loading new data as soon as they arrive with a data warehouse's ability to manage Terabytes of historical data on secondary storage. Table of Contents: Introduction \/ Data Stream Management Systems \/ Streaming Data Warehouses \/ Conclusions","language":"en","currency":"USD","id":"1608452735","title":"Data Stream Management","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=uaSSAwAAQBAJ&source=gbs_api","authors":["Lukasz Golab","M. Tamer Ozsu"]},{"pageCount":680,"thumbnail":"http:\/\/books.google.com\/books\/content?id=BPx9DwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":79.2,"subtitle":"18th International Conference, ICA3PP 2018, Guangzhou, China, November 15-17, 2018, Proceedings","description":"The four-volume set LNCS 11334-11337 constitutes the proceedings of the 18th International Conference on Algorithms and Architectures for Parallel Processing, ICA3PP 2018, held in Guangzhou, China, in November 2018. The 141 full and 50 short papers presented were carefully reviewed and selected from numerous submissions. The papers are organized in topical sections on Distributed and Parallel Computing; High Performance Computing; Big Data and Information Processing; Internet of Things and Cloud Computing; and Security and Privacy in Computing.","language":"en","currency":"USD","id":"3030050572","title":"Algorithms and Architectures for Parallel Processing","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=BPx9DwAAQBAJ&source=gbs_api","authors":["Jaideep Vaidya","Jin Li"]},{"pageCount":97,"thumbnail":"http:\/\/books.google.com\/books\/content?id=6guCDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":55.99,"subtitle":"Principles and Fundamentals using Hadoop and Spark","description":"Data-intensive systems are a technological building block supporting Big Data and Data Science applications.This book familiarizes readers with core concepts that they should be aware of before continuing with independent work and the more advanced technical reference literature that dominates the current landscape. The material in the book is structured following a problem-based approach. This means that the content in the chapters is focused on developing solutions to simplified, but still realistic problems using data-intensive technologies and approaches. The reader follows one reference scenario through the whole book, that uses an open Apache dataset. The origins of this volume are in lectures from a master\u2019s course in Data-intensive Systems, given at the University of Stavanger. Some chapters were also a base for guest lectures at Purdue University and Lodz University of Technology.","language":"en","currency":"USD","id":"3030046036","title":"Data-intensive Systems","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=6guCDwAAQBAJ&source=gbs_api","authors":["Tomasz Wiktorski"]},{"pageCount":264,"thumbnail":"http:\/\/books.google.com\/books\/content?id=XLICEAAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":31.19,"subtitle":null,"description":"If you're training a machine learning model but aren't sure how to put it into production, this book will get you there. Kubeflow provides a collection of cloud native tools for different stages of a model's lifecycle, from data exploration, feature preparation, and model training to model serving. This guide helps data scientists build production-grade machine learning implementations with Kubeflow and shows data engineers how to make models scalable and reliable. Using examples throughout the book, authors Holden Karau, Trevor Grant, Ilan Filonenko, Richard Liu, and Boris Lublinsky explain how to use Kubeflow to train and serve your machine learning models on top of Kubernetes in the cloud or in a development environment on-premises. Understand Kubeflow's design, core components, and the problems it solves Understand the differences between Kubeflow on different cluster types Train models using Kubeflow with popular tools including Scikit-learn, TensorFlow, and Apache Spark Keep your model up to date with Kubeflow Pipelines Understand how to capture model training metadata Explore how to extend Kubeflow with additional open source tools Use hyperparameter tuning for training Learn how to serve your model in production","language":"en","currency":"USD","id":"1492050075","title":"Kubeflow for Machine Learning","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=XLICEAAAQBAJ&source=gbs_api","authors":["Trevor Grant","Holden Karau","Boris Lublinsky","Richard Liu","Ilan Filonenko"]},{"pageCount":398,"thumbnail":"http:\/\/books.google.com\/books\/content?id=8ppYDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":95.2,"subtitle":"A Hands-On Approach for Application Development","description":"In order to carry out data analytics, we need powerful and flexible computing software. However the software available for data analytics is often proprietary and can be expensive. This book reviews Apache tools, which are open source and easy to use. After providing an overview of the background of data analytics, covering the different types of analysis and the basics of using Hadoop as a tool, it focuses on different Hadoop ecosystem tools, like Apache Flume, Apache Spark, Apache Storm, Apache Hive, R, and Python, which can be used for different types of analysis. It then examines the different machine learning techniques that are useful for data analytics, and how to visualize data with different graphs and charts. Presenting data analytics from a practice-oriented viewpoint, the book discusses useful tools and approaches for data analytics, supported by concrete code examples. The book is a valuable reference resource for graduate students and professionals in related fields, and is also of interest to general readers with an understanding of data analytics.","language":"en","currency":"USD","id":"3319778005","title":"Network Data Analytics","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=8ppYDwAAQBAJ&source=gbs_api","authors":["K. G. Srinivasa","Siddesh G. M.","Srinidhi H."]},{"pageCount":122,"thumbnail":"http:\/\/books.google.com\/books\/content?id=6ODlDAAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":0,"subtitle":null,"description":"This IBM® Redbooks® publication provides topics to help the technical community take advantage of the resilience, scalability, and performance of the IBM Power SystemsTM platform to implement or integrate an IBM Data Engine for Hadoop and Spark solution for analytics solutions to access, manage, and analyze data sets to improve business outcomes. This book documents topics to demonstrate and take advantage of the analytics strengths of the IBM POWER8® platform, the IBM analytics software portfolio, and selected third-party tools to help solve customer's data analytic workload requirements. This book describes how to plan, prepare, install, integrate, manage, and show how to use the IBM Data Engine for Hadoop and Spark solution to run analytic workloads on IBM POWER8. In addition, this publication delivers documentation to complement available IBM analytics solutions to help your data analytic needs. This publication strengthens the position of IBM analytics and big data solutions with a well-defined and documented deployment model within an IBM POWER8 virtualized environment so that customers have a planned foundation for security, scaling, capacity, resilience, and optimization for analytics workloads. This book is targeted at technical professionals (analytics consultants, technical support staff, IT Architects, and IT Specialists) that are responsible for delivering analytics solutions and support on IBM Power Systems.","language":"en","currency":"USD","id":"0738441937","title":"IBM Data Engine for Hadoop and Spark","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=6ODlDAAAQBAJ&source=gbs_api","authors":["Dino Quintero","Luis Bolinches","Aditya Gandakusuma Sutandyo","Nicolas Joly","Reinaldo Tetsuo Katahira","IBM Redbooks"]},{"pageCount":496,"thumbnail":"http:\/\/books.google.com\/books\/content?id=2BqSDgAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":31.19,"subtitle":null,"description":"Apache Hadoop is the technology at the heart of the Big Data revolution, and Hadoop skills are in enormous demand. Now, in just 24 lessons of one hour or less, you can learn all the skills and techniques you'll need to deploy each key component of a Hadoop platform in your local environment or in the cloud, building a fully functional Hadoop cluster and using it with real programs and datasets. Each short, easy lesson builds on all that's come before, helping you master all of Hadoop's essentials, and extend it to meet your unique challenges. Apache Hadoop in 24 Hours, Sams Teach Yourself covers all this, and much more: Understanding Hadoop and the Hadoop Distributed File System (HDFS) Importing data into Hadoop, and process it there Mastering basic MapReduce Java programming, and using advanced MapReduce API concepts Making the most of Apache Pig and Apache Hive Implementing and administering YARN Taking advantage of the full Hadoop ecosystem Managing Hadoop clusters with Apache Ambari Working with the Hadoop User Environment (HUE) Scaling, securing, and troubleshooting Hadoop environments Integrating Hadoop into the enterprise Deploying Hadoop in the cloud Getting started with Apache Spark Step-by-step instructions walk you through common questions, issues, and tasks; Q-and-As, Quizzes, and Exercises build and test your knowledge; \"Did You Know?\" tips offer insider advice and shortcuts; and \"Watch Out!\" alerts help you avoid pitfalls. By the time you're finished, you'll be comfortable using Apache Hadoop to solve a wide spectrum of Big Data problems.","language":"en","currency":"USD","id":"0134456726","title":"Hadoop in 24 Hours, Sams Teach Yourself","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=2BqSDgAAQBAJ&source=gbs_api","authors":["Jeffrey Aven"]},{"pageCount":476,"thumbnail":"http:\/\/books.google.com\/books\/content?id=1JTcDgAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":31.19,"subtitle":null,"description":"Discover everything you need to build robust machine learning applications with Spark 2.0 About This Book Get the most up-to-date book on the market that focuses on design, engineering, and scalable solutions in machine learning with Spark 2.0.0 Use Spark's machine learning library in a big data environment You will learn how to develop high-value applications at scale with ease and a develop a personalized design Who This Book Is For This book is for data science engineers and scientists who work with large and complex data sets. You should be familiar with the basics of machine learning concepts, statistics, and computational mathematics. Knowledge of Scala and Java is advisable. What You Will Learn Get solid theoretical understandings of ML algorithms Configure Spark on cluster and cloud infrastructure to develop applications using Scala, Java, Python, and R Scale up ML applications on large cluster or cloud infrastructures Use Spark ML and MLlib to develop ML pipelines with recommendation system, classification, regression, clustering, sentiment analysis, and dimensionality reduction Handle large texts for developing ML applications with strong focus on feature engineering Use Spark Streaming to develop ML applications for real-time streaming Tune ML models with cross-validation, hyperparameters tuning and train split Enhance ML models to make them adaptable for new data in dynamic and incremental environments In Detail Data processing, implementing related algorithms, tuning, scaling up and finally deploying are some crucial steps in the process of optimising any application. Spark is capable of handling large-scale batch and streaming data to figure out when to cache data in memory and processing them up to 100 times faster than Hadoop-based MapReduce. This means predictive analytics can be applied to streaming and batch to develop complete machine learning (ML) applications a lot quicker, making Spark an ideal candidate for large data-intensive applications. This book focuses on design engineering and scalable solutions using ML with Spark. First, you will learn how to install Spark with all new features from the latest Spark 2.0 release. Moving on, you'll explore important concepts such as advanced feature engineering with RDD and Datasets. After studying developing and deploying applications, you will see how to use external libraries with Spark. In summary, you will be able to develop complete and personalised ML applications from data collections,model building, tuning, and scaling up to deploying on a cluster or the cloud. Style and approach This book takes a practical approach where all the topics explained are demonstrated with the help of real-world use cases.","language":"en","currency":"USD","id":"1785883712","title":"Large Scale Machine Learning with Spark","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=1JTcDgAAQBAJ&source=gbs_api","authors":["Md. Rezaul Karim","Md. Mahedi Kaysar"]},{"pageCount":316,"thumbnail":"http:\/\/books.google.com\/books\/content?id=mn9cDgAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":22.39,"subtitle":null,"description":"Use Hadoop to solve business problems by learning from a rich set of real-life case studies About This Book Solve real-world business problems using Hadoop and other Big Data technologies Build efficient data lakes in Hadoop, and develop systems for various business cases like improving marketing campaigns, fraud detection, and more Power packed with six case studies to get you going with Hadoop for Business Intelligence Who This Book Is For If you are interested in building efficient business solutions using Hadoop, this is the book for you This book assumes that you have basic knowledge of Hadoop, Java, and any scripting language. What You Will Learn Learn about the evolution of Hadoop as the big data platform Understand the basics of Hadoop architecture Build a 360 degree view of your customer using Sqoop and Hive Build and run classification models on Hadoop using BigML Use Spark and Hadoop to build a fraud detection system Develop a churn detection system using Java and MapReduce Build an IoT-based data collection and visualization system Get to grips with building a Hadoop-based Data Lake for large enterprises Learn about the coexistence of NoSQL and In-Memory databases in the Hadoop ecosystem In Detail If you have a basic understanding of Hadoop and want to put your knowledge to use to build fantastic Big Data solutions for business, then this book is for you. Build six real-life, end-to-end solutions using the tools in the Hadoop ecosystem, and take your knowledge of Hadoop to the next level. Start off by understanding various business problems which can be solved using Hadoop. You will also get acquainted with the common architectural patterns which are used to build Hadoop-based solutions. Build a 360-degree view of the customer by working with different types of data, and build an efficient fraud detection system for a financial institution. You will also develop a system in Hadoop to improve the effectiveness of marketing campaigns. Build a churn detection system for a telecom company, develop an Internet of Things (IoT) system to monitor the environment in a factory, and build a data lake \u2013 all making use of the concepts and techniques mentioned in this book. The book covers other technologies and frameworks like Apache Spark, Hive, Sqoop, and more, and how they can be used in conjunction with Hadoop. You will be able to try out the solutions explained in the book and use the knowledge gained to extend them further in your own problem space. Style and approach This is an example-driven book where each chapter covers a single business problem and describes its solution by explaining the structure of a dataset and tools required to process it. Every project is demonstrated with a step-by-step approach, and explained in a very easy-to-understand manner.","language":"en","currency":"USD","id":"1783980311","title":"Hadoop Blueprints","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=mn9cDgAAQBAJ&source=gbs_api","authors":["Anurag Shrivastava","Tanmay Deshpande"]},{"pageCount":544,"thumbnail":"http:\/\/books.google.com\/books\/content?id=OnCLDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":31.72,"subtitle":"Big data processing at scale to unlock unique business insights","description":"A comprehensive guide to mastering the most advanced Hadoop 3 concepts Key Features Get to grips with the newly introduced features and capabilities of Hadoop 3 Crunch and process data using MapReduce, YARN, and a host of tools within the Hadoop ecosystem Sharpen your Hadoop skills with real-world case studies and code Book Description Apache Hadoop is one of the most popular big data solutions for distributed storage and for processing large chunks of data. With Hadoop 3, Apache promises to provide a high-performance, more fault-tolerant, and highly efficient big data processing platform, with a focus on improved scalability and increased efficiency. With this guide, you\u2019ll understand advanced concepts of the Hadoop ecosystem tool. You\u2019ll learn how Hadoop works internally, study advanced concepts of different ecosystem tools, discover solutions to real-world use cases, and understand how to secure your cluster. It will then walk you through HDFS, YARN, MapReduce, and Hadoop 3 concepts. You\u2019ll be able to address common challenges like using Kafka efficiently, designing low latency, reliable message delivery Kafka systems, and handling high data volumes. As you advance, you\u2019ll discover how to address major challenges when building an enterprise-grade messaging system, and how to use different stream processing systems along with Kafka to fulfil your enterprise goals. By the end of this book, you\u2019ll have a complete understanding of how components in the Hadoop ecosystem are effectively integrated to implement a fast and reliable data pipeline, and you\u2019ll be equipped to tackle a range of real-world problems in data pipelines. What you will learn Gain an in-depth understanding of distributed computing using Hadoop 3 Develop enterprise-grade applications using Apache Spark, Flink, and more Build scalable and high-performance Hadoop data pipelines with security, monitoring, and data governance Explore batch data processing patterns and how to model data in Hadoop Master best practices for enterprises using, or planning to use, Hadoop 3 as a data platform Understand security aspects of Hadoop, including authorization and authentication Who this book is for If you want to become a big data professional by mastering the advanced concepts of Hadoop, this book is for you. You\u2019ll also find this book useful if you\u2019re a Hadoop professional looking to strengthen your knowledge of the Hadoop ecosystem. Fundamental knowledge of the Java programming language and basics of Hadoop is necessary to get started with this book.","language":"en","currency":"USD","id":"1788628322","title":"Mastering Hadoop 3","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=OnCLDwAAQBAJ&source=gbs_api","authors":["Chanchal Singh","Manish Kumar"]},{"pageCount":544,"thumbnail":"http:\/\/books.google.com\/books\/content?id=gJf9tI2mytIC&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":17.27,"subtitle":"Standards and Styles for Developing Maintainable Code","description":"Many programmers code by instinct, relying on convenient habits or a \"style\" they picked up early on. They aren't conscious of all the choices they make, like how they format their source, the names they use for variables, or the kinds of loops they use. They're focused entirely on problems they're solving, solutions they're creating, and algorithms they're implementing. So they write code in the way that seems natural, that happens intuitively, and that feels good. But if you're serious about your profession, intuition isn't enough. Perl Best Practices author Damian Conway explains that rules, conventions, standards, and practices not only help programmers communicate and coordinate with one another, they also provide a reliable framework for thinking about problems, and a common language for expressing solutions. This is especially critical in Perl, because the language is designed to offer many ways to accomplish the same task, and consequently it supports many incompatible dialects. With a good dose of Aussie humor, Dr. Conway (familiar to many in the Perl community) offers 256 guidelines on the art of coding to help you write better Perl code--in fact, the best Perl code you possibly can. The guidelines cover code layout, naming conventions, choice of data and control structures, program decomposition, interface design and implementation, modularity, object orientation, error handling, testing, and debugging. They're designed to work together to produce code that is clear, robust, efficient, maintainable, and concise, but Dr. Conway doesn't pretend that this is the one true universal and unequivocal set of best practices. Instead, Perl Best Practices offers coherent and widely applicable suggestions based on real-world experience of how code is actually written, rather than on someone's ivory-tower theories on howsoftware ought to be created. Most of all, Perl Best Practices offers guidelines that actually work, and that many developers around the world are already using. Much like Perl itself, these guidelines are about helping you to get your job done, without getting in the way. Praise for Perl Best Practices from Perl community members: \"As a manager of a large Perl project, I'd ensure that every member of my team has a copy of Perl Best Practices on their desk, and use it as the basis for an in-house style guide.\"-- Randal Schwartz \"There are no more excuses for writing bad Perl programs. All levels of Perl programmer will be more productive after reading this book.\"-- Peter Scott \"Perl Best Practices will be the next big important book in the evolution of Perl. The ideas and practices Damian lays down will help bring Perl out from under the embarrassing heading of \"scripting languages\". Many of us have known Perl is a real programming language, worthy of all the tasks normally delegated to Java and C++. With Perl Best Practices, Damian shows specifically how and why, so everyone else can see, too.\"-- Andy Lester \"Damian's done what many thought impossible: show how to build large, maintainable Perl applications, while still letting Perl be the powerful, expressive language that programmers have loved for years.\"-- Bill Odom \"Finally, a means to bring lasting order to the process and product of real Perl development teams.\"-- Andrew Sundstrom \"Perl Best Practices provides a valuable education in how to write robust, maintainable Perl, and is a definitive citation source when coaching other programmers.\"-- Bennett Todd\"I've been teaching Perl for years, and find the same question keeps being asked: Where can I find a reference for writing reusable, maintainable Perl code? Finally I have a decent answer.\"-- Paul Fenwick\"At last a well researched, well thought-out, comprehensive guide to Perl style. Instead of each of us developing our own, we can learn good practices from one of Perl's most prolific and experienced authors. I recommend this book to anyone who prefers getting on with the job rather than going back and fixing errors caused by syntax and poor style issues.\"-- Jacinta Richardson\"If you care about programming in any language read this book. Even if you don't intend to follow all of the practices, thinking through your style will improve it.\"-- Steven Lembark\"The Perl community's best author is back with another outstanding book. There has never been a comprehensive reference on high quality Perl coding and style until Perl Best Practices. This book fills a large gap in every Perl bookshelf.\"-- Uri Guttman","language":"en","currency":"USD","id":"9780596555023","title":"Perl Best Practices","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=gJf9tI2mytIC&source=gbs_api","authors":["Damian Conway"]},{"pageCount":504,"thumbnail":"http:\/\/books.google.com\/books\/content?id=KGIbfiiP1i4C&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":19.79,"subtitle":"Analyzing Text with the Natural Language Toolkit","description":"This book offers a highly accessible introduction to natural language processing, the field that supports a variety of language technologies, from predictive text and email filtering to automatic summarization and translation. With it, you'll learn how to write Python programs that work with large collections of unstructured text. You'll access richly annotated datasets using a comprehensive range of linguistic data structures, and you'll understand the main algorithms for analyzing the content and structure of written communication. Packed with examples and exercises, Natural Language Processing with Python will help you: Extract information from unstructured text, either to guess the topic or identify \"named entities\" Analyze linguistic structure in text, including parsing and semantic analysis Access popular linguistic databases, including WordNet and treebanks Integrate techniques drawn from fields as diverse as linguistics and artificial intelligence This book will help you gain practical skills in natural language processing using the Python programming language and the Natural Language Toolkit (NLTK) open source library. If you're interested in developing web applications, analyzing multilingual news sources, or documenting endangered languages -- or if you're simply curious to have a programmer's perspective on how human language works -- you'll find Natural Language Processing with Python both fascinating and immensely useful.","language":"en","currency":"USD","id":"0596555717","title":"Natural Language Processing with Python","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=KGIbfiiP1i4C&source=gbs_api","authors":["Steven Bird","Ewan Klein","Edward Loper"]},{"pageCount":368,"thumbnail":"http:\/\/books.google.com\/books\/content?id=FRu3DwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":30,"subtitle":"Essential Techniques for Predictive Analytics","description":"Machine Learning with Spark and Python Essential Techniques for Predictive Analytics, Second Edition simplifies ML for practical uses by focusing on two key algorithms. This new second edition improves with the addition of Spark\u2014a ML framework from the Apache foundation. By implementing Spark, machine learning students can easily process much large data sets and call the spark algorithms using ordinary Python code. Machine Learning with Spark and Python focuses on two algorithm families (linear methods and ensemble methods) that effectively predict outcomes. This type of problem covers many use cases such as what ad to place on a web page, predicting prices in securities markets, or detecting credit card fraud. The focus on two families gives enough room for full descriptions of the mechanisms at work in the algorithms. Then the code examples serve to illustrate the workings of the machinery with specific hackable code.","language":"en","currency":"USD","id":"1119561957","title":"Machine Learning with Spark and Python","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=FRu3DwAAQBAJ&source=gbs_api","authors":["Michael Bowles"]},{"pageCount":1392,"thumbnail":"http:\/\/books.google.com\/books\/content?id=WuCgDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":215.2,"subtitle":"Proceedings of the INFUS 2019 Conference, Istanbul, Turkey, July 23-25, 2019","description":"This book includes the proceedings of the Intelligent and Fuzzy Techniques INFUS 2019 Conference, held in Istanbul, Turkey, on July 23\u201325, 2019. Big data analytics refers to the strategy of analyzing large volumes of data, or big data, gathered from a wide variety of sources, including social networks, videos, digital images, sensors, and sales transaction records. Big data analytics allows data scientists and various other users to evaluate large volumes of transaction data and other data sources that traditional business systems would be unable to tackle. Data-driven and knowledge-driven approaches and techniques have been widely used in intelligent decision-making, and they are increasingly attracting attention due to their importance and effectiveness in addressing uncertainty and incompleteness. INFUS 2019 focused on intelligent and fuzzy systems with applications in big data analytics and decision-making, providing an international forum that brought together those actively involved in areas of interest to data science and knowledge engineering. These proceeding feature about 150 peer-reviewed papers from countries such as China, Iran, Turkey, Malaysia, India, USA, Spain, France, Poland, Mexico, Bulgaria, Algeria, Pakistan, Australia, Lebanon, and Czech Republic.","language":"en","currency":"USD","id":"3030237567","title":"Intelligent and Fuzzy Techniques in Big Data Analytics and Decision Making","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=WuCgDwAAQBAJ&source=gbs_api","authors":["Cengiz Kahraman","Selcuk Cebi","Sezi Cevik Onar","Basar Oztaysi","A. Cagri Tolga","Irem Ucal Sari"]},{"pageCount":400,"thumbnail":"http:\/\/books.google.com\/books\/content?id=SWTNDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":40,"subtitle":null,"description":"Publisher's Note: Products purchased from Third Party sellers are not guaranteed by the publisher for quality, authenticity, or access to any online entitlements included with the product. Manage your own robust, inexpensive cybersecurity testing environment This hands-on guide shows clearly how to administer an effective cybersecurity testing lab using affordable technologies and cloud resources. Build Your Own Cybersecurity Testing Lab: Low-cost Solutions for Testing in Virtual and Cloud-based Environments fully explains multiple techniques for developing lab systems, including the use of Infrastructure-as-Code, meaning you can write programs to create your labs quickly, without manual steps that could lead to costly and frustrating mistakes. Written by a seasoned IT security professional and academic, this book offers complete coverage of cloud and virtual environments as well as physical networks and automation. Included with the book is access to videos that demystify difficult concepts. Inside, you will discover how to: \u2022 Gather network requirements and build your cybersecurity testing lab \u2022 Set up virtual machines and physical systems from inexpensive components \u2022 Select and configure the necessary operating systems \u2022 Gain remote access through SSH, RDP, and other remote access protocols \u2022 Efficiently isolate subnets with physical switches, routers, and VLANs \u2022 Analyze the vulnerabilities and challenges of cloud-based infrastructures \u2022 Handle implementation of systems on Amazon Web Services, Microsoft Azure, and Google Cloud Engine \u2022 Maximize consistency and repeatability using the latest automation tools","language":"en","currency":"USD","id":"1260458326","title":"Build Your Own Cybersecurity Testing Lab: Low-cost Solutions for Testing in Virtual and Cloud-based Environments","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=SWTNDwAAQBAJ&source=gbs_api","authors":["Ric Messier"]},{"pageCount":365,"thumbnail":"http:\/\/books.google.com\/books\/content?id=Y8FHDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":39.49,"subtitle":null,"description":"See a Mesos-based big data stack created and the components used. You will use currently available Apache full and incubating systems. The components are introduced by example and you learn how they work together. In the Complete Guide to Open Source Big Data Stack, the author begins by creating a private cloud and then installs and examines Apache Brooklyn. After that, he uses each chapter to introduce one piece of the big data stack\u2014sharing how to source the software and how to install it. You learn by simple example, step by step and chapter by chapter, as a real big data stack is created. The book concentrates on Apache-based systems and shares detailed examples of cloud storage, release management, resource management, processing, queuing, frameworks, data visualization, and more. What You\u2019ll Learn Install a private cloud onto the local cluster using Apache cloud stack Source, install, and configure Apache: Brooklyn, Mesos, Kafka, and Zeppelin See how Brooklyn can be used to install Mule ESB on a cluster and Cassandra in the cloud Install and use DCOS for big data processing Use Apache Spark for big data stack data processing Who This Book Is For Developers, architects, IT project managers, database administrators, and others charged with developing or supporting a big data system. It is also for anyone interested in Hadoop or big data, and those experiencing problems with data size.","language":"en","currency":"USD","id":"1484221494","title":"Complete Guide to Open Source Big Data Stack","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=Y8FHDwAAQBAJ&source=gbs_api","authors":["Michael Frampton"]},{"pageCount":598,"thumbnail":"http:\/\/books.google.com\/books\/content?id=3XqrBQAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":31.19,"subtitle":"Scalability = Functional Programming + Objects","description":"Get up to speed on Scala, the JVM language that offers all the benefits of a modern object model, functional programming, and an advanced type system. Packed with code examples, this comprehensive book shows you how to be productive with the language and ecosystem right away, and explains why Scala is ideal for today's highly scalable, data-centric applications that support concurrency and distribution. This second edition covers recent language features, with new chapters on pattern matching, comprehensions, and advanced functional programming. You\u2019ll also learn about Scala\u2019s command-line tools, third-party tools, libraries, and language-aware plugins for editors and IDEs. This book is ideal for beginning and advanced Scala developers alike. Program faster with Scala\u2019s succinct and flexible syntax Dive into basic and advanced functional programming (FP) techniques Build killer big-data apps, using Scala\u2019s functional combinators Use traits for mixin composition and pattern matching for data extraction Learn the sophisticated type system that combines FP and object-oriented programming concepts Explore Scala-specific concurrency tools, including Akka Understand how to develop rich domain-specific languages Learn good design techniques for building scalable and robust Scala applications","language":"en","currency":"USD","id":"1491950153","title":"Programming Scala","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=3XqrBQAAQBAJ&source=gbs_api","authors":["Dean Wampler","Alex Payne"]},{"pageCount":416,"thumbnail":"http:\/\/books.google.com\/books\/content?id=NV8dDAAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":31.72,"subtitle":null,"description":"Leverage the power of Scala with different tools to build scalable, robust data science applications About This Book A complete guide for scalable data science solutions, from data ingestion to data visualization Deploy horizontally scalable data processing pipelines and take advantage of web frameworks to build engaging visualizations Build functional, type-safe routines to interact with relational and NoSQL databases with the help of tutorials and examples provided Who This Book Is For If you are a Scala developer or data scientist, or if you want to enter the field of data science, then this book will give you all the tools you need to implement data science solutions. What You Will Learn Transform and filter tabular data to extract features for machine learning Implement your own algorithms or take advantage of MLLib's extensive suite of models to build distributed machine learning pipelines Read, transform, and write data to both SQL and NoSQL databases in a functional manner Write robust routines to query web APIs Read data from web APIs such as the GitHub or Twitter API Use Scala to interact with MongoDB, which offers high performance and helps to store large data sets with uncertain query requirements Create Scala web applications that couple with JavaScript libraries such as D3 to create compelling interactive visualizations Deploy scalable parallel applications using Apache Spark, loading data from HDFS or Hive In Detail Scala is a multi-paradigm programming language (it supports both object-oriented and functional programming) and scripting language used to build applications for the JVM. Languages such as R, Python, Java, and so on are mostly used for data science. It is particularly good at analyzing large sets of data without any significant impact on performance and thus Scala is being adopted by many developers and data scientists. Data scientists might be aware that building applications that are truly scalable is hard. Scala, with its powerful functional libraries for interacting with databases and building scalable frameworks will give you the tools to construct robust data pipelines. This book will introduce you to the libraries for ingesting, storing, manipulating, processing, and visualizing data in Scala. Packed with real-world examples and interesting data sets, this book will teach you to ingest data from flat files and web APIs and store it in a SQL or NoSQL database. It will show you how to design scalable architectures to process and modelling your data, starting from simple concurrency constructs such as parallel collections and futures, through to actor systems and Apache Spark. As well as Scala's emphasis on functional structures and immutability, you will learn how to use the right parallel construct for the job at hand, minimizing development time without compromising scalability. Finally, you will learn how to build beautiful interactive visualizations using web frameworks. This book gives tutorials on some of the most common Scala libraries for data science, allowing you to quickly get up to speed with building data science and data engineering solutions. Style and approach A tutorial with complete examples, this book will give you the tools to start building useful data engineering and data science solutions straightaway","language":"en","currency":"USD","id":"1785289381","title":"Scala for Data Science","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=NV8dDAAAQBAJ&source=gbs_api","authors":["Pascal Bugnion"]},{"pageCount":400,"thumbnail":"http:\/\/books.google.com\/books\/content?id=heoXAwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":17.27,"subtitle":"Moving beyond MapReduce and Batch Processing with Apache Hadoop 2","description":"\u201CThis book is a critically needed resource for the newly released Apache Hadoop 2.0, highlighting YARN as the significant breakthrough that broadens Hadoop beyond the MapReduce paradigm.\u201D \u2014From the Foreword by Raymie Stata, CEO of Altiscale The Insider\u2019s Guide to Building Distributed, Big Data Applications with Apache Hadoop™ YARN Apache Hadoop is helping drive the Big Data revolution. Now, its data processing has been completely overhauled: Apache Hadoop YARN provides resource management at data center scale and easier ways to create distributed applications that process petabytes of data. And now in Apache Hadoop™ YARN, two Hadoop technical leaders show you how to develop new applications and adapt existing code to fully leverage these revolutionary advances. YARN project founder Arun Murthy and project lead Vinod Kumar Vavilapalli demonstrate how YARN increases scalability and cluster utilization, enables new programming models and services, and opens new options beyond Java and batch processing. They walk you through the entire YARN project lifecycle, from installation through deployment. You\u2019ll find many examples drawn from the authors\u2019 cutting-edge experience\u2014first as Hadoop\u2019s earliest developers and implementers at Yahoo! and now as Hortonworks developers moving the platform forward and helping customers succeed with it. Coverage includes YARN\u2019s goals, design, architecture, and components\u2014how it expands the Apache Hadoop ecosystem Exploring YARN on a single node Administering YARN clusters and Capacity Scheduler Running existing MapReduce applications Developing a large-scale clustered YARN application Discovering new open source frameworks that run under YARN","language":"en","currency":"USD","id":"0133441911","title":"Apache Hadoop YARN","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=heoXAwAAQBAJ&source=gbs_api","authors":["Arun Murthy","Vinod Vavilapalli","Douglas Eadline","Joseph Niemiec","Jeff Markham"]},{"pageCount":120,"thumbnail":"http:\/\/books.google.com\/books\/content?id=PdqcAQAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":13.94,"subtitle":null,"description":"This book will be a basic, step-by-step tutorial, which will help readers take advantage of all that Spark has to offer.Fastdata Processing with Spark is for software developers who want to learn how to write distributed programs with Spark. It will help developers who have had problems that were too much to be dealt with on a single computer. No previous experience with distributed programming is necessary. This book assumes knowledge of either Java, Scala, or Python.","language":"en","currency":"USD","id":"1782167072","title":"Fast Data Processing With Spark","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=PdqcAQAAQBAJ&source=gbs_api","authors":["Holden Karau"]},{"pageCount":262,"thumbnail":"http:\/\/books.google.com\/books\/content?id=g5DqDAAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":19.24,"subtitle":"Charting Your Strategy for Next-Generation Business Analytics","description":"Learn all you need to know about seven key innovations disrupting business analytics today. These innovations\u2014the open source business model, cloud analytics, the Hadoop ecosystem, Spark and in-memory analytics, streaming analytics, Deep Learning, and self-service analytics\u2014are radically changing how businesses use data for competitive advantage. Taken together, they are disrupting the business analytics value chain, creating new opportunities. Enterprises who seize the opportunity will thrive and prosper, while others struggle and decline: disrupt or be disrupted. Disruptive Business Analytics provides strategies to profit from disruption. It shows you how to organize for insight, build and provision an open source stack, how to practice lean data warehousing, and how to assimilate disruptive innovations into an organization. Through a short history of business analytics and a detailed survey of products and services, analytics authority Thomas W. Dinsmore provides a practical explanation of the most compelling innovations available today. What You'll Learn Discover how the open source business model works and how to make it work for you See how cloud computing completely changes the economics of analytics Harness the power of Hadoop and its ecosystem Find out why Apache Spark is everywhere Discover the potential of streaming and real-time analytics Learn what Deep Learning can do and why it matters See how self-service analytics can change the way organizations do business Who This Book Is For Corporate actors at all levels of responsibility for analytics: analysts, CIOs, CTOs, strategic decision makers, managers, systems architects, technical marketers, product developers, IT personnel, and consultants.","language":"en","currency":"USD","id":"1484213114","title":"Disruptive Analytics","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=g5DqDAAAQBAJ&source=gbs_api","authors":["Thomas W. Dinsmore"]},{"pageCount":290,"thumbnail":"http:\/\/books.google.com\/books\/content?id=w7LjCwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":31.72,"subtitle":null,"description":"Over 90 hands-on recipes to help you learn and master the intricacies of Apache Hadoop 2.X, YARN, Hive, Pig, Oozie, Flume, Sqoop, Apache Spark, and Mahout About This Book Implement outstanding Machine Learning use cases on your own analytics models and processes. Solutions to common problems when working with the Hadoop ecosystem. Step-by-step implementation of end-to-end big data use cases. Who This Book Is For Readers who have a basic knowledge of big data systems and want to advance their knowledge with hands-on recipes. What You Will Learn Installing and maintaining Hadoop 2.X cluster and its ecosystem. Write advanced Map Reduce programs and understand design patterns. Advanced Data Analysis using the Hive, Pig, and Map Reduce programs. Import and export data from various sources using Sqoop and Flume. Data storage in various file formats such as Text, Sequential, Parquet, ORC, and RC Files. Machine learning principles with libraries such as Mahout Batch and Stream data processing using Apache Spark In Detail Big data is the current requirement. Most organizations produce huge amount of data every day. With the arrival of Hadoop-like tools, it has become easier for everyone to solve big data problems with great efficiency and at minimal cost. Grasping Machine Learning techniques will help you greatly in building predictive models and using this data to make the right decisions for your organization. Hadoop Real World Solutions Cookbook gives readers insights into learning and mastering big data via recipes. The book not only clarifies most big data tools in the market but also provides best practices for using them. The book provides recipes that are based on the latest versions of Apache Hadoop 2.X, YARN, Hive, Pig, Sqoop, Flume, Apache Spark, Mahout and many more such ecosystem tools. This real-world-solution cookbook is packed with handy recipes you can apply to your own everyday issues. Each chapter provides in-depth recipes that can be referenced easily. This book provides detailed practices on the latest technologies such as YARN and Apache Spark. Readers will be able to consider themselves as big data experts on completion of this book. This guide is an invaluable tutorial if you are planning to implement a big data warehouse for your business. Style and approach An easy-to-follow guide that walks you through world of big data. Each tool in the Hadoop ecosystem is explained in detail and the recipes are placed in such a manner that readers can implement them sequentially. Plenty of reference links are provided for advanced reading.","language":"en","currency":"USD","id":"1784398004","title":"Hadoop Real-World Solutions Cookbook","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=w7LjCwAAQBAJ&source=gbs_api","authors":["Tanmay Deshpande"]},{"pageCount":320,"thumbnail":"http:\/\/books.google.com\/books\/content?id=_JRwCwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":16.75,"subtitle":null,"description":"Apache Sparkは多数のコンピュータを並列で動かして高速処理を実現する技術です。大量のデータを扱う「ビッグデータ」や「機械学習」、「IoT(Internet of Things:物のインターネット)」などの分野で応用が期待されるOSS(Open Source Software)です。 Apache SparkはUCバークレイで提唱されたRDD(Resilient Distributed Datasets)というアーキテクチャを採用しており、メモリを積極的に活用した分散並列処理を実現します。これにより、従来よりも大幅なパフォーマンスアップが期待できます。また、Hadoopとの高い親和性を有しており、YARNやHDFSなどのHadoopのシステムの枠組を使えます。 本書はApache Sparkを使うための知識を簡潔かつ実践的に紹介していきます。Apache Sparkでは「機械学習」「グラフ処理」「ストリーミング」処理等々を実現するためのライブラリが標準で利用できますが、各分野への応用も見据えたこれらの活用方法も本書で解説します。 Apache Sparkの仕組みとその利用方法を理解することにより、一歩先を行くデータ処理の新しい潮流を知ることができます。 \u203B本電子書籍は同名出版物を底本として作成しました。記載内容は印刷出版当時のものです。 \u203B印刷出版再現のため電子書籍としては不要な情報を含んでいる場合があります。 \u203B印刷出版とは異なる表記・表現の場合があります。予めご了承ください。 \u203Bプレビューにてお手持ちの電子端末での表示状態をご確認の上、商品をお買い求めください。 (翔泳社)","language":"ja","currency":"USD","id":"4798143944","title":"Apache Spark入門 動かして学ぶ最新並列分散処理フレームワーク","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=_JRwCwAAQBAJ&source=gbs_api","authors":["株式会社NTTデータ","猿田浩輔","土橋昌","吉田耕陽","佐々木徹","都築正宜"]},{"pageCount":376,"thumbnail":"http:\/\/books.google.com\/books\/content?id=OM_cDgAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":31.19,"subtitle":null,"description":"Combine the incredible powers of Spark, Mesos, Akka, Cassandra, and Kafka to build data processing platforms that can take on even the hardest of your data troubles! About This Book This highly practical guide shows you how to use the best of the big data technologies to solve your response-critical problems Learn the art of making cheap-yet-effective big data architecture without using complex Greek-letter architectures Use this easy-to-follow guide to build fast data processing systems for your organization Who This Book Is For If you are a developer, data architect, or a data scientist looking for information on how to integrate the Big Data stack architecture and how to choose the correct technology in every layer, this book is what you are looking for. What You Will Learn Design and implement a fast data Pipeline architecture Think and solve programming challenges in a functional way with Scala Learn to use Akka, the actors model implementation for the JVM Make on memory processing and data analysis with Spark to solve modern business demands Build a powerful and effective cluster infrastructure with Mesos and Docker Manage and consume unstructured and No-SQL data sources with Cassandra Consume and produce messages in a massive way with Kafka In Detail SMACK is an open source full stack for big data architecture. It is a combination of Spark, Mesos, Akka, Cassandra, and Kafka. This stack is the newest technique developers have begun to use to tackle critical real-time analytics for big data. This highly practical guide will teach you how to integrate these technologies to create a highly efficient data analysis system for fast data processing. We'll start off with an introduction to SMACK and show you when to use it. First you'll get to grips with functional thinking and problem solving using Scala. Next you'll come to understand the Akka architecture. Then you'll get to know how to improve the data structure architecture and optimize resources using Apache Spark. Moving forward, you'll learn how to perform linear scalability in databases with Apache Cassandra. You'll grasp the high throughput distributed messaging systems using Apache Kafka. We'll show you how to build a cheap but effective cluster infrastructure with Apache Mesos. Finally, you will deep dive into the different aspect of SMACK using a few case studies. By the end of the book, you will be able to integrate all the components of the SMACK stack and use them together to achieve highly effective and fast data processing. Style and approach With the help of various industry examples, you will learn about the full stack of big data architecture, taking the important aspects in every technology. You will learn how to integrate the technologies to build effective systems rather than getting incomplete information on single technologies. You will learn how various open source technologies can be used to build cheap and fast data processing systems with the help of various industry examples","language":"en","currency":"USD","id":"1786468069","title":"Fast Data Processing Systems with SMACK Stack","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=OM_cDgAAQBAJ&source=gbs_api","authors":["Raul Estrada"]},{"pageCount":400,"thumbnail":"http:\/\/books.google.com\/books\/content?id=qZwvCgAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":40,"subtitle":"A Guide to Data Science for Fraud Detection","description":"Detect fraud earlier to mitigate loss and prevent cascading damage Fraud Analytics Using Descriptive, Predictive, and Social Network Techniques is an authoritative guidebook for setting up a comprehensive fraud detection analytics solution. Early detection is a key factor in mitigating fraud damage, but it involves more specialized techniques than detecting fraud at the more advanced stages. This invaluable guide details both the theory and technical aspects of these techniques, and provides expert insight into streamlining implementation. Coverage includes data gathering, preprocessing, model building, and post-implementation, with comprehensive guidance on various learning techniques and the data types utilized by each. These techniques are effective for fraud detection across industry boundaries, including applications in insurance fraud, credit card fraud, anti-money laundering, healthcare fraud, telecommunications fraud, click fraud, tax evasion, and more, giving you a highly practical framework for fraud prevention. It is estimated that a typical organization loses about 5% of its revenue to fraud every year. More effective fraud detection is possible, and this book describes the various analytical techniques your organization must implement to put a stop to the revenue leak. Examine fraud patterns in historical data Utilize labeled, unlabeled, and networked data Detect fraud before the damage cascades Reduce losses, increase recovery, and tighten security The longer fraud is allowed to go on, the more harm it causes. It expands exponentially, sending ripples of damage throughout the organization, and becomes more and more complex to track, stop, and reverse. Fraud prevention relies on early and effective fraud detection, enabled by the techniques discussed here. Fraud Analytics Using Descriptive, Predictive, and Social Network Techniques helps you stop fraud in its tracks, and eliminate the opportunities for future occurrence.","language":"en","currency":"USD","id":"1119146836","title":"Fraud Analytics Using Descriptive, Predictive, and Social Network Techniques","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=qZwvCgAAQBAJ&source=gbs_api","authors":["Bart Baesens","Veronique Van Vlasselaer","Wouter Verbeke"]},{"pageCount":278,"thumbnail":"http:\/\/books.google.com\/books\/content?id=V5qzDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":34.99,"subtitle":"Dive into the Future of Infrastructure","description":"Kubernetes radically changes the way applications are built and deployed in the cloud. Since its introduction in 2014, this container orchestrator has become one of the largest and most popular open source projects in the world. The updated edition of this practical book shows developers and ops personnel how Kubernetes and container technology can help you achieve new levels of velocity, agility, reliability, and efficiency. Kelsey Hightower, Brendan Burns, and Joe Beda\u2014who\u2019ve worked on Kubernetes at Google and beyond\u2014explain how this system fits into the lifecycle of a distributed application. You\u2019ll learn how to use tools and APIs to automate scalable distributed systems, whether it\u2019s for online services, machine learning applications, or a cluster of Raspberry Pi computers. Create a simple cluster to learn how Kubernetes works Dive into the details of deploying an application using Kubernetes Learn specialized objects in Kubernetes, such as DaemonSets, jobs, ConfigMaps, and secrets Explore deployments that tie together the lifecycle of a complete application Get practical examples of how to develop and deploy real-world applications in Kubernetes","language":"en","currency":"USD","id":"1492046485","title":"Kubernetes: Up and Running","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=V5qzDwAAQBAJ&source=gbs_api","authors":["Brendan Burns","Joe Beda","Kelsey Hightower"]},{"pageCount":560,"thumbnail":"http:\/\/books.google.com\/books\/content?id=fyisDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":31.19,"subtitle":"A practical guide to designing, indexing, and querying advanced distributed search engines","description":"Master the intricacies of Elasticsearch 7.0 and use it to create flexible and scalable search solutions Key Features Master the latest distributed search and analytics capabilities of Elasticsearch 7.0 Perform searching, indexing, and aggregation of your data at scale Discover tips and techniques for speeding up your search query performance Book Description Building enterprise-grade distributed applications and executing systematic search operations call for a strong understanding of Elasticsearch and expertise in using its core APIs and latest features. This book will help you master the advanced functionalities of Elasticsearch and understand how you can develop a sophisticated, real-time search engine confidently. In addition to this, you'll also learn to run machine learning jobs in Elasticsearch to speed up routine tasks. You'll get started by learning to use Elasticsearch features on Hadoop and Spark and make search results faster, thereby improving the speed of query results and enhancing the customer experience. You'll then get up to speed with performing analytics by building a metrics pipeline, defining queries, and using Kibana for intuitive visualizations that help provide decision-makers with better insights. The book will later guide you through using Logstash with examples to collect, parse, and enrich logs before indexing them in Elasticsearch. By the end of this book, you will have comprehensive knowledge of advanced topics such as Apache Spark support, machine learning using Elasticsearch and scikit-learn, and real-time analytics, along with the expertise you need to increase business productivity, perform analytics, and get the very best out of Elasticsearch. What you will learn Pre-process documents before indexing in ingest pipelines Learn how to model your data in the real world Get to grips with using Elasticsearch for exploratory data analysis Understand how to build analytics and RESTful services Use Kibana, Logstash, and Beats for dashboard applications Get up to speed with Spark and Elasticsearch for real-time analytics Explore the basics of Spring Data Elasticsearch, and understand how to index, search, and query in a Spring application Who this book is for This book is for Elasticsearch developers and data engineers who want to take their basic knowledge of Elasticsearch to the next level and use it to build enterprise-grade distributed search applications. Prior experience of working with Elasticsearch will be useful to get the most out of this book.","language":"en","currency":"USD","id":"1789956560","title":"Advanced Elasticsearch 7.0","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=fyisDwAAQBAJ&source=gbs_api","authors":["Wai Tak Wong"]},{"pageCount":239,"thumbnail":"http:\/\/books.google.com\/books\/content?id=aC02DwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":55.99,"subtitle":"6th IFIP WG 2.14 European Conference, ESOCC 2017, Oslo, Norway, September 27-29, 2017, Proceedings","description":"This book constitutes the refereed proceedings of the 6th IFIP WG 2.14 European Conference on Service-Oriented and Cloud Computing, ESOCC 2017, held in Oslo, Norway, in September 2017. The 6 short and 10 full papers presented in this volume were carefully reviewed and selected from 37 submissions. The volume also contains one invited talk in full paper length. The contributions were organized in topical sections named: microservices and containers; security; cloud resources; services; internet of things and data streams; and industrial applications of service and cloud computing.","language":"en","currency":"USD","id":"3319672622","title":"Service-Oriented and Cloud Computing","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=aC02DwAAQBAJ&source=gbs_api","authors":["Flavio De Paoli","Stefan Schulte","Einar Broch Johnsen"]},{"pageCount":183,"thumbnail":"http:\/\/books.google.com\/books\/content?id=-i2lDgAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":47.39,"subtitle":"Second International Workshop, ALGOCLOUD 2016, Aarhus, Denmark, August 22, 2016, Revised Selected Papers","description":"This book constitutes the thoroughly refereed post-conference proceedings of the Second International Workshop on Algorithmic Aspects of Cloud Computing, ALGOCLOUD 2016, held in Aarhus, Denmark, in August 2016. The 11 revised full papers presented together with one tutorial paper were carefully reviewed and selected from 30 initial submissions. They deal with the following topics: algorithmic aspects of elasticity and scalability for distributed, large-scale data stores (e.g. NoSQL and columnar databases); search and retrieval algorithms for cloud infrastructures; monitoring and analysis of elasticity for virtualized environments; NoSQL, schemaless data modeling, integration; caching and load-balancing; storage structures and indexing for cloud databases; new algorithmic aspects of parallel and distributed computing for cloud applications; scalable machine learning, analytics and data science; high availability, reliability, failover; transactional models and algorithms for cloud databases; query languages and processing programming models; consistency, replication and partitioning CAP, data structures and algorithms for eventually consistent stores.","language":"en","currency":"USD","id":"3319570455","title":"Algorithmic Aspects of Cloud Computing","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=-i2lDgAAQBAJ&source=gbs_api","authors":["Timos Sellis","Konstantinos Oikonomou"]},{"pageCount":183,"thumbnail":"http:\/\/books.google.com\/books\/content?id=-i2lDgAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":47.39,"subtitle":"Second International Workshop, ALGOCLOUD 2016, Aarhus, Denmark, August 22, 2016, Revised Selected Papers","description":"This book constitutes the thoroughly refereed post-conference proceedings of the Second International Workshop on Algorithmic Aspects of Cloud Computing, ALGOCLOUD 2016, held in Aarhus, Denmark, in August 2016. The 11 revised full papers presented together with one tutorial paper were carefully reviewed and selected from 30 initial submissions. They deal with the following topics: algorithmic aspects of elasticity and scalability for distributed, large-scale data stores (e.g. NoSQL and columnar databases); search and retrieval algorithms for cloud infrastructures; monitoring and analysis of elasticity for virtualized environments; NoSQL, schemaless data modeling, integration; caching and load-balancing; storage structures and indexing for cloud databases; new algorithmic aspects of parallel and distributed computing for cloud applications; scalable machine learning, analytics and data science; high availability, reliability, failover; transactional models and algorithms for cloud databases; query languages and processing programming models; consistency, replication and partitioning CAP, data structures and algorithms for eventually consistent stores.","language":"en","currency":"USD","id":"3319570455","title":"Algorithmic Aspects of Cloud Computing","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=-i2lDgAAQBAJ&source=gbs_api","authors":["Timos Sellis","Konstantinos Oikonomou"]},{"pageCount":668,"thumbnail":"http:\/\/books.google.com\/books\/content?id=QFqxDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":19.79,"subtitle":"Build and deploy Java microservices using Spring Cloud, Istio, and Kubernetes","description":"Apply microservices patterns to build resilient and scalable distributed systems Key Features Understand the challenges of building large-scale microservice landscapes Build cloud-native production-ready microservices with this comprehensive guide Discover how to get the best out of Spring Cloud, Kubernetes, and Istio when used together Book Description Microservices architecture allows developers to build and maintain applications with ease, and enterprises are rapidly adopting it to build software using Spring Boot as their default framework. With this book, you\u2019ll learn how to efficiently build and deploy microservices using Spring Boot. This microservices book will take you through tried and tested approaches to building distributed systems and implementing microservices architecture in your organization. Starting with a set of simple cooperating microservices developed using Spring Boot, you\u2019ll learn how you can add functionalities such as persistence, make your microservices reactive, and describe their APIs using Swagger\/OpenAPI. As you advance, you\u2019ll understand how to add different services from Spring Cloud to your microservice system. The book also demonstrates how to deploy your microservices using Kubernetes and manage them with Istio for improved security and traffic management. Finally, you\u2019ll explore centralized log management using the EFK stack and monitor microservices using Prometheus and Grafana. By the end of this book, you\u2019ll be able to build microservices that are scalable and robust using Spring Boot and Spring Cloud. What you will learn Build reactive microservices using Spring Boot Develop resilient and scalable microservices using Spring Cloud Use OAuth 2.0\/OIDC and Spring Security to protect public APIs Implement Docker to bridge the gap between development, testing, and production Deploy and manage microservices using Kubernetes Apply Istio for improved security, observability, and traffic management Who this book is for This book is for Java and Spring developers and architects who want to learn how to break up their existing monoliths into microservices and deploy them either on-premises or in the cloud using Kubernetes as a container orchestrator and Istio as a service Mesh. No familiarity with microservices architecture is required to get started with this book.","language":"en","currency":"USD","id":"1789613523","title":"Hands-On Microservices with Spring Boot and Spring Cloud","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=QFqxDwAAQBAJ&source=gbs_api","authors":["Magnus Larsson"]},{"pageCount":140,"thumbnail":"http:\/\/books.google.com\/books\/content?id=EaTPDQAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":16.19,"subtitle":"An SQL Driver for HBase","description":"Leverage Phoenix as an ANSI SQL engine built on top of the highly distributed and scalable NoSQL framework HBase. Learn the basics and best practices that are being adopted in Phoenix to enable a high write and read throughput in a big data space. This book includes real-world cases such as Internet of Things devices that send continuous streams to Phoenix, and the book explains how key features such as joins, indexes, transactions, and functions help you understand the simple, flexible, and powerful API that Phoenix provides. Examples are provided using real-time data and data-driven businesses that show you how to collect, analyze, and act in seconds. Pro Apache Phoenix covers the nuances of setting up a distributed HBase cluster with Phoenix libraries, running performance benchmarks, configuring parameters for production scenarios, and viewing the results. The book also shows how Phoenix plays well with other key frameworks in the Hadoop ecosystem such as Apache Spark, Pig, Flume, and Sqoop. You will learn how to: Handle a petabyte data store by applying familiar SQL techniques Store, analyze, and manipulate data in a NoSQL Hadoop echo system with HBase Apply best practices while working with a scalable data store on Hadoop and HBase Integrate popular frameworks (Apache Spark, Pig, Flume) to simplify big data analysis Demonstrate real-time use cases and big data modeling techniques Who This Book Is For Data engineers, Big Data administrators, and architects.","language":"en","currency":"USD","id":"1484223705","title":"Pro Apache Phoenix","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=EaTPDQAAQBAJ&source=gbs_api","authors":["Shakil Akhtar","Ravi Magham"]},{"pageCount":128,"thumbnail":"http:\/\/books.google.com\/books\/content?id=lSHlCwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":14.59,"subtitle":null,"description":"Over 50 hands-on recipes to efficiently administer, maintain, and use your Apache Kafka installation About This Book Quickly configure and manage your Kafka cluster Learn how to use the Apache Kafka cluster and connect it with tools for big data processing A practical guide to monitor your Apache Kafka installation Who This Book Is For If you are a programmer or big data engineer using or planning to use Apache Kafka, then this book is for you. This book has several recipes which will teach you how to effectively use Apache Kafka. You need to have some basic knowledge of Java. If you don't know big data tools, this would be your stepping stone for learning how to consume the data in these kind of systems. What You Will Learn Learn how to configure Kafka brokers for better efficiency Explore how to configure producers and consumers for optimal performance Set up tools for maintaining and operating Apache Kafka Create producers and consumers for Apache Kafka in Java Understand how Apache Kafka can be used by several third party system for big data processing, such as Apache Storm, Apache Spark, Hadoop, and more Monitor Apache Kafka using tools like graphite and Ganglia In Detail This book will give you details about how to manage and administer your Apache Kafka Cluster. We will cover topics like how to configure your broker, producer, and consumer for maximum efficiency for your situation. Also, you will learn how to maintain and administer your cluster for fault tolerance. We will also explore tools provided with Apache Kafka to do regular maintenance operations. We shall also look at how to easily integrate Apache Kafka with big data tools like Hadoop, Apache Spark, Apache Storm, and Elasticsearch. Style and approach Easy-to-follow, step-by-step recipes explaining from start to finish how to accomplish real-world tasks.","language":"en","currency":"USD","id":"1785880187","title":"Apache Kafka Cookbook","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=lSHlCwAAQBAJ&source=gbs_api","authors":["Saurabh Minni"]},{"pageCount":378,"thumbnail":"http:\/\/books.google.com\/books\/content?id=A1AoDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":31.19,"subtitle":null,"description":"Master over 60 recipes to help you deliver complete, scalable, microservice-based solutions and see the improved business results immediately About This Book Adopt microservices-based architecture and deploy it at scale Build your complete microservice architecture using different recipes for different solutions Identify specific tools for specific scenarios and deliver immediate business results, correlate use cases, and adopt them in your team and organization Who This Book Is For This book is for developers, ops, and DevOps professionals who would like to put microservices to work and improve products, services, and operations. Those looking to build and deploy microservices will find this book useful, as well as managers and people at CXO level looking to adopt microservices in their organization. Prior knowledge of Java is expected. No prior knowledge of microservices is assumed. What You Will Learn Build microservices using Spring Boot, Wildfly Swarm, Dropwizard, and SparkJava Containerize your microservice using Docker Deploy microservices using Mesos\/Marathon and Kubernetes Implement service discovery and load balancing using Zookeeper, Consul, and Nginx Monitor microservices using Graphite and Grafana Write stream programs with Kafka Streams and Spark Aggregate and manage logs using Kafka Get introduced to DC\/OS, Docker Swarm, and YARN In Detail This book will help any team or organization understand, deploy, and manage microservices at scale. It is driven by a sample application, helping you gradually build a complete microservice-based ecosystem. Rather than just focusing on writing a microservice, this book addresses various other microservice-related solutions: deployments, clustering, load balancing, logging, streaming, and monitoring. The initial chapters offer insights into how web and enterprise apps can be migrated to scalable microservices. Moving on, you'll see how to Dockerize your application so that it is ready to be shipped and deployed. We will look at how to deploy microservices on Mesos and Marathon and will also deploy microservices on Kubernetes. Next, you will implement service discovery and load balancing for your microservices. We'll also show you how to build asynchronous streaming systems using Kafka Streams and Apache Spark. Finally, we wind up by aggregating your logs in Kafka, creating your own metrics, and monitoring the metrics for the microservice. Style and approach This book follows a recipe-driven approach and shows you how to plug and play with all the various pieces, putting them together to build a complete scalable microservice ecosystem. You do not need to study the chapters in order, as you can directly refer to the content you need for your situation.","language":"en","currency":"USD","id":"1786461315","title":"Microservices Deployment Cookbook","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=A1AoDwAAQBAJ&source=gbs_api","authors":["Vikram Murugesan"]},{"pageCount":44,"thumbnail":"http:\/\/books.google.com\/books\/content?id=LEUqDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":0,"subtitle":null,"description":"There has been a considerable focus on performance improvements as one of the main themes in recent IBM DB2® releases, and DB2 12 for IBM z\/OS® is certainly no exception. With the high-value data retained on DB2 for z\/OS and the z Systems platform, customers are increasingly attempting to extract value from that data for competitive advantage. Although customers have historically moved data off platform to gain insight, the landscape has changed significantly and allowed z Systems to again converge operational systems with analytics for real-time insight. Business-critical analytics is now requiring the same levels of service as expected for operational systems, and real-time or near real-time currency of data is expected. Hence the resurgence of z Systems. As a precursor to this shift, IDAA brought the data warehouse back to DB2 for z\/OS and, with its tight integration with DB2, significantly reduces data latency as compared to the ETL processing that is involved with moving data to a stand-alone data warehouse environment. That change has opened up new opportunities for operational systems to extend the breadth of analytics processing without affecting the mission-critical system and integrating near real-time analytics within that system, all while maintaining the same z Systems qualities of service. Apache Spark on z\/OS and Linux for System z also allow analytics in-place, in real-time or near real-time. Enabling Spark natively on z Systems reduces the security risk of multiple copies of the Enterprise data, while providing an application developer-friendly platform for faster insight in a simplified and more secure analytics framework. How is all of this relevant to DB2 for z\/OS? Given that z Systems is proving again to be the core Enterprise Hybrid Transactional\/Analytical Processing (HTAP) system, it is critical that DB2 for z\/OS can handle its traditional transactional applications and address the requirements for analytics processing that might not be candidates for these rapidly evolving targeted analytics systems. And not only are there opportunities for DB2 for z\/OS to play an increasing role in analytics, the complexity of the transactional systems is increasing. Analytics is being integrated within the scope of those transactions. DB2 12 for z\/OS has targeted performance to increase the success of new application deployments and integration of analytics to ensure that we keep pace with the rapid evolution of IDAA and Spark as equal partners in HTAP systems. This paper describes the enhancements delivered specifically by the query processing engine of DB2. This engine is generally called the optimizer or the Relational Data Services (RDS) components, which encompasses the query transformation, access path selection, run time, and parallelism. DB2 12 for z\/OS also delivers improvements targeted at OLTP applications, which are the realm of the Data Manager, Index Manager, and Buffer Manager components (to name a few), and are not identified here. Although the performance measurement focus is based on reducing CPU, improvement in elapsed time is likely to be similarly achieved as CPU is reduced and performance constraints alleviated. However, elapsed time improvements can be achieved with parallelism, and DB2 12 does increase the percentage offload for parallel child tasks, which can further reduce chargeable CPU for analytics workloads.","language":"en","currency":"USD","id":"0738456128","title":"DB2 12 for z Optimizer","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=LEUqDwAAQBAJ&source=gbs_api","authors":["Terry Purcell","IBM Redbooks"]},{"pageCount":592,"thumbnail":"http:\/\/books.google.com\/books\/content?id=FWvoCgAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":19.79,"subtitle":null,"description":"Sams Teach Yourself Big Data Analytics with Microsoft HDInsight in 24 Hours In just 24 lessons of one hour or less, Sams Teach Yourself Big Data Analytics with Microsoft HDInsight in 24 Hours helps you leverage Hadoop\u2019s power on a flexible, scalable cloud platform using Microsoft\u2019s newest business intelligence, visualization, and productivity tools. This book\u2019s straightforward, step-by-step approach shows you how to provision, configure, monitor, and troubleshoot HDInsight and use Hadoop cloud services to solve real analytics problems. You\u2019ll gain more of Hadoop\u2019s benefits, with less complexity\u2013even if you\u2019re completely new to Big Data analytics. Every lesson builds on what you\u2019ve already learned, giving you a rock-solid foundation for real-world success. Practical, hands-on examples show you how to apply what you learn Quizzes and exercises help you test your knowledge and stretch your skills Notes and tips point out shortcuts and solutions Learn how to\u2026 · Master core Big Data and NoSQL concepts, value propositions, and use cases · Work with key Hadoop features, such as HDFS2 and YARN · Quickly install, configure, and monitor Hadoop (HDInsight) clusters in the cloud · Automate provisioning, customize clusters, install additional Hadoop projects, and administer clusters · Integrate, analyze, and report with Microsoft BI and Power BI · Automate workflows for data transformation, integration, and other tasks · Use Apache HBase on HDInsight · Use Sqoop or SSIS to move data to or from HDInsight · Perform R-based statistical computing on HDInsight datasets · Accelerate analytics with Apache Spark · Run real-time analytics on high-velocity data streams · Write MapReduce, Hive, and Pig programs Register your book at informit.com\/register for convenient access to downloads, updates, and corrections as they become available.","language":"en","currency":"USD","id":"013403533X","title":"Big Data Analytics with Microsoft HDInsight in 24 Hours, Sams Teach Yourself","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=FWvoCgAAQBAJ&source=gbs_api","authors":["Manpreet Singh","Arshad Ali"]},{"pageCount":330,"thumbnail":"http:\/\/books.google.com\/books\/content?id=RqegDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":34.99,"subtitle":"Teaching Machines to Paint, Write, Compose, and Play","description":"Generative modeling is one of the hottest topics in AI. It\u2019s now possible to teach a machine to excel at human endeavors such as painting, writing, and composing music. With this practical book, machine-learning engineers and data scientists will discover how to re-create some of the most impressive examples of generative deep learning models, such as variational autoencoders,generative adversarial networks (GANs), encoder-decoder models and world models. Author David Foster demonstrates the inner workings of each technique, starting with the basics of deep learning before advancing to some of the most cutting-edge algorithms in the field. Through tips and tricks, you\u2019ll understand how to make your models learn more efficiently and become more creative. Discover how variational autoencoders can change facial expressions in photos Build practical GAN examples from scratch, including CycleGAN for style transfer and MuseGAN for music generation Create recurrent generative models for text generation and learn how to improve the models using attention Understand how generative models can help agents to accomplish tasks within a reinforcement learning setting Explore the architecture of the Transformer (BERT, GPT-2) and image generation models such as ProGAN and StyleGAN","language":"en","currency":"USD","id":"1492041890","title":"Generative Deep Learning","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=RqegDwAAQBAJ&source=gbs_api","authors":["David Foster"]},{"pageCount":324,"thumbnail":"http:\/\/books.google.com\/books\/content?id=GpoKZncgCxsC&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":16.54,"subtitle":null,"description":"Over 150 recipes to design and optimize large scale Apache Cassandra deployments.","language":"en","currency":"USD","id":"1849515131","title":"Cassandra High Performance Cookbook","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=GpoKZncgCxsC&source=gbs_api","authors":["Edward Capriolo"]},{"pageCount":326,"thumbnail":"http:\/\/books.google.com\/books\/content?id=1VlLDAAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":22.39,"subtitle":null,"description":"Design, process, and analyze large sets of complex data in real time About This Book Get acquainted with transformations and database-level interactions, and ensure the reliability of messages processed using Storm Implement strategies to solve the challenges of real-time data processing Load datasets, build queries, and make recommendations using Spark SQL Who This Book Is For If you are a Big Data architect, developer, or a programmer who wants to develop applications\/frameworks to implement real-time analytics using open source technologies, then this book is for you. What You Will Learn Explore big data technologies and frameworks Work through practical challenges and use cases of real-time analytics versus batch analytics Develop real-word use cases for processing and analyzing data in real-time using the programming paradigm of Apache Storm Handle and process real-time transactional data Optimize and tune Apache Storm for varied workloads and production deployments Process and stream data with Amazon Kinesis and Elastic MapReduce Perform interactive and exploratory data analytics using Spark SQL Develop common enterprise architectures\/applications for real-time and batch analytics In Detail Enterprise has been striving hard to deal with the challenges of data arriving in real time or near real time. Although there are technologies such as Storm and Spark (and many more) that solve the challenges of real-time data, using the appropriate technology\/framework for the right business use case is the key to success. This book provides you with the skills required to quickly design, implement and deploy your real-time analytics using real-world examples of big data use cases. From the beginning of the book, we will cover the basics of varied real-time data processing frameworks and technologies. We will discuss and explain the differences between batch and real-time processing in detail, and will also explore the techniques and programming concepts using Apache Storm. Moving on, we'll familiarize you with \u201CAmazon Kinesis\u201D for real-time data processing on cloud. We will further develop your understanding of real-time analytics through a comprehensive review of Apache Spark along with the high-level architecture and the building blocks of a Spark program. You will learn how to transform your data, get an output from transformations, and persist your results using Spark RDDs, using an interface called Spark SQL to work with Spark. At the end of this book, we will introduce Spark Streaming, the streaming library of Spark, and will walk you through the emerging Lambda Architecture (LA), which provides a hybrid platform for big data processing by combining real-time and precomputed batch data to provide a near real-time view of incoming data. Style and approach This step-by-step is an easy-to-follow, detailed tutorial, filled with practical examples of basic and advanced features. Each topic is explained sequentially and supported by real-world examples and executable code snippets.","language":"en","currency":"USD","id":"1784397407","title":"Real-Time Big Data Analytics","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=1VlLDAAAQBAJ&source=gbs_api","authors":["Sumit Gupta","Shilpi,"]},{"pageCount":null,"thumbnail":"http:\/\/books.google.com\/books\/content?id=X-cZEAAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":40,"subtitle":null,"description":"This self-study resource offers complete coverage of every topic on the AWS Certified Security Specialty exam Take the AWS Certified Security \u2013 Specialty exam with confidence using the detailed information contained in this effective self-study resource. Written by a team of AWS insiders, the book shows how to develop, deploy, and maintain robust security protocols on Amazon Web Services. AWS Certified Security Specialty All-in-One Exam Guide (Exam SCS-C01) covers every objective for the exam and provides comprehensive content on cloud-based security. To aid in study, each chapter includes exam tips, chapter summaries, and practice questions that simulate those on the live test. Designed to help you pass the exam with ease, this hands-on guide also serves as an ideal on-the-job reference. Covers all exam topics, including: Cloud security event investigation Cloud security event remediation and planning Monitoring with Amazon CloudWatch Enhanced security monitoring and compliance with AWS services Logging on AWS AWS cryptographic services and tools Designing edge security on AWS Designing and implementing a secure network infrastructure Troubleshooting a secure network infrastructure Designing and implementing host-based security AWS identity and access management Troubleshooting authorization and authentication services Online content includes: 130 practice exam questions Fully customizable exam engine Downloadable code","language":"en","currency":"USD","id":"1260461734","title":"AWS Certified Security Specialty All-in-One Exam Guide (Exam SCS-C01)","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=X-cZEAAAQBAJ&source=gbs_api","authors":["Tracy Pierce","Aravind Kodandaramaiah","Rafael Koike","Alex Rosa"]},{"pageCount":298,"thumbnail":"http:\/\/books.google.com\/books\/content?id=faPPDQAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":31.19,"subtitle":"Designing and Building Big Data Systems using the Hadoop Ecosystem","description":"Learn advanced analytical techniques and leverage existing tool kits to make your analytic applications more powerful, precise, and efficient. This book provides the right combination of architecture, design, and implementation information to create analytical systems that go beyond the basics of classification, clustering, and recommendation. Pro Hadoop Data Analytics emphasizes best practices to ensure coherent, efficient development. A complete example system will be developed using standard third-party components that consist of the tool kits, libraries, visualization and reporting code, as well as support glue to provide a working and extensible end-to-end system. The book also highlights the importance of end-to-end, flexible, configurable, high-performance data pipeline systems with analytical components as well as appropriate visualization results. You'll discover the importance of mix-and-match or hybrid systems, using different analytical components in one application. This hybrid approach will be prominent in the examples. What You'll Learn Build big data analytic systems with the Hadoop ecosystem Use libraries, tool kits, and algorithms to make development easier and more effective Apply metrics to measure performance and efficiency of components and systems Connect to standard relational databases, noSQL data sources, and more Follow case studies with example components to create your own systems Who This Book Is For Software engineers, architects, and data scientists with an interest in the design and implementation of big data analytical systems using Hadoop, the Hadoop ecosystem, and other associated technologies.","language":"en","currency":"USD","id":"1484219104","title":"Pro Hadoop Data Analytics","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=faPPDQAAQBAJ&source=gbs_api","authors":["Kerry Koitzsch"]},{"pageCount":457,"thumbnail":"http:\/\/books.google.com\/books\/content?id=dEqzDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":19.24,"subtitle":"A Practical Implementation Guide to Predictive Data Analytics Using Python","description":"Explore fundamental to advanced Python 3 topics in six steps, all designed to make you a worthy practitioner. This updated version\u2019s approach is based on the \u201Csix degrees of separation\u201D theory, which states that everyone and everything is a maximum of six steps away and presents each topic in two parts: theoretical concepts and practical implementation using suitable Python 3 packages. You\u2019ll start with the fundamentals of Python 3 programming language, machine learning history, evolution, and the system development frameworks. Key data mining\/analysis concepts, such as exploratory analysis, feature dimension reduction, regressions, time series forecasting and their efficient implementation in Scikit-learn are covered as well. You\u2019ll also learn commonly used model diagnostic and tuning techniques. These include optimal probability cutoff point for class creation, variance, bias, bagging, boosting, ensemble voting, grid search, random search, Bayesian optimization, and the noise reduction technique for IoT data. Finally, you\u2019ll review advanced text mining techniques, recommender systems, neural networks, deep learning, reinforcement learning techniques and their implementation. All the code presented in the book will be available in the form of iPython notebooks to enable you to try out these examples and extend them to your advantage. What You'll Learn Understand machine learning development and frameworks Assess model diagnosis and tuning in machine learning Examine text mining, natuarl language processing (NLP), and recommender systems Review reinforcement learning and CNN Who This Book Is For Python developers, data engineers, and machine learning engineers looking to expand their knowledge or career into machine learning area.","language":"en","currency":"USD","id":"148424947X","title":"Mastering Machine Learning with Python in Six Steps","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=dEqzDwAAQBAJ&source=gbs_api","authors":["Manohar Swamynathan"]},{"pageCount":488,"thumbnail":"http:\/\/books.google.com\/books\/content?id=O4wwDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":67.99,"subtitle":"19th International Conference, DaWaK 2017, Lyon, France, August 28\u201331, 2017, Proceedings","description":"This book constitutes the refereed proceedings of the 19th International Conference on Big Data Analytics and Knowledge Discovery, DaWaK 2017, held in Lyon, France, in August 2017. The 24 revised full papers and 11 short papers presented were carefully reviewed and selected from 97 submissions. The papers are organized in the following topical sections: new generation data warehouses design; cloud and NoSQL databases; advanced programming paradigms; non-functional requirements satisfaction; machine learning; social media and twitter analysis; sentiment analysis and user influence; knowledge discovery; and data flow management and optimization.","language":"en","currency":"USD","id":"3319642839","title":"Big Data Analytics and Knowledge Discovery","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=O4wwDwAAQBAJ&source=gbs_api","authors":["Ladjel Bellatreche","Sharma Chakravarthy"]},{"pageCount":340,"thumbnail":"http:\/\/books.google.com\/books\/content?id=oQZnDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":19.79,"subtitle":"Develop scalable, data-intensive, and robust applications the smart way","description":"Architect and design data-intensive applications and, in the process, learn how to collect, process, store, govern, and expose data for a variety of use cases Key Features Integrate the data-intensive approach into your application architecture Create a robust application layout with effective messaging and data querying architecture Enable smooth data flow and make the data of your application intensive and fast Book Description Are you an architect or a developer who looks at your own applications gingerly while browsing through Facebook and applauding it silently for its data-intensive, yet fluent and efficient, behaviour? This book is your gateway to build smart data-intensive systems by incorporating the core data-intensive architectural principles, patterns, and techniques directly into your application architecture. This book starts by taking you through the primary design challenges involved with architecting data-intensive applications. You will learn how to implement data curation and data dissemination, depending on the volume of your data. You will then implement your application architecture one step at a time. You will get to grips with implementing the correct message delivery protocols and creating a data layer that doesn\u2019t fail when running high traffic. This book will show you how you can divide your application into layers, each of which adheres to the single responsibility principle. By the end of this book, you will learn to streamline your thoughts and make the right choice in terms of technologies and architectural principles based on the problem at hand. What you will learn Understand how to envision a data-intensive system Identify and compare the non-functional requirements of a data collection component Understand patterns involving data processing, as well as technologies that help to speed up the development of data processing systems Understand how to implement Data Governance policies at design time using various Open Source Tools Recognize the anti-patterns to avoid while designing a data store for applications Understand the different data dissemination technologies available to query the data in an efficient manner Implement a simple data governance policy that can be extended using Apache Falcon Who this book is for This book is for developers and data architects who have to code, test, deploy, and\/or maintain large-scale, high data volume applications. It is also useful for system architects who need to understand various non-functional aspects revolving around Data Intensive Systems.","language":"en","currency":"USD","id":"1785884204","title":"Architecting Data-Intensive Applications","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=oQZnDwAAQBAJ&source=gbs_api","authors":["Anuj Kumar"]},{"pageCount":448,"thumbnail":"http:\/\/books.google.com\/books\/content?id=udgtAAAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":31.19,"subtitle":null,"description":"Scala is a modern programming language for the Java Virtual Machine (JVM) that combines the best features of object-oriented and functional programming languages. Using Scala, you can write programs more concisely than in Java, as well as leverage the full power of concurrency. Since Scala runs on the JVM, it can access any Java library and is interoperable with Java frameworks. Scala for the Impatient concisely shows developers what Scala can do and how to do it. In this book, Cay Horstmann, the principal author of the international best-selling Core Java™, offers a rapid, code-based introduction that\u2019s completely practical. Horstmann introduces Scala concepts and techniques in \u201Cblog-sized\u201D chunks that you can quickly master and apply. Hands-on activities guide you through well-defined stages of competency, from basic to expert. Coverage includes Getting started quickly with Scala\u2019s interpreter, syntax, tools, and unique idioms Mastering core language features: functions, arrays, maps, tuples, packages, imports, exception handling, and more Becoming familiar with object-oriented programming in Scala: classes, inheritance, and traits Using Scala for real-world programming tasks: working with files, regular expressions, and XML Working with higher-order functions and the powerful Scala collections library Leveraging Scala\u2019s powerful pattern matching and case classes Creating concurrent programs with Scala actors Implementing domain-specific languages Understanding the Scala type system Applying advanced \u201Cpower tools\u201D such as annotations, implicits, and delimited continuations Scala is rapidly reaching a tipping point that will reshape the experience of programming. This book will help object-oriented programmers build on their existing skills, allowing them to immediately construct useful applications as they gradually master advanced programming techniques.","language":"en","currency":"USD","id":"0132761807","title":"Scala for the Impatient","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=udgtAAAAQBAJ&source=gbs_api","authors":["Cay S. Horstmann"]},{"pageCount":null,"thumbnail":"http:\/\/books.google.com\/books\/content?id=BCEOEAAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":40,"subtitle":null,"description":"This up-to-date study guide offers 100% coverage of every objective for the current version of the AWS Certified Solutions Architect Professional exam Get complete coverage of all objectives included on the SAA-C02 exam from this comprehensive resource. Written by an expert AWS Solutions Architect and well-respected author, this authoritative guide fully addresses the knowledge and skills required for passing the AWS Certified Solutions Architect \u2013 Associate exam. You\u2019ll find learning objectives at the beginning of each chapter, exam tips, practice exam questions, and in-depth explanations. You\u2019ll also build your practical knowledge with the many hands-on labs found throughout this guide. Designed to help you pass the exam with ease, this definitive volume also serves as an essential on-the-job reference. Covers all exam domains, including: Design Resilient Architectures Design High-Performing Architectures Design Secure Applications and Architectures Design Cost-Optimized Architectures Online content includes: 130 practice exam questions Test engine that provides practice exams or quizzes that can be customized by chapter or exam objective","language":"en","currency":"USD","id":"1260470199","title":"AWS Certified Solutions Architect Associate All-in-One Exam Guide, Second Edition (Exam SAA-C02)","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=BCEOEAAAQBAJ&source=gbs_api","authors":["Joyjeet Banerjee"]},{"pageCount":254,"thumbnail":"http:\/\/books.google.com\/books\/content?id=qPt_CwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":22.39,"subtitle":null,"description":"Navigate the world of data analysis, visualization, and machine learning with over 100 hands-on Scala recipes About This Book Implement Scala in your data analysis using features from Spark, Breeze, and Zeppelin Scale up your data anlytics infrastructure with practical recipes for Scala machine learning Recipes for every stage of the data analysis process, from reading and collecting data to distributed analytics Who This Book Is For This book shows data scientists and analysts how to leverage their existing knowledge of Scala for quality and scalable data analysis. What You Will Learn Familiarize and set up the Breeze and Spark libraries and use data structures Import data from a host of possible sources and create dataframes from CSV Clean, validate and transform data using Scala to pre-process numerical and string data Integrate quintessential machine learning algorithms using Scala stack Bundle and scale up Spark jobs by deploying them into a variety of cluster managers Run streaming and graph analytics in Spark to visualize data, enabling exploratory analysis In Detail This book will introduce you to the most popular Scala tools, libraries, and frameworks through practical recipes around loading, manipulating, and preparing your data. It will also help you explore and make sense of your data using stunning and insightfulvisualizations, and machine learning toolkits. Starting with introductory recipes on utilizing the Breeze and Spark libraries, get to grips withhow to import data from a host of possible sources and how to pre-process numerical, string, and date data. Next, you'll get an understanding of concepts that will help you visualize data using the Apache Zeppelin and Bokeh bindings in Scala, enabling exploratory data analysis. iscover how to program quintessential machine learning algorithms using Spark ML library. Work through steps to scale your machine learning models and deploy them into a standalone cluster, EC2, YARN, and Mesos. Finally dip into the powerful options presented by Spark Streaming, and machine learning for streaming data, as well as utilizing Spark GraphX. Style and approach This book contains a rich set of recipes that covers the full spectrum of interesting data analysis tasks and will help you revolutionize your data analysis skills using Scala and Spark.","language":"en","currency":"USD","id":"1784394998","title":"Scala Data Analysis Cookbook","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=qPt_CwAAQBAJ&source=gbs_api","authors":["Arun Manivannan"]},{"pageCount":578,"thumbnail":"http:\/\/books.google.com\/books\/content?id=nvZ0DwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":87.2,"subtitle":"Second International Conference, ICACDS 2018, Dehradun, India, April 20-21, 2018, Revised Selected Papers","description":"This two-volume set (CCIS 905 and CCIS 906) constitutes the refereed proceedings of the Second International Conference on Advances in Computing and Data Sciences, ICACDS 2018, held in Dehradun, India, in April 2018. The 110 full papers were carefully reviewed and selected from 598 submissions. The papers are centered around topics like advanced computing, data sciences, distributed systems organizing principles, development frameworks and environments, software verification and validation, computational complexity and cryptography, machine learning theory, database theory, probabilistic representations.","language":"en","currency":"USD","id":"9811318131","title":"Advances in Computing and Data Sciences","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=nvZ0DwAAQBAJ&source=gbs_api","authors":["Mayank Singh","P. K. Gupta","Vipin Tyagi","Jan Flusser","Tuncer Ören"]},{"pageCount":352,"thumbnail":"http:\/\/books.google.com\/books\/content?id=iNHcDgAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":31.19,"subtitle":null,"description":"Learn to get the most out of your business data to optimize your business About This Book This book will enable and empower you to break free of the shackles of spreadsheets Learn to make informed decisions using the data at hand with this highly practical, comprehensive guide This book includes real-world use cases that teach you how analytics can be put to work to optimize your business Using a fictional transactional dataset in raw form, you'll work your way up to ultimately creating a fully-functional warehouse and a fleshed-out BI platform Who This Book Is For This book is for anyone who has wrangled with data to try to perform automated data analysis through visualizations for themselves or their customers. This highly-customized guide is for developers who know a bit about analytics but don't know how to make use of it in the field of business intelligence. What You Will Learn Create a BI environment that enables self-service reporting Understand SQL and the aggregation of data Develop a data model suitable for analytical reporting Connect a data warehouse to the analytic reporting tools Understand the specific benefits behind visualizations with D3.js, R, Tableau, QlikView, and Python Get to know the best practices to develop various reports and applications when using BI tools Explore the field of data analysis with all the data we will use for reporting In Detail Business Intelligence (BI) is at the crux of revolutionizing enterprise. Everyone wants to minimize losses and maximize profits. Thanks to Big Data and improved methodologies to analyze data, Data Analysts and Data Scientists are increasingly using data to make informed decisions. Just knowing how to analyze data is not enough, you need to start thinking how to use data as a business asset and then perform the right analysis to build an insightful BI solution. Efficient BI strives to achieve the automation of data for ease of reporting and analysis. Through this book, you will develop the ability to think along the right lines and use more than one tool to perform analysis depending on the needs of your business. We start off by preparing you for data analytics. We then move on to teach you a range of techniques to fetch important information from various databases, which can be used to optimize your business. The book aims to provide a full end-to-end solution for an environment setup that can help you make informed business decisions and deliver efficient and automated BI solutions to any company. It is a complete guide for implementing Business intelligence with the help of the most powerful tools like D3.js, R, Tableau, Qlikview and Python that are available on the market. Style and approach Packed with real-world examples, this pragmatic guide helps you polish your data and make informed decisions for your business. We cover both business and data analysis perspectives, blending theory and practical hands-on work so that you perceive data as a business asset.","language":"en","currency":"USD","id":"1785889974","title":"Practical Business Intelligence","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=iNHcDgAAQBAJ&source=gbs_api","authors":["Ahmed Sherif"]},{"pageCount":288,"thumbnail":"http:\/\/books.google.com\/books\/content?id=CO1FDAAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":16.19,"subtitle":"An Introduction for Data Scientists","description":"Ready to use statistical and machine-learning techniques across large data sets? This practical guide shows you why the Hadoop ecosystem is perfect for the job. Instead of deployment, operations, or software development usually associated with distributed computing, you\u2019ll focus on particular analyses you can build, the data warehousing techniques that Hadoop provides, and higher order data workflows this framework can produce. Data scientists and analysts will learn how to perform a wide range of techniques, from writing MapReduce and Spark applications with Python to using advanced modeling and data management with Spark MLlib, Hive, and HBase. You\u2019ll also learn about the analytical processes and data systems available to build and empower data products that can handle\u2014and actually require\u2014huge amounts of data. Understand core concepts behind Hadoop and cluster computing Use design patterns and parallel analytical algorithms to create distributed data analysis jobs Learn about data management, mining, and warehousing in a distributed context using Apache Hive and HBase Use Sqoop and Apache Flume to ingest data from relational databases Program complex Hadoop and Spark applications with Apache Pig and Spark DataFrames Perform machine learning techniques such as classification, clustering, and collaborative filtering with Spark\u2019s MLlib","language":"en","currency":"USD","id":"1491913754","title":"Data Analytics with Hadoop","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=CO1FDAAAQBAJ&source=gbs_api","authors":["Benjamin Bengfort","Jenny Kim"]},{"pageCount":190,"thumbnail":"http:\/\/books.google.com\/books\/content?id=IA1rDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":31.44,"subtitle":"Managing Successful Data Projects","description":"While many companies ponder implementation details such as distributed processing engines and algorithms for data analysis, this practical book takes a much wider view of big data development, starting with initial planning and moving diligently toward execution. Authors Ted Malaska and Jonathan Seidman guide you through the major components necessary to start, architect, and develop successful big data projects. Everyone from CIOs and COOs to lead architects and developers will explore a variety of big data architectures and applications, from massive data pipelines to web-scale applications. Each chapter addresses a piece of the software development life cycle and identifies patterns to maximize long-term success throughout the life of your project. Start the planning process by considering the key data project types Use guidelines to evaluate and select data management solutions Reduce risk related to technology, your team, and vague requirements Explore system interface design using APIs, REST, and pub\/sub systems Choose the right distributed storage system for your big data system Plan and implement metadata collections for your data architecture Use data pipelines to ensure data integrity from source to final storage Evaluate the attributes of various engines for processing the data you collect","language":"en","currency":"USD","id":"1492038695","title":"Foundations for Architecting Data Solutions","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=IA1rDwAAQBAJ&source=gbs_api","authors":["Ted Malaska","Jonathan Seidman"]},{"pageCount":560,"thumbnail":"http:\/\/books.google.com\/books\/content?id=o-VoDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":79.2,"subtitle":"Third International Conference, BDCA 2018, Kenitra, Morocco, April 4\u20135, 2018, Revised Selected Papers","description":"This book constitutes the thoroughly refereed proceedings of the Third International Conference on Big Data, Cloud and Applications, BDCA 2018, held in Kenitra, Morocco, in April 2018.The 45 revised full papers presented in this book were carefully selected from 99 submissions with a thorough double-blind review process. They focus on the following topics: big data, cloud computing, machine learning, deep learning, data analysis, neural networks, information system and social media, image processing and applications, and natural language processing.","language":"en","currency":"USD","id":"3319962922","title":"Big Data, Cloud and Applications","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=o-VoDwAAQBAJ&source=gbs_api","authors":["Youness Tabii","Mohamed Lazaar","Mohammed Al Achhab","Nourddine Enneya"]},{"pageCount":546,"thumbnail":"http:\/\/books.google.com\/books\/content?id=2i8tDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":69.42,"subtitle":"Second International Conference, DMBD 2017, Fukuoka, Japan, July 27 \u2013 August 1, 2017, Proceedings","description":"This book constitutes the refereed proceedings of the Second International Conference on Data Mining and Big Data, DMBD 2017, held in Fukuoka, Japan, in July\/August 2017. The 53 papers presented in this volume were carefully reviewed and selected from 96 submissions. They were organized in topical sections named: association analysis; clustering; prediction; classification; schedule and sequence analysis; big data; data analysis; data mining; text mining; deep learning; high performance computing; knowledge base and its framework; and fuzzy control.","language":"en","currency":"USD","id":"3319618458","title":"Data Mining and Big Data","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=2i8tDwAAQBAJ&source=gbs_api","authors":["Ying Tan","Hideyuki Takagi","Yuhui Shi"]},{"pageCount":560,"thumbnail":"http:\/\/books.google.com\/books\/content?id=kdEAEAAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":40,"subtitle":null,"description":"This study guide offers 100% coverage of every objective for the Google Cloud Certified Associate Cloud Engineer exam Take the challenging Google Cloud Certified Associate Cloud Engineer exam with confidence using the comprehensive information contained in this effective self-study guide. The book serves as an introduction to Google Cloud Platform (GCP) and shows you how to pass the test. Beyond exam preparation, the guide also serves as a valuable on-the-job reference. Written by a recognized expert in the field, Google Cloud Certified Associate Cloud Engineer All-In-One Exam Guide is based on proven pedagogy and features special elements that teach and reinforce practical skills. The book contains accurate practice questions and detailed explanations. You will discover how to plan set up, and configure GCP; ensure effective operation; and administer access and security. Covers every topic on the exam\u2014demonstrated through exercises, sample exams, and practice use cases Provides online access to TotalTester customizable exam engine with additional practice questions Written by a cloud computing expert, educator, and experienced author","language":"en","currency":"USD","id":"1260473465","title":"Google Cloud Certified Associate Cloud Engineer All-in-One Exam Guide","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=kdEAEAAAQBAJ&source=gbs_api","authors":["Jack Hyman"]},{"pageCount":216,"thumbnail":"http:\/\/books.google.com\/books\/content?id=vzfVDQAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":116,"subtitle":null,"description":"The growing presence of smart phones and smart devices has caused significant changes to wireless networks. With the ubiquity of these technologies, there is now increasingly more available data for mobile operators to utilize. Big Data Applications in the Telecommunications Industry is a comprehensive reference source for the latest scholarly material on the use of data analytics to study wireless networks and examines how these techniques can increase reliability and profitability, as well as network performance and connectivity. Featuring extensive coverage on relevant topics, such as accessibility, traffic data, and customer satisfaction, this publication is ideally designed for engineers, students, professionals, academics, and researchers seeking innovative perspectives on data science and wireless network communications.","language":"en","currency":"USD","id":"1522517510","title":"Big Data Applications in the Telecommunications Industry","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=vzfVDQAAQBAJ&source=gbs_api","authors":["Ouyang, Ye","Hu, Mantian"]},{"pageCount":164,"thumbnail":"http:\/\/books.google.com\/books\/content?id=cyLlCwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":17.19,"subtitle":null,"description":"Unleash the power of Apache Oozie to create and manage your big data and machine learning pipelines in one go About This Book Teaches you everything you need to know to get started with Apache Oozie from scratch and manage your data pipelines effortlessly Learn to write data ingestion workflows with the help of real-life examples from the author's own personal experience Embed Spark jobs to run your machine learning models on top of Hadoop Who This Book Is For If you are an expert Hadoop user who wants to use Apache Oozie to handle workflows efficiently, this book is for you. This book will be handy to anyone who is familiar with the basics of Hadoop and wants to automate data and machine learning pipelines. What You Will Learn Install and configure Oozie from source code on your Hadoop cluster Dive into the world of Oozie with Java MapReduce jobs Schedule Hive ETL and data ingestion jobs Import data from a database through Sqoop jobs in HDFS Create and process data pipelines with Pig, hive scripts as per business requirements. Run machine learning Spark jobs on Hadoop Create quick Oozie jobs using Hue Make the most of Oozie's security capabilities by configuring Oozie's security In Detail As more and more organizations are discovering the use of big data analytics, interest in platforms that provide storage, computation, and analytic capabilities is booming exponentially. This calls for data management. Hadoop caters to this need. Oozie fulfils this necessity for a scheduler for a Hadoop job by acting as a cron to better analyze data. Apache Oozie Essentials starts off with the basics right from installing and configuring Oozie from source code on your Hadoop cluster to managing your complex clusters. You will learn how to create data ingestion and machine learning workflows. This book is sprinkled with the examples and exercises to help you take your big data learning to the next level. You will discover how to write workflows to run your MapReduce, Pig ,Hive, and Sqoop scripts and schedule them to run at a specific time or for a specific business requirement using a coordinator. This book has engaging real-life exercises and examples to get you in the thick of things. Lastly, you'll get a grip of how to embed Spark jobs, which can be used to run your machine learning models on Hadoop. By the end of the book, you will have a good knowledge of Apache Oozie. You will be capable of using Oozie to handle large Hadoop workflows and even improve the availability of your Hadoop environment. Style and approach This book is a hands-on guide that explains Oozie using real-world examples. Each chapter is blended beautifully with fundamental concepts sprinkled in-between case study solution algorithms and topped off with self-learning exercises.","language":"en","currency":"USD","id":"1785888463","title":"Apache Oozie Essentials","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=cyLlCwAAQBAJ&source=gbs_api","authors":["Jagat Jasjit Singh"]},{"pageCount":184,"thumbnail":"http:\/\/books.google.com\/books\/content?id=YTe9BwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":14.59,"subtitle":null,"description":"Fast Data Processing with Spark - Second Edition is for software developers who want to learn how to write distributed programs with Spark. It will help developers who have had problems that were too big to be dealt with on a single computer. No previous experience with distributed programming is necessary. This book assumes knowledge of either Java, Scala, or Python.","language":"en","currency":"USD","id":"1784399078","title":"Fast Data Processing with Spark - Second Edition","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=YTe9BwAAQBAJ&source=gbs_api","authors":["Krishna Sankar","Holden Karau"]},{"pageCount":238,"thumbnail":"http:\/\/books.google.com\/books\/content?id=saHcDgAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":31.19,"subtitle":null,"description":"Learn how to write code, mathematics, graphics, and output, all in a single document, as well as in a web browser using Project Jupyter About This Book Learn to write, execute, and comment your live code and formulae all under one roof using this unique guide This one-stop solution on Project Jupyter will teach you everything you need to know to perform scientific computation with ease This easy-to-follow, highly practical guide lets you forget your worries in scientific application development by leveraging big data tools such as Apache Spark, Python, R etc Who This Book Is For This book caters to all developers, students, or educators who want to execute code, see output, and comment all in the same document, in the browser. Data science professionals will also find this book very useful to perform technical and scientific computing in a graphical, agile manner. What You Will Learn Install and run the Jupyter Notebook system on your machine Implement programming languages such as R, Python, Julia, and JavaScript with Jupyter Notebook Use interactive widgets to manipulate and visualize data in real time Start sharing your Notebook with colleagues Invite your colleagues to work with you in the same Notebook Organize your Notebook using Jupyter namespaces Access big data in Jupyter In Detail Jupyter Notebook is a web-based environment that enables interactive computing in notebook documents. It allows you to create and share documents that contain live code, equations, visualizations, and explanatory text. The Jupyter Notebook system is extensively used in domains such as data cleaning and transformation, numerical simulation, statistical modeling, machine learning, and much more. This book starts with a detailed overview of the Jupyter Notebook system and its installation in different environments. Next we'll help you will learn to integrate Jupyter system with different programming languages such as R, Python, JavaScript, and Julia and explore the various versions and packages that are compatible with the Notebook system. Moving ahead, you master interactive widgets, namespaces, and working with Jupyter in a multiuser mode. Towards the end, you will use Jupyter with a big data set and will apply all the functionalities learned throughout the book. Style and approach This comprehensive practical guide will teach you how to work with the Jupyter Notebook system. It demonstrates the integration of various programming languages with Jupyter Notebook through hands-on examples in every chapter.","language":"en","currency":"USD","id":"1785889451","title":"Learning Jupyter","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=saHcDgAAQBAJ&source=gbs_api","authors":["Dan Toomey"]},{"pageCount":265,"thumbnail":"http:\/\/books.google.com\/books\/content?id=eD5qDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":67.99,"subtitle":"19th International Conference, EANN 2018, Bristol, UK, September 3-5, 2018, Proceedings","description":"This book constitutes the refereed proceedings of the 19th International Conference on Engineering Applications of Neural Networks, EANN 2018, held in Bristol, UK, in September 2018. The 16 revised full papers and 5 revised short papers presented were carefully reviewed and selected from 39 submissions. The papers are organized in topical sections on activity recognition, deep learning, extreme learning machine, machine learning applications, predictive models, fuzzy and recommender systems, recurrent neural networks, spiking neural networks.","language":"en","currency":"USD","id":"3319982044","title":"Engineering Applications of Neural Networks","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=eD5qDwAAQBAJ&source=gbs_api","authors":["Elias Pimenidis","Chrisina Jayne"]},{"pageCount":184,"thumbnail":"http:\/\/books.google.com\/books\/content?id=YTe9BwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":14.59,"subtitle":null,"description":"Fast Data Processing with Spark - Second Edition is for software developers who want to learn how to write distributed programs with Spark. It will help developers who have had problems that were too big to be dealt with on a single computer. No previous experience with distributed programming is necessary. This book assumes knowledge of either Java, Scala, or Python.","language":"en","currency":"USD","id":"1784399078","title":"Fast Data Processing with Spark - Second Edition","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=YTe9BwAAQBAJ&source=gbs_api","authors":["Krishna Sankar","Holden Karau"]},{"pageCount":82,"thumbnail":"http:\/\/books.google.com\/books\/content?id=hNZJDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":0,"subtitle":null,"description":"Data warehouses were developed for many good reasons, such as providing quick query and reporting for business operations, and business performance. However, over the years, due to the explosion of applications and data volume, many existing data warehouses have become difficult to manage. Extract, Transform, and Load (ETL) processes are taking longer, missing their allocated batch windows. In addition, data types that are required for business analysis have expanded from structured data to unstructured data. The Apache open source Hadoop platform provides a great alternative for solving these problems. IBM® has committed to open source since the early years of open Linux. IBM and Hortonworks together are committed to Apache open source software more than any other company. IBM Power SystemsTM servers are built with open technologies and are designed for mission-critical data applications. Power Systems servers use technology from the OpenPOWER Foundation, an open technology infrastructure that uses the IBM POWER® architecture to help meet the evolving needs of big data applications. The combination of Power Systems with Hortonworks Data Platform (HDP) provides users with a highly efficient platform that provides leadership performance for big data workloads such as Hadoop and Spark. This IBM RedpaperTM publication provides details about Enterprise Data Warehouse (EDW) optimization with Hadoop on Power Systems. Many people know Power Systems from the IBM AIX® platform, but might not be familiar with IBM PowerLinuxTM, so part of this paper provides a Power Systems overview. A quick introduction to Hadoop is provided for those not familiar with the topic. Details of HDP on Power Reference architecture are included that will help both software architects and infrastructure architects understand the design. In the optimization chapter, we describe various topics: traditional EDW offload, sizing guidelines, performance tuning, IBM Elastic StorageTM Server (ESS) for data-intensive workload, IBM Big SQL as the common structured query language (SQL) engine for Hadoop platform, and tools that are available on Power Systems that are related to EDW optimization. We also dedicate some pages to the analytics components (IBM Data Science Experience (IBM DSX) and IBM SpectrumTM Conductor for Spark workload) for the Hadoop infrastructure.","language":"en","currency":"USD","id":"0738456608","title":"Enterprise Data Warehouse Optimization with Hadoop on IBM Power Systems Servers","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=hNZJDwAAQBAJ&source=gbs_api","authors":["Scott Vetter","Helen Lu","Maciej Olejniczak","IBM Redbooks"]},{"pageCount":null,"thumbnail":"http:\/\/books.google.com\/books\/content?id=0ISYDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":48,"subtitle":null,"description":"Publisher's Note: Products purchased from Third Party sellers are not guaranteed by the publisher for quality, authenticity, or access to any online entitlements included with the product. This study guide covers 100% of the objectives for the AWS Certified SysOps Administrator Associate exam Take the challenging AWS Certified SysOps Administrator Associate exam with confidence using this highly effective self-study guide. You will learn how to provision systems, ensure data integrity, handle security, and monitor and tune Amazon Web Services performance. Written by an industry-leading expert, AWS Certified SysOps Administrator Associate All-in-One Exam Guide (Exam SOA-C01) fully covers every objective for the exam and follows a hands-on, step-by-step methodology. Beyond fully preparing you for the exam, the book also serves as a valuable on-the-job reference. Covers all exam topics, including:\u2022Systems operations\u2022Signing up, working with the AWS Management Console, and the AWS CLI\u2022AWS Identity and Access Management (IAM) and AWS service security\u2022AWS compute services and the Elastic Compute Cloud (EC2)\u2022Amazon ECS, AWS Batch, AWS Lambda, and other compute services\u2022Storage and archiving in the AWS cloud with Amazon EBS, Amazon EFS, and Amazon S3 Glacier\u2022Managing databases in the cloud\u2014Amazon RDS, Amazon Aurora, Amazon DynamoDB, Amazon ElastiCache, and Amazon Redshift\u2022Application integration with Amazon SQS and Amazon SNS\u2022AWS high availability strategies\u2022Monitoring with Amazon CloudWatch, logging, and managing events\u2022Managing AWS costs and billing\u2022Infrastructure provisioning through AWS CloudFormation and AWS OpsWorks, application deployment, and creating scalable infrastructures Online content includes:\u2022130 practice questions\u2022Test engine that provides full-length practice exams or customized quizzes by chapter or by exam domain","language":"en","currency":"USD","id":"1260135551","title":"AWS Certified SysOps Administrator Associate All-in-One-Exam Guide (Exam SOA-C01)","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=0ISYDwAAQBAJ&source=gbs_api","authors":["Sam R. Alapati"]},{"pageCount":376,"thumbnail":"http:\/\/books.google.com\/books\/content?id=-F2vDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":40.79,"subtitle":"A Deep Dive into How Distributed Data Systems Work","description":"When it comes to choosing, using, and maintaining a database, understanding its internals is essential. But with so many distributed databases and tools available today, it\u2019s often difficult to understand what each one offers and how they differ. With this practical guide, Alex Petrov guides developers through the concepts behind modern database and storage engine internals. Throughout the book, you\u2019ll explore relevant material gleaned from numerous books, papers, blog posts, and the source code of several open source databases. These resources are listed at the end of parts one and two. You\u2019ll discover that the most significant distinctions among many modern databases reside in subsystems that determine how storage is organized and how data is distributed. This book examines: Storage engines: Explore storage classification and taxonomy, and dive into B-Tree-based and immutable Log Structured storage engines, with differences and use-cases for each Storage building blocks: Learn how database files are organized to build efficient storage, using auxiliary data structures such as Page Cache, Buffer Pool and Write-Ahead Log Distributed systems: Learn step-by-step how nodes and processes connect and build complex communication patterns Database clusters: Which consistency models are commonly used by modern databases and how distributed storage systems achieve consistency","language":"en","currency":"USD","id":"1492040304","title":"Database Internals","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=-F2vDwAAQBAJ&source=gbs_api","authors":["Alex Petrov"]},{"pageCount":304,"thumbnail":"http:\/\/books.google.com\/books\/content?id=EwNwDQAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":37.67,"subtitle":null,"description":"100 recipes that teach you how to perform various machine learning tasks in the real world About This Book Understand which algorithms to use in a given context with the help of this exciting recipe-based guide Learn about perceptrons and see how they are used to build neural networks Stuck while making sense of images, text, speech, and real estate? This guide will come to your rescue, showing you how to perform machine learning for each one of these using various techniques Who This Book Is For This book is for Python programmers who are looking to use machine-learning algorithms to create real-world applications. This book is friendly to Python beginners, but familiarity with Python programming would certainly be useful to play around with the code. What You Will Learn Explore classification algorithms and apply them to the income bracket estimation problem Use predictive modeling and apply it to real-world problems Understand how to perform market segmentation using unsupervised learning Explore data visualization techniques to interact with your data in diverse ways Find out how to build a recommendation engine Understand how to interact with text data and build models to analyze it Work with speech data and recognize spoken words using Hidden Markov Models Analyze stock market data using Conditional Random Fields Work with image data and build systems for image recognition and biometric face recognition Grasp how to use deep neural networks to build an optical character recognition system In Detail Machine learning is becoming increasingly pervasive in the modern data-driven world. It is used extensively across many fields such as search engines, robotics, self-driving cars, and more. With this book, you will learn how to perform various machine learning tasks in different environments. We'll start by exploring a range of real-life scenarios where machine learning can be used, and look at various building blocks. Throughout the book, you'll use a wide variety of machine learning algorithms to solve real-world problems and use Python to implement these algorithms. You'll discover how to deal with various types of data and explore the differences between machine learning paradigms such as supervised and unsupervised learning. We also cover a range of regression techniques, classification algorithms, predictive modeling, data visualization techniques, recommendation engines, and more with the help of real-world examples. Style and approach You will explore various real-life scenarios in this book where machine learning can be used, and learn about different building blocks of machine learning using independent recipes in the book.","language":"en","currency":"USD","id":"1786467682","title":"Python Machine Learning Cookbook","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=EwNwDQAAQBAJ&source=gbs_api","authors":["Prateek Joshi"]},{"pageCount":177,"thumbnail":"http:\/\/books.google.com\/books\/content?id=7jM8DwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":59.99,"subtitle":"4th SemWebEval Challenge at ESWC 2017, Portoroz, Slovenia, May 28 - June 1, 2017, Revised Selected Papers","description":"This book constitutes the thoroughly refereed post conference proceedings of the 4th edition of the Semantic Web Evaluation Challenge, SemWebEval 2017, co-located with the 14th European Semantic Web conference, held in Portoroz, Slovenia, in May\/June 2017. This book includes the descriptions of all methods and tools that competed at SemWebEval 2017, together with a detailed description of the tasks, evaluation procedures and datasets. The 11 revised full papers presented in this volume were carefully reviewed and selected from 21 submissions. The contributions are grouped in the areas: the mighty storage challenge; open knowledge extraction challenge; question answering over linked data challenge; semantic sentiment analysis.","language":"en","currency":"USD","id":"3319691465","title":"Semantic Web Challenges","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=7jM8DwAAQBAJ&source=gbs_api","authors":["Mauro Dragoni","Monika Solanki","Eva Blomqvist"]},{"pageCount":262,"thumbnail":"http:\/\/books.google.com\/books\/content?id=DOlODwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":19.79,"subtitle":"A practical approach to building neural network models using PyTorch","description":"Build neural network models in text, vision and advanced analytics using PyTorch Key Features Learn PyTorch for implementing cutting-edge deep learning algorithms. Train your neural networks for higher speed and flexibility and learn how to implement them in various scenarios; Cover various advanced neural network architecture such as ResNet, Inception, DenseNet and more with practical examples; Book Description Deep learning powers the most intelligent systems in the world, such as Google Voice, Siri, and Alexa. Advancements in powerful hardware, such as GPUs, software frameworks such as PyTorch, Keras, Tensorflow, and CNTK along with the availability of big data have made it easier to implement solutions to problems in the areas of text, vision, and advanced analytics. This book will get you up and running with one of the most cutting-edge deep learning libraries\u2014PyTorch. PyTorch is grabbing the attention of deep learning researchers and data science professionals due to its accessibility, efficiency and being more native to Python way of development. You'll start off by installing PyTorch, then quickly move on to learn various fundamental blocks that power modern deep learning. You will also learn how to use CNN, RNN, LSTM and other networks to solve real-world problems. This book explains the concepts of various state-of-the-art deep learning architectures, such as ResNet, DenseNet, Inception, and Seq2Seq, without diving deep into the math behind them. You will also learn about GPU computing during the course of the book. You will see how to train a model with PyTorch and dive into complex neural networks such as generative networks for producing text and images. By the end of the book, you'll be able to implement deep learning applications in PyTorch with ease. What you will learn Use PyTorch for GPU-accelerated tensor computations Build custom datasets and data loaders for images and test the models using torchvision and torchtext Build an image classifier by implementing CNN architectures using PyTorch Build systems that do text classification and language modeling using RNN, LSTM, and GRU Learn advanced CNN architectures such as ResNet, Inception, Densenet, and learn how to use them for transfer learning Learn how to mix multiple models for a powerful ensemble model Generate new images using GAN\u2019s and generate artistic images using style transfer Who this book is for This book is for machine learning engineers, data analysts, data scientists interested in deep learning and are looking to explore implementing advanced algorithms in PyTorch. Some knowledge of machine learning is helpful but not a mandatory need. Working knowledge of Python programming is expected.","language":"en","currency":"USD","id":"1788626079","title":"Deep Learning with PyTorch","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=DOlODwAAQBAJ&source=gbs_api","authors":["Vishnu Subramanian"]},{"pageCount":290,"thumbnail":"http:\/\/books.google.com\/books\/content?id=sNqdDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":55.99,"subtitle":"12th International Conference, SBP-BRiMS 2019, Washington, DC, USA, July 9\u201312, 2019, Proceedings","description":"This book constitutes the proceedings of the 12th International Conference on Social, Cultural, and Behavioral Modeling, SBP-BRiMS 2019, held in Washington, DC, USA, in July 2019. The total of 28 papers presented in this volume was carefully reviewed and selected from 72 submissions. The papers in this volume show, people, theories, methods and data from a wide number of disciplines including computer science, psychology, sociology, communication science, public health, bioinformatics, political science, and organizational science. Numerous types of computational methods are used include, but not limited to, machine learning, language technology, social network analysis and visualization, agent-based simulation, and statistics.","language":"en","currency":"USD","id":"3030217418","title":"Social, Cultural, and Behavioral Modeling","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=sNqdDwAAQBAJ&source=gbs_api","authors":["Robert Thomson","Halil Bisgin","Christopher Dancy","Ayaz Hyder"]},{"pageCount":302,"thumbnail":"http:\/\/books.google.com\/books\/content?id=HnxeDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":14.59,"subtitle":"Build web applications with MongoDB, Express.js, React, and Node","description":"Build web applications with MongoDB, ExpressJS, React, and Node Key Features Build applications with the MERN stack Work with each component of the MERN stack Become confident with MERN and ready for more! Book Description The MERN stack is a collection of great tools\u2014MongoDB, Express.js, React, and Node\u2014that provide a strong base for a developer to build easily maintainable web applications. With each of them a JavaScript or JavaScript-based technology, having a shared programming language means it takes less time to develop web applications. This book focuses on providing key tasks that can help you get started, learn, understand, and build full-stack web applications. It walks you through the process of installing all the requirements and project setup to build client-side React web applications, managing synchronous and asynchronous data flows with Redux, and building real-time web applications with Socket.IO, RESTful APIs, and other concepts. This book gives you practical and clear hands-on experience so you can begin building a full-stack MERN web application. Quick Start Guides are focused, shorter titles that provide a faster paced introduction to a technology. They are for people who don't need all the detail at this point in their learning curve. The presentation has been streamlined to concentrate on the things you really need to know. What you will learn Get started with the MERN stack Install Node.js and configure MongoDB Build RESTful APIs with Express.js and Mongoose Build real-time applications with Socket.IO Manage synchronous and asynchronous data flows with Redux Build web applications with React Who this book is for The book is for JavaScript developers who want to get stated with the MERN Stack.","language":"en","currency":"USD","id":"1787280047","title":"MERN Quick Start Guide","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=HnxeDwAAQBAJ&source=gbs_api","authors":["Eddy Wilson"]},{"pageCount":168,"thumbnail":"http:\/\/books.google.com\/books\/content?id=1_KoCwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":17.19,"subtitle":null,"description":"Build real-world, industry-strength data storage solutions with time-tested design methodologies using Cassandra About This Book Explore design patterns which co-exist with legacy data stores, migration from RDBMS, and caching technologies with Cassandra Learn about design patterns and use Cassandra to provide consistency, availability, and partition tolerance guarantees for applications Handle temporal data for analytical purposes Who This Book Is For This book is intended for big data developers who are familiar with the basics of Cassandra and wish to understand and utilize Cassandra design patterns to develop real-world big data solutions. Prior knowledge of RDBMS solutions is assumed. What You Will Learn Enable Cassandra to co-exist with RDBMS and other legacy data stores Explore various design patterns to build effective and robust storage solutions Migrate from RDBMS-based data stores and caching solutions to Cassandra Understand the behaviour of Cassandra when trying to balance the needs of consistency, availability, and partition tolerance Deal with time stamps related to data effectively See how Cassandra can be used in analytical use cases Apply the design patterns covered in this book in real-world use cases In Detail There are many NoSQL data stores used by big data applications. Cassandra is one of the most widely used NoSQL data stores that is frequently used by a huge number of heavy duty Internet-scale applications. Unlike the RDBMS world, the NoSQL landscape is very diverse and there is no one way to model data stores. This mandates the need to have good solutions to commonly seen data store design problems. Cassandra addresses such common problems simply. If you are new to Cassandra but well-versed in RDBMS modeling and design, then it is natural to model data in the same way in Cassandra, resulting in poorly performing applications and losing the real purpose of Cassandra. If you want to learn to make the most of Cassandra, this book is for you. This book starts with strategies to integrate Cassandra with other legacy data stores and progresses to the ways in which a migration from RDBMS to Cassandra can be accomplished. The journey continues with ideas to migrate data from cache solutions to Cassandra. With this, the stage is set and the book moves on to some of the most commonly seen problems in applications when dealing with consistency, availability, and partition tolerance guarantees. Cassandra is exceptionally good at dealing with temporal data and patterns such as the time-series pattern and log pattern, which are covered next. Many NoSQL data stores fail miserably when a huge amount of data is read for analytical purposes, but Cassandra is different in this regard. Keeping analytical needs in mind, you'll walk through different and interesting design patterns. No theoretical discussions are complete without a good set of use cases to which the knowledge gained can be applied, so the book concludes with a set of use cases you can apply the patterns you've learned. Style and approach This book is written in very simple language and an engaging style complete with examples in every chapter and real-world use cases at the end of the book.","language":"en","currency":"USD","id":"1783988487","title":"Cassandra Design Patterns","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=1_KoCwAAQBAJ&source=gbs_api","authors":["Rajanarayanan Thottuvaikkatumana"]},{"pageCount":348,"thumbnail":"http:\/\/books.google.com\/books\/content?id=-B5LDQAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":191.2,"subtitle":"Proceedings of the 2nd INNS Conference on Big Data, October 23-25, 2016, Thessaloniki, Greece","description":"The book offers a timely snapshot of neural network technologies as a significant component of big data analytics platforms. It promotes new advances and research directions in efficient and innovative algorithmic approaches to analyzing big data (e.g. deep networks, nature-inspired and brain-inspired algorithms); implementations on different computing platforms (e.g. neuromorphic, graphics processing units (GPUs), clouds, clusters); and big data analytics applications to solve real-world problems (e.g. weather prediction, transportation, energy management). The book, which reports on the second edition of the INNS Conference on Big Data, held on October 23\u201325, 2016, in Thessaloniki, Greece, depicts an interesting collaborative adventure of neural networks with big data and other learning technologies.","language":"en","currency":"USD","id":"3319478982","title":"Advances in Big Data","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=-B5LDQAAQBAJ&source=gbs_api","authors":["Plamen Angelov","Yannis Manolopoulos","Lazaros Iliadis","Asim Roy","Marley Vellasco"]},{"pageCount":278,"thumbnail":"http:\/\/books.google.com\/books\/content?id=YO13CgAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":22.39,"subtitle":null,"description":"Moving beyond MapReduce - learn resource management and big data processing using YARN About This Book Deep dive into YARN components, schedulers, life cycle management and security architecture Create your own Hadoop-YARN applications and integrate big data technologies with YARN Step-by-step guide to provision, manage, and monitor Hadoop-YARN clusters with ease Who This Book Is For This book is intended for those who want to understand what YARN is and how to efficiently use it for the resource management of large clusters. For cluster administrators, this book gives a detailed explanation of provisioning and managing YARN clusters. If you are a Java developer or an open source contributor, this book will help you to drill down the YARN architecture, write your own YARN applications and understand the application execution phases. This book will also help big data engineers explore YARN integration with real-time analytics technologies such as Spark and Storm. What You Will Learn Explore YARN features and offerings Manage big data clusters efficiently using the YARN framework Create single as well as multi-node Hadoop-YARN clusters on Linux machines Understand YARN components and their administration Gain insights into application execution flow over a YARN cluster Write your own distributed application and execute it over YARN cluster Work with schedulers and queues for efficient scheduling of applications Integrate big data projects like Spark and Storm with YARN In Detail Today enterprises generate huge volumes of data. In order to provide effective services and to make smarter and more intelligent decisions from these huge volumes of data, enterprises use big-data analytics. In recent years, Hadoop has been used for massive data storage and efficient distributed processing of data. The Yet Another Resource Negotiator (YARN) framework solves the design problems related to resource management faced by the Hadoop 1.x framework by providing a more scalable, efficient, flexible, and highly available resource management framework for distributed data processing. This book starts with an overview of the YARN features and explains how YARN provides a business solution for growing big data needs. You will learn to provision and manage single, as well as multi-node, Hadoop-YARN clusters in the easiest way. You will walk through the YARN administration, life cycle management, application execution, REST APIs, schedulers, security framework and so on. You will gain insights about the YARN components and features such as ResourceManager, NodeManager, ApplicationMaster, Container, Timeline Server, High Availability, Resource Localisation and so on. The book explains Hadoop-YARN commands and the configurations of components and explores topics such as High Availability, Resource Localization and Log aggregation. You will then be ready to develop your own ApplicationMaster and execute it over a Hadoop-YARN cluster. Towards the end of the book, you will learn about the security architecture and integration of YARN with big data technologies like Spark and Storm. This book promises conceptual as well as practical knowledge of resource management using YARN. Style and approach Starting with the basics and covering the core concepts with the practical usage, this tutorial is a complete guide to learn and explore YARN offerings.","language":"en","currency":"USD","id":"1784394580","title":"Learning YARN","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=YO13CgAAQBAJ&source=gbs_api","authors":["Akhil Arora","Shrey Mehrotra"]},{"pageCount":480,"thumbnail":"http:\/\/books.google.com\/books\/content?id=qmPHDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":48,"subtitle":null,"description":"Publisher's Note: Products purchased from Third Party sellers are not guaranteed by the publisher for quality, authenticity, or access to any online entitlements included with the product. This study guide covers 100% of the objectives for the Oracle Cloud Infrastructure Architect Associate exam Pass the new Oracle Cloud Infrastructure Architect Associate exam with ease using the detailed information contained in this effective self-study system. Written by an Oracle expert and respected author, Oracle Cloud Infrastructure Architect Associate All-in-One Exam Guide (Exam 1Z0-1072) offers complete coverage of every subject on the challenging exam. Hands-on exercises, practice exam questions with in-depth explanations, \u201CNotes,\u201D \u201CExam Tips,\u201D and \u201CCautions\u201D throughout provide professional insight and call out potentially harmful situations. Beyond exam preparation, this guide also serves as a valuable on-the-job reference. Covers all exam topics, including: \u2022 Oracle Cloud Infrastructure concepts \u2022 OCI identity and access management \u2022 OCI networking \u2022 Compute instances \u2022 Storage \u2022 Database \u2022 Automation tools \u2022 OCI best practice architectures Online content includes: \u2022 140 practice questions \u2022 Fully-customizable online test engine","language":"en","currency":"USD","id":"1260452603","title":"Oracle Cloud Infrastructure Architect Associate All-in-One Exam Guide (Exam 1Z0-1072)","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=qmPHDwAAQBAJ&source=gbs_api","authors":["Roopesh Ramklass"]},{"pageCount":448,"thumbnail":"http:\/\/books.google.com\/books\/content?id=YlGoBAAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":60,"subtitle":null,"description":"Take Your PL\/SQL Programming Skills to the Next Level Build robust database-centric PL\/SQL applications quickly and effectively. Oracle Database 12c PL\/SQL Advanced Programming Techniques shows you how to write and deploy Java libraries inside Oracle Database 12c, use the utl_file and DBMS_SCHEDULER packages, and create external tables and external procedures. Application security, performance tuning, and Oracle Database In-Memory are also covered in this Oracle Press guide. Configure, deploy, and troubleshoot Java libraries for Oracle object types Use the utl_file package to manage unstructured and structured data Develop and deploy Java I\/O libraries and wrap them with PL\/SQL Create and use external tables Implement high-speed data transfer Harden database systems and develop secure applications Manage complex schedules and jobs with the DBMS_SCHEDULER package Optimize PL\/SQL for use in performance tuning Create and deploy external procedures Implement the Oracle Database In-Memory column store feature","language":"en","currency":"USD","id":"0071835156","title":"Oracle Database 12c PL\/SQL Advanced Programming Techniques","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=YlGoBAAAQBAJ&source=gbs_api","authors":["Michael McLaughlin","John M. Harper"]},{"pageCount":null,"thumbnail":"http:\/\/books.google.com\/books\/content?id=3igKEAAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":40,"subtitle":null,"description":"This effective self-study system delivers complete coverage of every topic on the AWS Certified Developer Associate Exam Take the challenging AWS Certified Developer Associate Exam with confidence using the comprehensive information contained in this effective test preparation guide. Written by an Amazon Web Services certified expert and experienced trainer, AWS Certified Developer Associate All-in-One Exam Guide (Exam DVA-C01) covers every subject on the exam and clearly explains how to create, deploy, migrate, monitor, and debug cloud-native applications. Designed to help you pass the exam with ease, this guide also serves as an ideal on-the-job reference. Covers all topics on the exam, including: Getting started with AWS Journey AWS high availability and fault tolerance Working with cloud storage Authentication and authorization Creating SQL and NoSQL databases in AWS Cloud AWS application integration and management Developing cloud-native applications in AWS Building, deploying, and debugging cloud applications Electronic content includes: 130 practice questions Test engine containing full-length practice exams and customizable quizzes","language":"en","currency":"USD","id":"1260460185","title":"AWS Certified Developer Associate All-in-One Exam Guide (Exam DVA-C01)","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=3igKEAAAQBAJ&source=gbs_api","authors":["Kamesh Ganesan"]},{"pageCount":null,"thumbnail":"http:\/\/books.google.com\/books\/content?id=XxNqDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":40,"subtitle":null,"description":"COVERS THE NEW 2018 EXAM SAA-C01! This effective study guide provides 100% coverage of every topic on the AWS Certified Solutions Architect Associate exam. Get complete coverage of all objectives included on the February 2018 SAA-C01 exam from this comprehensive resource. Written by an expert AWS Solutions Architect and well-respected author, this authoritative guide fully addresses the knowledge and skills required for passing the AWS Certified Solutions Architect Associate exam. You\u2019ll find learning objectives at the beginning of each chapter, exam tips, practice exam questions, and in-depth explanations. Designed to help you pass the exam with ease, this definitive volume also serves as an essential on-the-job reference. Covers all exam domains, including: \u2022Design Resilient Architectures \u2022Define Performant Architectures \u2022Specify Secure Applications and Architectures \u2022Design Cost-Optimized Architectures \u2022Define Operationally Excellent Architectures Digital content includes: \u2022130 practice exam questions\u2022Test engine that provides practice exams or quizzes that can be customized by chapter or exam objective","language":"en","currency":"USD","id":"1260108260","title":"AWS Certified Solutions Architect Associate All-in-One Exam Guide (Exam SAA-C01)","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=XxNqDwAAQBAJ&source=gbs_api","authors":["Joyjeet Banerjee"]},{"pageCount":424,"thumbnail":"http:\/\/books.google.com\/books\/content?id=F9s1DwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":67.99,"subtitle":"21st European Conference, ADBIS 2017, Nicosia, Cyprus, September 24-27, 2017, Proceedings","description":"This book constitutes the proceedings of the 21st European Conference on Advances in Databases and Information Systems, ADBIS 2017, held in Nicosia, Cyprus, in September 2017. The 26 regular papers presented together with one keynote paper and one keynote abstract were carefully selected and reviewed from numerous submissions. The papers are organized in topical sections such as conceptual modeling and human factors; subsequence matching and streaming data; OLAP; graph databases; spatial data management; parallel and distributed data processing; query optimization, recovery, and databases on modern hardware; semantic data processing; and additional database and information systems topics.","language":"en","currency":"USD","id":"3319669176","title":"Advances in Databases and Information Systems","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=F9s1DwAAQBAJ&source=gbs_api","authors":["Mārīte Kirikova","Kjetil Nørvåg","George A. Papadopoulos"]},{"pageCount":334,"thumbnail":"http:\/\/books.google.com\/books\/content?id=sBBkDAAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":151.2,"subtitle":"Proceedings of the 12th International Conference on Computing and Information Technology (IC2IT)","description":"This proceedings book presents recent research work and results in the area of communication and information technologies. The chapters of this book contain the main, well-selected and reviewed contributions of scientists who met at the 12th International Conference on Computing and Information Technology (IC2IT) held during 7th - 8th July 2016 in Khon Kaen, Thailand The book is divided into three parts: \u201CUser Centric Data Mining and Text Processing\u201D, \u201CData Mining Algoritms and their Applications\u201D and \u201COptimization of Complex Networks\u201D.","language":"en","currency":"USD","id":"3319404156","title":"Recent Advances in Information and Communication Technology 2016","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=sBBkDAAAQBAJ&source=gbs_api","authors":["Phayung Meesad","Sirapat Boonkrong","Herwig Unger"]},{"pageCount":724,"thumbnail":"http:\/\/books.google.com\/books\/content?id=qzCWDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":31.19,"subtitle":"Over 100 recipes for fast, scalable, and reliable search for your enterprise, 4th Edition","description":"Search, analyze, and manage data effectively with Elasticsearch 7 Key Features Extend Elasticsearch functionalities and learn how to deploy on Elastic Cloud Deploy and manage simple Elasticsearch nodes as well as complex cluster topologies Explore the capabilities of Elasticsearch 7 with easy-to-follow recipes Book Description Elasticsearch is a Lucene-based distributed search server that allows users to index and search unstructured content with petabytes of data. With this book, you'll be guided through comprehensive recipes on what's new in Elasticsearch 7, and see how to create and run complex queries and analytics. Packed with recipes on performing index mapping, aggregation, and scripting using Elasticsearch, this fourth edition of Elasticsearch Cookbook will get you acquainted with numerous solutions and quick techniques for performing both every day and uncommon tasks such as deploying Elasticsearch nodes, integrating other tools to Elasticsearch, and creating different visualizations. You will install Kibana to monitor a cluster and also extend it using a variety of plugins. Finally, you will integrate your Java, Scala, Python, and big data applications such as Apache Spark and Pig with Elasticsearch, and create efficient data applications powered by enhanced functionalities and custom plugins. By the end of this book, you will have gained in-depth knowledge of implementing Elasticsearch architecture, and you'll be able to manage, search, and store data efficiently and effectively using Elasticsearch. What you will learn Create an efficient architecture with Elasticsearch Optimize search results by executing analytics aggregations Build complex queries by managing indices and documents Monitor the performance of your cluster and nodes Design advanced mapping to take full control of index steps Integrate Elasticsearch in Java, Scala, Python, and big data applications Install Kibana to monitor clusters and extend it for plugins Who this book is for If you\u2019re a software engineer, big data infrastructure engineer, or Elasticsearch developer, you'll find this book useful. This Elasticsearch book will also help data professionals working in the e-commerce and FMCG industry who use Elastic for metrics evaluation and search analytics to get deeper insights for better business decisions. Prior experience with Elasticsearch will help you get the most out of this book.","language":"en","currency":"USD","id":"1789959020","title":"Elasticsearch 7.0 Cookbook","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=qzCWDwAAQBAJ&source=gbs_api","authors":["Alberto Paro"]},{"pageCount":180,"thumbnail":"http:\/\/books.google.com\/books\/content?id=srRJDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":14.99,"subtitle":"Power BI Is Better When You Learn to Write DAX","description":"Power BI is a powerful self-service (and enterprise) business intelligence (BI) tool that was first made generally available by Microsoft in July 2015. Power BI is a complete BI package that covers the end to end BI process including data acquisition (get data), data modelling (prepare\/model the data) and data visualisation (analyse the data). And there is a lot of good news about this tool including the fact that the skills needed to succeed with Power BI are fully transferable to Microsoft Excel. There are 3 learning areas required to master everything Power BI Desktop has to offer.1. The M Language - used for data acquisition2. The DAX Language - used to prepare and model data3. Visualisation and analysis - used to present data in a compelling wayPower BI is probably the first commercial grade software product that brings all of these areas into a single software package that is completely accessible to a business user (you don't need to be an IT pro). This book focuses on number 2 above, the DAX language (Data Analysis Expressions). Super Charge Power BI Desktop is the second book written by Matt Allington and is a sister book to his first book Learn to Write DAX (first released Dec 2015). Super Charge Power BI Desktop uses the same learning and practice exercise framework as used in Learn to Write DAX however the entire book is written using the Power BI Desktop user interface. Unfortunately simply reading a book is normally not enough for Excel users wanting to get the most out of Power BI Desktop and to learn the DAX language - most people will also need some practice. Super Charge Power BI Desktop is different to other books - it is written in such a way to clearly explain the concepts of Power BI data modelling while at the same time giving hands-on practice to deeply engage the reader to help the new knowledge and concepts stick. The book first presents the theory, then provides worked through sample exercises demonstrating each of the concepts, and finally it provides the reader with practice exercises and answers to maximize learning retention.","language":"en","currency":"USD","id":"1615473602","title":"Super Charge Power BI","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=srRJDwAAQBAJ&source=gbs_api","authors":["Matt Allington"]},{"pageCount":384,"thumbnail":"http:\/\/books.google.com\/books\/content?id=o2ovDgAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":18,"subtitle":null,"description":"Discover how data science can help you gain in-depth insight into your business - the easy way! Jobs in data science abound, but few people have the data science skills needed to fill these increasingly important roles. Data Science For Dummies is the perfect starting point for IT professionals and students who want a quick primer on all areas of the expansive data science space. With a focus on business cases, the book explores topics in big data, data science, and data engineering, and how these three areas are combined to produce tremendous value. If you want to pick-up the skills you need to begin a new career or initiate a new project, reading this book will help you understand what technologies, programming languages, and mathematical methods on which to focus. While this book serves as a wildly fantastic guide through the broad, sometimes intimidating field of big data and data science, it is not an instruction manual for hands-on implementation. Here\u2019s what to expect: Provides a background in big data and data engineering before moving on to data science and how it's applied to generate value Includes coverage of big data frameworks like Hadoop, MapReduce, Spark, MPP platforms, and NoSQL Explains machine learning and many of its algorithms as well as artificial intelligence and the evolution of the Internet of Things Details data visualization techniques that can be used to showcase, summarize, and communicate the data insights you generate It's a big, big data world out there\u2014let Data Science For Dummies help you harness its power and gain a competitive edge for your organization.","language":"en","currency":"USD","id":"1119327652","title":"Data Science For Dummies","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=o2ovDgAAQBAJ&source=gbs_api","authors":["Lillian Pierson"]},{"pageCount":792,"thumbnail":"http:\/\/books.google.com\/books\/content?id=bIZHCgAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":29.99,"subtitle":"Clear, Concise, and Effective Programming","description":"Python\u2019s simplicity lets you become productive quickly, but this often means you aren\u2019t using everything it has to offer. With this hands-on guide, you\u2019ll learn how to write effective, idiomatic Python code by leveraging its best\u2014and possibly most neglected\u2014features. Author Luciano Ramalho takes you through Python\u2019s core language features and libraries, and shows you how to make your code shorter, faster, and more readable at the same time. Many experienced programmers try to bend Python to fit patterns they learned from other languages, and never discover Python features outside of their experience. With this book, those Python programmers will thoroughly learn how to become proficient in Python 3. This book covers: Python data model: understand how special methods are the key to the consistent behavior of objects Data structures: take full advantage of built-in types, and understand the text vs bytes duality in the Unicode age Functions as objects: view Python functions as first-class objects, and understand how this affects popular design patterns Object-oriented idioms: build classes by learning about references, mutability, interfaces, operator overloading, and multiple inheritance Control flow: leverage context managers, generators, coroutines, and concurrency with the concurrent.futures and asyncio packages Metaprogramming: understand how properties, attribute descriptors, class decorators, and metaclasses work","language":"en","currency":"USD","id":"1491946253","title":"Fluent Python","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=bIZHCgAAQBAJ&source=gbs_api","authors":["Luciano Ramalho"]},{"pageCount":592,"thumbnail":"http:\/\/books.google.com\/books\/content?id=5R6VDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":69.42,"subtitle":"19th International Conference, ICWE 2019, Daejeon, South Korea, June 11\u201314, 2019, Proceedings","description":"This book constitutes the refereed proceedings of the 19th International Conference on Web Engineering, ICWE 2019, held in Daejeon, South Korea, in June 2019. The 26 full research papers and 9 short papers presented were carefully reviewed and selected from 106 submissions. Additionally, two demonstrations, four posters, and four contributions to the PhD symposium as well as five tutorials are included in this volume. The papers cover research areas such as Web mining and knowledge extraction, Web big data and Web data analytics, social Web applications and crowdsourcing, Web user interfaces, Web security and privacy, Web programming, Web services and computing, Semantic Web and linked open data applications, and Web application modeling and engineering.","language":"en","currency":"USD","id":"3030192741","title":"Web Engineering","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=5R6VDwAAQBAJ&source=gbs_api","authors":["Maxim Bakaev","Flavius Frasincar","In-Young Ko"]},{"pageCount":768,"thumbnail":"http:\/\/books.google.com\/books\/content?id=8PqlDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":87.2,"subtitle":"15th International Conference, ICIC 2019, Nanchang, China, August 3\u20136, 2019, Proceedings","description":"This two-volume set of LNCS 11643 and LNCS 11644 constitutes - in conjunction with the volume LNAI 11645 - the refereed proceedings of the 15th International Conference on Intelligent Computing, ICIC 2019, held in Nanchang, China, in August 2019. The 217 full papers of the three proceedings volumes were carefully reviewed and selected from 609 submissions. The ICIC theme unifies the picture of contemporary intelligent computing techniques as an integral concept that highlights the trends in advanced computational intelligence and bridges theoretical research with applications. The theme for this conference is \u201CAdvanced Intelligent Computing Methodologies and Applications.\u201D Papers related to this theme are especially solicited, including theories, methodologies, and applications in science and technology.","language":"en","currency":"USD","id":"3030267636","title":"Intelligent Computing Theories and Application","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=8PqlDwAAQBAJ&source=gbs_api","authors":["De-Shuang Huang","Vitoantonio Bevilacqua","Prashan Premaratne"]},{"pageCount":247,"thumbnail":"http:\/\/books.google.com\/books\/content?id=9S3EDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":19.24,"subtitle":"With Data Modeling and Query Building Strategies","description":"Get the most out of MongoDB using a problem-solution approach. This book starts with recipes on the MongoDB query language, including how to query various data structures stored within documents. These self-contained code examples allow you to solve your MongoDB problems without fuss. MongoDB Recipes describes how to use advanced querying in MongoDB, such as indexing and the aggregation framework. It demonstrates how to use the Compass function, a GUI client interacting with MongoDB, and how to apply data modeling to your MongoDB application. You\u2019ll see recipes on the latest features of MongoDB 4 allowing you to manage data in an efficient manner using MongoDB. What You Will Learn Work with the MongoDB document model Design MongoDB schemas Use the MongoDB query language Harness the aggregation framework Create replica sets and sharding in MongoDB Who This Book Is ForDevelopers and professionals who work with MongoDB.","language":"en","currency":"USD","id":"1484248910","title":"MongoDB Recipes","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=9S3EDwAAQBAJ&source=gbs_api","authors":["Subhashini Chellappan","Dharanitharan Ganesan"]},{"pageCount":1046,"thumbnail":"http:\/\/books.google.com\/books\/content?id=JIBSDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":271.2,"subtitle":"Proceedings of the 2nd Mediterranean Symposium on Smart City Applications","description":"This proceedings book showcases the latest research work presented at the Second Edition of the Mediterranean Symposium on Smart City Application (SCAMS 2017), which was held in Tangier, Morocco on October 15\u201327, 2017. It presents original research results, new ideas and practical development experiences that concentrate on both theory and practice. It includes papers from all areas of Smart City Applications, e.g. Smart Mobility, Big Data, Smart Grids, Smart Homes and Buildings, clouds, crowds, mashups, social networks, and security issues. The conference stimulated cutting-edge research discussions among pioneering researchers, scientists, industrial engineers, and students from all around the world. The topics covered in this book also focus on innovative issues at the international level by bringing together experts from different countries. The scope of SCAMS 2017 included methods and practices that combine various emerging internetworking and data technologies to capture, integrate, analyze, mine, annotate, and visualize data in a meaningful and collaborative manner. A series of international workshops were organized as invited sessions during the SCAMS 2017:The 2nd International Workshop on Smart Learning & Innovative EducationsThe 1st International Workshop on Smart HealthcareThe 1st International Workshop on Mathematics for Smart CityThe 1st International Workshop Industry 4.0 and Smart Manufacturing","language":"en","currency":"USD","id":"331974500X","title":"Innovations in Smart Cities and Applications","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=JIBSDwAAQBAJ&source=gbs_api","authors":["Mohamed Ben Ahmed","Anouar Abdelhakim Boudhir"]},{"pageCount":526,"thumbnail":"http:\/\/books.google.com\/books\/content?id=36gGEAAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":15.24,"subtitle":"Build intelligent systems using Python, TensorFlow 2, PyTorch, and scikit-learn, 3rd Edition","description":"Equipped with the latest updates, this third edition of Python Machine Learning By Example provides a comprehensive course for ML enthusiasts to strengthen their command of ML concepts, techniques, and algorithms.","language":"en","currency":"USD","id":"1800203861","title":"Python Machine Learning By Example","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=36gGEAAAQBAJ&source=gbs_api","authors":["Yuxi (Hayden) Liu"]},{"pageCount":180,"thumbnail":"http:\/\/books.google.com\/books\/content?id=M4jiCgAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":14.99,"subtitle":"A practical guide to learning Power Pivot for Excel and Power BI","description":"Active learning lessons for mastering DAX Data analysis expressions (DAX) is the formula language of PowerPivot and this book is written to give hands-on practice to anyone who wants to become competent at writing such formulas. Sample exercises that explain each concept are provided and followed by practice questions and answers to maximize learning and experience with DAX.","language":"en","currency":"USD","id":"1615473548","title":"Learn to Write DAX","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=M4jiCgAAQBAJ&source=gbs_api","authors":["Matt Allington"]},{"pageCount":180,"thumbnail":"http:\/\/books.google.com\/books\/content?id=M4jiCgAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":14.99,"subtitle":"A practical guide to learning Power Pivot for Excel and Power BI","description":"Active learning lessons for mastering DAX Data analysis expressions (DAX) is the formula language of PowerPivot and this book is written to give hands-on practice to anyone who wants to become competent at writing such formulas. Sample exercises that explain each concept are provided and followed by practice questions and answers to maximize learning and experience with DAX.","language":"en","currency":"USD","id":"1615473548","title":"Learn to Write DAX","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=M4jiCgAAQBAJ&source=gbs_api","authors":["Matt Allington"]},{"pageCount":568,"thumbnail":"http:\/\/books.google.com\/books\/content?id=y83aDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":28.49,"subtitle":"Build powerful and reliable Python web applications from scratch, 3rd Edition","description":"Learn Django 3 with four end-to-end web projects Key Features Learn Django 3 by building real-world web applications from scratch in Python, using coding best practices Integrate other technologies into your application with clear, step-by-step explanations and comprehensive example code Implement advanced functionalities like a full-text search engine, a user activity stream, or a recommendation engine Add real-time features with Django Channels and WebSockets Book Description If you want to learn the entire process of developing professional web applications with Python and Django, then this book is for you. In the process of building four professional Django projects, you will learn about Django 3 features, how to solve common web development problems, how to implement best practices, and how to successfully deploy your applications. In this book, you will build a blog application, a social image bookmarking website, an online shop, and an e-learning platform. Step-by-step guidance will teach you how to integrate popular technologies, enhance your applications with AJAX, create RESTful APIs, and set up a production environment for your Django projects. By the end of this book, you will have mastered Django 3 by building advanced web applications. What you will learn Build real-world web applications Learn Django essentials, including models, views, ORM, templates, URLs, forms, and authentication Implement advanced features such as custom model fields, custom template tags, cache, middleware, localization, and more Create complex functionalities, such as AJAX interactions, social authentication, a full-text search engine, a payment system, a CMS, a RESTful API, and more Integrate other technologies, including Redis, Celery, RabbitMQ, PostgreSQL, and Channels, into your projects Deploy Django projects in production using NGINX, uWSGI, and Daphne Who this book is for This book is intended for developers with Python knowledge who wish to learn Django in a pragmatic way. Perhaps you are completely new to Django, or you already know a little but you want to get the most out of it. This book will help you to master the most relevant areas of the framework by building practical projects from scratch. You need to have familiarity with programming concepts in order to read this book. Some previous knowledge of HTML and JavaScript is assumed.","language":"en","currency":"USD","id":"1838989323","title":"Django 3 By Example","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=y83aDwAAQBAJ&source=gbs_api","authors":["Antonio Melé"]},{"pageCount":230,"thumbnail":"http:\/\/books.google.com\/books\/content?id=fPwKCgAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":19.79,"subtitle":null,"description":"Apache Mesos is a cluster manager that provides efficient resource isolation and sharing across distributed applications, or frameworks. It allows developers to concurrently run the likes of Hadoop, Spark, Storm, and other applications on a dynamically shared pool of nodes. With Mesos, you have the power to manage a wide range of resources in a multi-tenant environment. Starting with the basics, this book will give you an insight into all the features that Mesos has to offer. You will first learn how to set up Mesos in various environments from data centers to the cloud. You will then learn how to implement self-managed Platform as a Service environment with Mesos using various service schedulers, such as Chronos, Aurora, and Marathon. You will then delve into the depths of Mesos fundamentals and learn how to build distributed applications using Mesos primitives. Finally, you will round things off by covering the operational aspects of Mesos including logging, monitoring, high availability, and recovery.","language":"en","currency":"USD","id":"1783288779","title":"Apache Mesos Essentials","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=fPwKCgAAQBAJ&source=gbs_api","authors":["Dharmesh Kakadia"]},{"pageCount":424,"thumbnail":"http:\/\/books.google.com\/books\/content?id=E9k1DwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":172,"subtitle":null,"description":"Emerging developments in cloud computing have created novel opportunities and applications for businesses. These innovations not only have organizational benefits, but can be advantageous for green enterprises as well. Cloud Computing Technologies for Green Enterprises is a pivotal reference source for the latest scholarly research on the advancements, benefits, and challenges of cloud computing for green enterprise endeavors. Highlighting pertinent topics such as resource allocation, energy efficiency, and mobile computing, this book is a premier resource for academics, researchers, students, professionals, and managers interested in novel trends in cloud computing applications.","language":"en","currency":"USD","id":"1522530398","title":"Cloud Computing Technologies for Green Enterprises","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=E9k1DwAAQBAJ&source=gbs_api","authors":["Munir, Kashif"]},{"pageCount":256,"thumbnail":"http:\/\/books.google.com\/books\/content?id=QOzSBQAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":18.35,"subtitle":"Practical Functional Programming for the JVM","description":"Why learn Scala? You don\u2019t need to be a data scientist or distributed computing expert to appreciate this object-oriented functional programming language. This practical book provides a comprehensive yet approachable introduction to the language, complete with syntax diagrams, examples, and exercises. You\u2019ll start with Scala's core types and syntax before diving into higher-order functions and immutable data structures. Author Jason Swartz demonstrates why Scala\u2019s concise and expressive syntax make it an ideal language for Ruby or Python developers who want to improve their craft, while its type safety and performance ensures that it\u2019s stable and fast enough for any application. Learn about the core data types, literals, values, and variables Discover how to think and write in expressions, the foundation for Scala's syntax Write higher-order functions that accept or return other functions Become familiar with immutable data structures and easily transform them with type-safe and declarative operations Create custom infix operators to simplify existing operations or even to start your own domain-specific language Build classes that compose one or more traits for full reusability, or create new functionality by mixing them in at instantiation","language":"en","currency":"USD","id":"1449368832","title":"Learning Scala","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=QOzSBQAAQBAJ&source=gbs_api","authors":["Jason Swartz"]},{"pageCount":382,"thumbnail":"http:\/\/books.google.com\/books\/content?id=eSVhDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":63.99,"subtitle":"7th International Congress, Held as Part of the Services Conference Federation, SCF 2018, Seattle, WA, USA, June 25\u201330, 2018, Proceedings","description":"This volume constitutes the proceedings of the 7th International Conference on BIGDATA 2018, held as Part of SCF 2018 in Seattle, WA, USA in June 2018. The 22 full papers together with 10 short papers published in this volume were carefully reviewed and selected from 97 submissions. They are organized in topical sections such as Data analysis, data as a service, services computing, data conversion, data storage, data centers, dataflow architectures, data compression, data exchange, data modeling, databases, and data management.","language":"en","currency":"USD","id":"3319943014","title":"Big Data \u2013 BigData 2018","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=eSVhDwAAQBAJ&source=gbs_api","authors":["Francis Y. L. Chin","C. L. Philip Chen","Latifur Khan","Kisung Lee","Liang-Jie Zhang"]},{"pageCount":520,"thumbnail":"http:\/\/books.google.com\/books\/content?id=I6y3DQAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":24.99,"subtitle":"Import, Tidy, Transform, Visualize, and Model Data","description":"Learn how to use R to turn raw data into insight, knowledge, and understanding. This book introduces you to R, RStudio, and the tidyverse, a collection of R packages designed to work together to make data science fast, fluent, and fun. Suitable for readers with no previous programming experience, R for Data Science is designed to get you doing data science as quickly as possible. Authors Hadley Wickham and Garrett Grolemund guide you through the steps of importing, wrangling, exploring, and modeling your data and communicating the results. You\u2019ll get a complete, big-picture understanding of the data science cycle, along with basic tools you need to manage the details. Each section of the book is paired with exercises to help you practice what you\u2019ve learned along the way. You\u2019ll learn how to: Wrangle\u2014transform your datasets into a form convenient for analysis Program\u2014learn powerful R tools for solving data problems with greater clarity and ease Explore\u2014examine your data, generate hypotheses, and quickly test them Model\u2014provide a low-dimensional summary that captures true \"signals\" in your dataset Communicate\u2014learn R Markdown for integrating prose, code, and results","language":"en","currency":"USD","id":"1491910348","title":"R for Data Science","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=I6y3DQAAQBAJ&source=gbs_api","authors":["Hadley Wickham","Garrett Grolemund"]},{"pageCount":185,"thumbnail":"http:\/\/books.google.com\/books\/content?id=eQ5FDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":47.39,"subtitle":"9th TPC Technology Conference, TPCTC 2017, Munich, Germany, August 28, 2017, Revised Selected Papers","description":"This book constitutes the thoroughly refereed post-conference proceedings of the 8th TPC Technology Conference, on Performance Evaluation and Benchmarking, TPCTC 2017, held in conjunction with the43rd International Conference on Very Large Databases (VLDB 2017) in August\/September 2017. The 12 papers presented were carefully reviewed and selected from numeroussubmissions. The TPC remains committed to developing new benchmark standards to keep pace with these rapid changes in technology.","language":"en","currency":"USD","id":"3319724010","title":"Performance Evaluation and Benchmarking for the Analytics Era","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=eQ5FDwAAQBAJ&source=gbs_api","authors":["Raghunath Nambiar","Meikel Poess"]},{"pageCount":246,"thumbnail":"http:\/\/books.google.com\/books\/content?id=n1nTBgAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":16.54,"subtitle":null,"description":"If you're an application developer familiar with SQL databases such as MySQL or Postgres, and you want to explore distributed databases such as Cassandra, this is the perfect guide for you. Even if you've never worked with a distributed database before, Cassandra's intuitive programming interface coupled with the step-by-step examples in this book will have you building highly scalable persistence layers for your applications in no time.","language":"en","currency":"USD","id":"1783989211","title":"Learning Apache Cassandra","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=n1nTBgAAQBAJ&source=gbs_api","authors":["Mat Brown"]},{"pageCount":112,"thumbnail":"http:\/\/books.google.com\/books\/content?id=mi_WBgAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":12.64,"subtitle":null,"description":"This book is for readers who want to know more about Apache Kafka at a hands-on level; the key audience is those with software development experience but no prior exposure to Apache Kafka or similar technologies. It is also useful for enterprise application developers and big data enthusiasts who have worked with other publisher-subscriber-based systems and want to explore Apache Kafka as a futuristic solution.","language":"en","currency":"USD","id":"1784390275","title":"Learning Apache Kafka - Second Edition","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=mi_WBgAAQBAJ&source=gbs_api","authors":["Nishant Garg"]},{"pageCount":504,"thumbnail":"http:\/\/books.google.com\/books\/content?id=2brVAAAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":40,"subtitle":null,"description":"The go-to guidebook for deploying Big Data solutions withHadoop Today's enterprise architects need to understand how the Hadoopframeworks and APIs fit together, and how they can be integrated todeliver real-world solutions. This book is a practical, detailedguide to building and implementing those solutions, with code-levelinstruction in the popular Wrox tradition. It covers storing datawith HDFS and Hbase, processing data with MapReduce, and automatingdata processing with Oozie. Hadoop security, running Hadoop withAmazon Web Services, best practices, and automating Hadoopprocesses in real time are also covered in depth. With in-depth code examples in Java and XML and the latest onrecent additions to the Hadoop ecosystem, this complete resourcealso covers the use of APIs, exposing their inner workings andallowing architects and developers to better leverage and customizethem. The ultimate guide for developers, designers, and architectswho need to build and deploy Hadoop applications Covers storing and processing data with various technologies,automating data processing, Hadoop security, and deliveringreal-time solutions Includes detailed, real-world examples and code-levelguidelines Explains when, why, and how to use these tools effectively Written by a team of Hadoop experts in theprogrammer-to-programmer Wrox style Professional Hadoop Solutions is the reference enterprisearchitects and developers need to maximize the power of Hadoop.","language":"en","currency":"USD","id":"1118824180","title":"Professional Hadoop Solutions","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=2brVAAAAQBAJ&source=gbs_api","authors":["Boris Lublinsky","Kevin T. Smith","Alexey Yakubovich"]},{"pageCount":160,"thumbnail":"http:\/\/books.google.com\/books\/content?id=JGxzkNqAvsgC&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":9.99,"subtitle":null,"description":"RegEx is supported in all major development environments (for use in editing and working with code) and will thus appeal to anyone using these tools. In addition, every JavaScript developer should be using RegEx, but most don't as it has never been taught to them properly before. Developers using ASP, C#, ColdFusion, Java JSP, PHP, Perl, Python, and more can (and should) be using RegEx, and so every one of them is a potential reader too. The reader of this book will learn how to: Match characters sets Match repeating characters (using minimums and maximums if needed) Match (or ignore) based on case Build sub-expressions Use all of the special characters Work with excape sequences Use POSIX classes to simplify complex expressions Use back-references Use look-behind operators Sams Teach Yourself Regular Expressions in 10 Minutes is a tutorial book organized into a series of easy-to-follow 10-minute lessons. These well targeted lessons teach you in 10 minutes what other books might take hundreds of pages to cover. Instead of dwelling on syntax, terminology, and arcane examples and scenarios, this book takes a very hands-on approach to solving the needs of the majority of RegEx users who simply need to manipulate data.","language":"en","currency":"USD","id":"9780768689952","title":"Sams Teach Yourself Regular Expressions in 10 Minutes","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=JGxzkNqAvsgC&source=gbs_api","authors":["Ben Forta"]},{"pageCount":816,"thumbnail":"http:\/\/books.google.com\/books\/content?id=ZZ_6DwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":19.79,"subtitle":"A deep dive into distributed ledgers, consensus protocols, smart contracts, DApps, cryptocurrencies, Ethereum, and more, 3rd Edition","description":"Mastering Blockchain, Third Edition is the blockchain bible to equip you with extensive knowledge of distributed ledgers, cryptocurrencies, smart contracts, consensus algorithms, cryptography and blockchain platforms such as Ethereum, Bitcoin, and many more.","language":"en","currency":"USD","id":"1839211377","title":"Mastering Blockchain","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=ZZ_6DwAAQBAJ&source=gbs_api","authors":["Imran Bashir"]},{"pageCount":470,"thumbnail":"http:\/\/books.google.com\/books\/content?id=zvPtDQAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":96,"subtitle":null,"description":"Software Architecture for Big Data and the Cloud is designed to be a single resource that brings together research on how software architectures can solve the challenges imposed by building big data software systems. The challenges of big data on the software architecture can relate to scale, security, integrity, performance, concurrency, parallelism, and dependability, amongst others. Big data handling requires rethinking architectural solutions to meet functional and non-functional requirements related to volume, variety and velocity. The book's editors have varied and complementary backgrounds in requirements and architecture, specifically in software architectures for cloud and big data, as well as expertise in software engineering for cloud and big data. This book brings together work across different disciplines in software engineering, including work expanded from conference tracks and workshops led by the editors. Discusses systematic and disciplined approaches to building software architectures for cloud and big data with state-of-the-art methods and techniques Presents case studies involving enterprise, business, and government service deployment of big data applications Shares guidance on theory, frameworks, methodologies, and architecture for cloud and big data","language":"en","currency":"USD","id":"0128093382","title":"Software Architecture for Big Data and the Cloud","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=zvPtDQAAQBAJ&source=gbs_api","authors":["Ivan Mistrik","Rami Bahsoon","Nour Ali","Maritta Heisel","Bruce Maxim"]},{"pageCount":646,"thumbnail":"http:\/\/books.google.com\/books\/content?id=BVnHDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":22.99,"subtitle":"Regression, ConvNets, GANs, RNNs, NLP, and more with TensorFlow 2 and the Keras API, 2nd Edition","description":"Build machine and deep learning systems with the newly released TensorFlow 2 and Keras for the lab, production, and mobile devices Key Features Introduces and then uses TensorFlow 2 and Keras right from the start Teaches key machine and deep learning techniques Understand the fundamentals of deep learning and machine learning through clear explanations and extensive code samples Book Description Deep Learning with TensorFlow 2 and Keras, Second Edition teaches neural networks and deep learning techniques alongside TensorFlow (TF) and Keras. You\u2019ll learn how to write deep learning applications in the most powerful, popular, and scalable machine learning stack available. TensorFlow is the machine learning library of choice for professional applications, while Keras offers a simple and powerful Python API for accessing TensorFlow. TensorFlow 2 provides full Keras integration, making advanced machine learning easier and more convenient than ever before. This book also introduces neural networks with TensorFlow, runs through the main applications (regression, ConvNets (CNNs), GANs, RNNs, NLP), covers two working example apps, and then dives into TF in production, TF mobile, and using TensorFlow with AutoML. What you will learn Build machine learning and deep learning systems with TensorFlow 2 and the Keras API Use Regression analysis, the most popular approach to machine learning Understand ConvNets (convolutional neural networks) and how they are essential for deep learning systems such as image classifiers Use GANs (generative adversarial networks) to create new data that fits with existing patterns Discover RNNs (recurrent neural networks) that can process sequences of input intelligently, using one part of a sequence to correctly interpret another Apply deep learning to natural human language and interpret natural language texts to produce an appropriate response Train your models on the cloud and put TF to work in real environments Explore how Google tools can automate simple ML workflows without the need for complex modeling Who this book is for This book is for Python developers and data scientists who want to build machine learning and deep learning systems with TensorFlow. Whether or not you have done machine learning before, this book gives you the theory and practice required to use Keras, TensorFlow 2, and AutoML to build machine learning systems.","language":"en","currency":"USD","id":"1838827722","title":"Deep Learning with TensorFlow 2 and Keras","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=BVnHDwAAQBAJ&source=gbs_api","authors":["Antonio Gulli","Amita Kapoor","Sujit Pal"]},{"pageCount":250,"thumbnail":"http:\/\/books.google.com\/books\/content?id=io44nAL61JYC&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":31.19,"subtitle":"Building Effective Algorithms and Analytics for Hadoop and Other Systems","description":"Until now, design patterns for the MapReduce framework have been scattered among various research papers, blogs, and books. This handy guide brings together a unique collection of valuable MapReduce patterns that will save you time and effort regardless of the domain, language, or development framework you\u2019re using. Each pattern is explained in context, with pitfalls and caveats clearly identified to help you avoid common design mistakes when modeling your big data architecture. This book also provides a complete overview of MapReduce that explains its origins and implementations, and why design patterns are so important. All code examples are written for Hadoop. Summarization patterns: get a top-level view by summarizing and grouping data Filtering patterns: view data subsets such as records generated from one user Data organization patterns: reorganize data to work with other systems, or to make MapReduce analysis easier Join patterns: analyze different datasets together to discover interesting relationships Metapatterns: piece together several patterns to solve multi-stage problems, or to perform several analytics in the same job Input and output patterns: customize the way you use Hadoop to load or store data \"A clear exposition of MapReduce programs for common data processing patterns\u2014this book is indespensible for anyone using Hadoop.\" --Tom White, author of Hadoop: The Definitive Guide","language":"en","currency":"USD","id":"1449341985","title":"MapReduce Design Patterns","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=io44nAL61JYC&source=gbs_api","authors":["Donald Miner","Adam Shook"]},{"pageCount":378,"thumbnail":"http:\/\/books.google.com\/books\/content?id=C3MzDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":63.99,"subtitle":"8th International Conference of the CLEF Association, CLEF 2017, Dublin, Ireland, September 11\u201314, 2017, Proceedings","description":"This book constitutes the refereed proceedings of the 8th International Conference of the CLEF Initiative, CLEF 2017, held in Dublin, Ireland, in September 2017. The 7 full papers and 9 short papers presented together with 6 best of the labs papers were carefully reviewed and selected from 38 submissions. In addition, this volume contains the results of 10 benchmarking labs reporting their year long activities in overview talks and lab sessions. The papers address all aspects of information access in any modality and language and cover a broad range of topics in the field of multilingual and multimodal information access evaluation.","language":"en","currency":"USD","id":"3319658131","title":"Experimental IR Meets Multilinguality, Multimodality, and Interaction","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=C3MzDwAAQBAJ&source=gbs_api","authors":["Gareth J.F. Jones","Séamus Lawless","Julio Gonzalo","Liadh Kelly","Lorraine Goeuriot","Thomas Mandl","Linda Cappellato","Nicola Ferro"]},{"pageCount":725,"thumbnail":"http:\/\/books.google.com\/books\/content?id=AaQxDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":87.2,"subtitle":"23rd International Conference on Parallel and Distributed Computing, Santiago de Compostela, Spain, August 28 \u2013 September 1, 2017, Proceedings","description":"This book constitutes the proceedings of the 23rd International Conference on Parallel and Distributed Computing, Euro-Par 2017, held in Santiago de Compostela, Spain, in August\/September 2017. The 50 revised full papers presented together with 2 abstract of invited talks and 1 invited paper were carefully reviewed and selected from 176 submissions. The papers are organized in the following topical sections: support tools and environments; performance and power modeling, prediction and evaluation; scheduling and load balancing; high performance architectures and compilers; parallel and distributed data management and analytics; cluster and cloud computing; distributed systems and algorithms; parallel and distributed programming, interfaces and languages; multicore and manycore parallelism; theory and algorithms for parallel computation and networking; prallel numerical methods and applications; and accelerator computing.","language":"en","currency":"USD","id":"3319642030","title":"Euro-Par 2017: Parallel Processing","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=AaQxDwAAQBAJ&source=gbs_api","authors":["Francisco F. Rivera","Tomás F. Pena","José C. Cabaleiro"]},{"pageCount":754,"thumbnail":"http:\/\/books.google.com\/books\/content?id=KetiDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":87.2,"subtitle":"18th International Conference, Melbourne, VIC, Australia, July 2-5, 2018, Proceedings","description":"The five volume set LNCS 10960 until 10964 constitutes the refereed proceedings of the 18th International Conference on Computational Science and Its Applications, ICCSA 2018, held in Melbourne, Australia, in July 2018. Apart from the general tracks, ICCSA 2018 also includes 34 international workshops in various areas of computational sciences, ranging from computational science technologies, to specific areas of computational sciences, such as computer graphics and virtual reality. The total of 265 full papers and 10 short papers presented in the 5-volume proceedings set of ICCSA 2018, were carefully reviewed and selected from 892 submissions.","language":"en","currency":"USD","id":"3319951629","title":"Computational Science and Its Applications \u2013 ICCSA 2018","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=KetiDwAAQBAJ&source=gbs_api","authors":["Osvaldo Gervasi","Beniamino Murgante","Sanjay Misra","Elena Stankova","Carmelo M. Torre","Ana Maria A.C. Rocha","David Taniar","Bernady O. Apduhan","Eufemia Tarantino","Yeonseung Ryu"]},{"pageCount":416,"thumbnail":"http:\/\/books.google.com\/books\/content?id=wJApAgAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":18,"subtitle":null,"description":"Let Hadoop For Dummies help harness the power of yourdata and rein in the information overload Big data has become big business, and companies and organizationsof all sizes are struggling to find ways to retrieve valuableinformation from their massive data sets with becoming overwhelmed.Enter Hadoop and this easy-to-understand For Dummiesguide. Hadoop For Dummies helps readers understand thevalue of big data, make a business case for using Hadoop, navigatethe Hadoop ecosystem, and build and manage Hadoop applications andclusters. Explains the origins of Hadoop, its economic benefits, and itsfunctionality and practical applications Helps you find your way around the Hadoop ecosystem, programMapReduce, utilize design patterns, and get your Hadoop cluster upand running quickly and easily Details how to use Hadoop applications for data mining, webanalytics and personalization, large-scale text processing, datascience, and problem-solving Shows you how to improve the value of your Hadoop cluster,maximize your investment in Hadoop, and avoid common pitfalls whenbuilding your Hadoop cluster From programmers challenged with building and maintainingaffordable, scaleable data systems to administrators who must dealwith huge volumes of information effectively and efficiently, thishow-to has something to help you with Hadoop.","language":"en","currency":"USD","id":"1118652207","title":"Hadoop For Dummies","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=wJApAgAAQBAJ&source=gbs_api","authors":["Dirk deRoos"]},{"pageCount":496,"thumbnail":"http:\/\/books.google.com\/books\/content?id=EMzVpLXl8f8C&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":19.79,"subtitle":null,"description":"Sams Teach Yourself COBOL in 24 Hours teaches the basics of COBOL programming in 24 step-by-step lessons. Each lesson builds on the previous one providing a solid foundation in COBOL programming concepts and techniques. This hands-on guide is the easiest, fastest way to begin creating standard COBOL compliant code. Business professionals and programmers from other languages will find this hands-on, task-oriented tutorial extremely useful for learning the essential features and concepts of COBOL programming. Writing a program can be a complex task. Concentrating on one development tool guides you to good results every time. There will be no programs that will not compile!","language":"en","currency":"USD","id":"9780768685206","title":"Sams Teach Yourself COBOL in 24 Hours","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=EMzVpLXl8f8C&source=gbs_api","authors":["Thane Hubbell"]},{"pageCount":196,"thumbnail":"http:\/\/books.google.com\/books\/content?id=l86PDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":14.59,"subtitle":"Get up to speed with the newly introduced features of TensorFlow 2.0","description":"Perform supervised and unsupervised machine learning and learn advanced techniques such as training neural networks. Key Features Train your own models for effective prediction, using high-level Keras API Perform supervised and unsupervised machine learning and learn advanced techniques such as training neural networks Get acquainted with some new practices introduced in TensorFlow 2.0 Alpha Book Description TensorFlow is one of the most popular machine learning frameworks in Python. With this book, you will improve your knowledge of some of the latest TensorFlow features and will be able to perform supervised and unsupervised machine learning and also train neural networks. After giving you an overview of what's new in TensorFlow 2.0 Alpha, the book moves on to setting up your machine learning environment using the TensorFlow library. You will perform popular supervised machine learning tasks using techniques such as linear regression, logistic regression, and clustering. You will get familiar with unsupervised learning for autoencoder applications. The book will also show you how to train effective neural networks using straightforward examples in a variety of different domains. By the end of the book, you will have been exposed to a large variety of machine learning and neural network TensorFlow techniques. What you will learn Use tf.Keras for fast prototyping, building, and training deep learning neural network models Easily convert your TensorFlow 1.12 applications to TensorFlow 2.0-compatible files Use TensorFlow to tackle traditional supervised and unsupervised machine learning applications Understand image recognition techniques using TensorFlow Perform neural style transfer for image hybridization using a neural network Code a recurrent neural network in TensorFlow to perform text-style generation Who this book is for Data scientists, machine learning developers, and deep learning enthusiasts looking to quickly get started with TensorFlow 2 will find this book useful. Some Python programming experience with version 3.6 or later, along with a familiarity with Jupyter notebooks will be an added advantage. Exposure to machine learning and neural network techniques would also be helpful.","language":"en","currency":"USD","id":"1789536960","title":"TensorFlow 2.0 Quick Start Guide","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=l86PDwAAQBAJ&source=gbs_api","authors":["Tony Holdroyd"]},{"pageCount":298,"thumbnail":"http:\/\/books.google.com\/books\/content?id=TQqSwRScVhoC&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":31.81,"subtitle":"A Guide for Developers and Administrators","description":"If you\u2019ve been asked to maintain large and complex Hadoop clusters, this book is a must. Demand for operations-specific material has skyrocketed now that Hadoop is becoming the de facto standard for truly large-scale data processing in the data center. Eric Sammer, Principal Solution Architect at Cloudera, shows you the particulars of running Hadoop in production, from planning, installing, and configuring the system to providing ongoing maintenance. Rather than run through all possible scenarios, this pragmatic operations guide calls out what works, as demonstrated in critical deployments. Get a high-level overview of HDFS and MapReduce: why they exist and how they work Plan a Hadoop deployment, from hardware and OS selection to network requirements Learn setup and configuration details with a list of critical properties Manage resources by sharing a cluster across multiple groups Get a runbook of the most common cluster maintenance tasks Monitor Hadoop clusters\u2014and learn troubleshooting with the help of real-world war stories Use basic tools and techniques to handle backup and catastrophic failure","language":"en","currency":"USD","id":"144932729X","title":"Hadoop Operations","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=TQqSwRScVhoC&source=gbs_api","authors":["Eric Sammer"]},{"pageCount":382,"thumbnail":"http:\/\/books.google.com\/books\/content?id=gJZGDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":31.19,"subtitle":null,"description":"Extract patterns and knowledge from your data in easy way using MATLAB About This Book Get your first steps into machine learning with the help of this easy-to-follow guide Learn regression, clustering, classification, predictive analytics, artificial neural networks and more with MATLAB Understand how your data works and identify hidden layers in the data with the power of machine learning. Who This Book Is For This book is for data analysts, data scientists, students, or anyone who is looking to get started with machine learning and want to build efficient data processing and predicting applications. A mathematical and statistical background will really help in following this book well. What You Will Learn Learn the introductory concepts of machine learning. Discover different ways to transform data using SAS XPORT, import and export tools, Explore the different types of regression techniques such as simple & multiple linear regression, ordinary least squares estimation, correlations and how to apply them to your data. Discover the basics of classification methods and how to implement Naive Bayes algorithm and Decision Trees in the Matlab environment. Uncover how to use clustering methods like hierarchical clustering to grouping data using the similarity measures. Know how to perform data fitting, pattern recognition, and clustering analysis with the help of MATLAB Neural Network Toolbox. Learn feature selection and extraction for dimensionality reduction leading to improved performance. In Detail MATLAB is the language of choice for many researchers and mathematics experts for machine learning. This book will help you build a foundation in machine learning using MATLAB for beginners. You'll start by getting your system ready with t he MATLAB environment for machine learning and you'll see how to easily interact with the Matlab workspace. We'll then move on to data cleansing, mining and analyzing various data types in machine learning and you'll see how to display data values on a plot. Next, you'll get to know about the different types of regression techniques and how to apply them to your data using the MATLAB functions. You'll understand the basic concepts of neural networks and perform data fitting, pattern recognition, and clustering analysis. Finally, you'll explore feature selection and extraction techniques for dimensionality reduction for performance improvement. At the end of the book, you will learn to put it all together into real-world cases covering major machine learning algorithms and be comfortable in performing machine learning with MATLAB. Style and approach The book takes a very comprehensive approach to enhance your understanding of machine learning using MATLAB. Sufficient real-world examples and use cases are included in the book to help you grasp the concepts quickly and apply them easily in your day-to-day work.","language":"en","currency":"USD","id":"1788399390","title":"MATLAB for Machine Learning","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=gJZGDwAAQBAJ&source=gbs_api","authors":["Giuseppe Ciaburro"]},{"pageCount":699,"thumbnail":"http:\/\/books.google.com\/books\/content?id=Yy7RDAAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":79.2,"subtitle":"22nd International Conference on Parallel and Distributed Computing, Grenoble, France, August 24-26, 2016, Proceedings","description":"This book constitutes the refereed proceedings of the 22nd International Conference on Parallel and Distributed Computing, Euro-Par 2016, held in Grenoble, France, in August 2016. The 47 revised full papers presented together with 2 invited papers and one industrial paper were carefully reviewed and selected from 176 submissions. The papers are organized in 12 topical sections: Support Tools and Environments; Performance and Power Modeling, Prediction and Evaluation; Scheduling and Load Balancing; High Performance Architectures and Compilers; Parallel and Distributed Data Management and Analytics; Cluster and Cloud Computing; Distributed Systems and Algorithms; Parallel and Distributed Programming, Interfaces, Languages; Multicore and Manycore Parallelism; Theory and Algorithms for Parallel Computation and Networking; Parallel Numerical Methods and Applications; Accelerator Computing.","language":"en","currency":"USD","id":"3319436597","title":"Euro-Par 2016: Parallel Processing","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=Yy7RDAAAQBAJ&source=gbs_api","authors":["Pierre-François Dutot","Denis Trystram"]},{"pageCount":416,"thumbnail":"http:\/\/books.google.com\/books\/content?id=0HW7DwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":37.49,"subtitle":"Theory and Practice in Python","description":"The Contemporary Introduction to Deep Reinforcement Learning that Combines Theory and Practice Deep reinforcement learning (deep RL) combines deep learning and reinforcement learning, in which artificial agents learn to solve sequential decision-making problems. In the past decade deep RL has achieved remarkable results on a range of problems, from single and multiplayer games\u2014such as Go, Atari games, and DotA 2\u2014to robotics. Foundations of Deep Reinforcement Learning is an introduction to deep RL that uniquely combines both theory and implementation. It starts with intuition, then carefully explains the theory of deep RL algorithms, discusses implementations in its companion software library SLM Lab, and finishes with the practical details of getting deep RL to work. This guide is ideal for both computer science students and software engineers who are familiar with basic machine learning concepts and have a working understanding of Python. Understand each key aspect of a deep RL problem Explore policy- and value-based algorithms, including REINFORCE, SARSA, DQN, Double DQN, and Prioritized Experience Replay (PER) Delve into combined algorithms, including Actor-Critic and Proximal Policy Optimization (PPO) Understand how algorithms can be parallelized synchronously and asynchronously Run algorithms in SLM Lab and learn the practical implementation details for getting deep RL to work Explore algorithm benchmark results with tuned hyperparameters Understand how deep RL environments are designed Register your book for convenient access to downloads, updates, and\/or corrections as they become available. See inside book for details.","language":"en","currency":"USD","id":"0135172489","title":"Foundations of Deep Reinforcement Learning","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=0HW7DwAAQBAJ&source=gbs_api","authors":["Laura Graesser","Wah Loon Keng"]},{"pageCount":288,"thumbnail":"http:\/\/books.google.com\/books\/content?id=tmbgBwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":87.2,"subtitle":null,"description":"This Guide to Sun Administration is areference manual written by Sun administrators for Sun administrators. The book is not in tended to be a complete guide to UNIX Systems Administration; instead it will concentrate on the special issues that are particular to the Sun environment. It will take you through the basic steps necessary to install and maintain a network of Sun computers. Along the way, helpful ideas will be given concerning NFS, YP, backup and restore procedures, as well as many useful installation tips that can make a system administrator's job less painful. Spe cifically, SunGS 4.0 through 4.0.3 will be studied; however, many ofthe ideas and concepts presented are generic enough to be used on any version of SunGS. This book is not intended to be basic introduction to SunGS. It is assumed thatthe reader will have at least a year ofexperience supporting UNIX. BookOverview The firstchaptergives adescription ofthe system types thatwill be discussed throughout the book. An understanding of all of the system types is needed to comprehend the rest ofthe book. Chapter 2 provides the information necessary to install a workstation. The format utility and the steps involved in the suninstall process are covered in detail. Ideas and concepts about partitioning are included in this chapter. YP is the topic of the third chapter. A specific description of each YPmap and each YPcommand ispresented, along with some tips about ways to best utilize this package in your environment.","language":"en","currency":"USD","id":"1441987169","title":"A System Administrator\u2019s Guide to Sun Workstations","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=tmbgBwAAQBAJ&source=gbs_api","authors":["George Becker","Kathy Slattery"]},{"pageCount":400,"thumbnail":"http:\/\/books.google.com\/books\/content?id=vbQlDQAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":29.99,"subtitle":"A Guide for Data Scientists","description":"Machine learning has become an integral part of many commercial applications and research projects, but this field is not exclusive to large companies with extensive research teams. If you use Python, even as a beginner, this book will teach you practical ways to build your own machine learning solutions. With all the data available today, machine learning applications are limited only by your imagination. You\u2019ll learn the steps necessary to create a successful machine-learning application with Python and the scikit-learn library. Authors Andreas Müller and Sarah Guido focus on the practical aspects of using machine learning algorithms, rather than the math behind them. Familiarity with the NumPy and matplotlib libraries will help you get even more from this book. With this book, you\u2019ll learn: Fundamental concepts and applications of machine learning Advantages and shortcomings of widely used machine learning algorithms How to represent data processed by machine learning, including which data aspects to focus on Advanced methods for model evaluation and parameter tuning The concept of pipelines for chaining models and encapsulating your workflow Methods for working with text data, including text-specific processing techniques Suggestions for improving your machine learning and data science skills","language":"en","currency":"USD","id":"1449369898","title":"Introduction to Machine Learning with Python","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=vbQlDQAAQBAJ&source=gbs_api","authors":["Andreas C. Müller","Sarah Guido"]},{"pageCount":416,"thumbnail":"http:\/\/books.google.com\/books\/content?id=mcBIDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":71.96,"subtitle":null,"description":"The field of multimedia is unique in offering a rich and dynamic forum for researchers from \u201Ctraditional\u201D fields to collaborate and develop new solutions and knowledge that transcend the boundaries of individual disciplines. Despite the prolific research activities and outcomes, however, few efforts have been made to develop books that serve as an introduction to the rich spectrum of topics covered by this broad field. A few books are available that either focus on specific subfields or basic background in multimedia. Tutorial-style materials covering the active topics being pursued by the leading researchers at frontiers of the field are currently lacking. In 2015, ACM SIGMM, the special interest group on multimedia, launched a new initiative to address this void by selecting and inviting 12 rising-star speakers from different subfields of multimedia research to deliver plenary tutorial-style talks at the ACM Multimedia conference for 2015. Each speaker discussed the challenges and state-of-the-art developments of their prospective research areas in a general manner to the broad community. The covered topics were comprehensive, including multimedia content understanding, multimodal human-human and human-computer interaction, multimedia social media, and multimedia system architecture and deployment. Following the very positive responses to these talks, the speakers were invited to expand the content covered in their talks into chapters that can be used as reference material for researchers, students, and practitioners. Each chapter discusses the problems, technical challenges, state-of-the-art approaches and performances, open issues, and promising direction for future work. Collectively, the chapters provide an excellent sampling of major topics addressed by the community as a whole. This book, capturing some of the outcomes of such efforts, is well positioned to fill the aforementioned needs in providing tutorial-style reference materials for frontier topics in multimedia. At the same time, the speed and sophistication required of data processing have grown. In addition to simple queries, complex algorithms like machine learning and graph analysis are becoming common. And in addition to batch processing, streaming analysis of real-time data is required to let organizations take timely action. Future computing platforms will need to not only scale out traditional workloads, but support these new applications too. This book, a revised version of the 2014 ACM Dissertation Award winning dissertation, proposes an architecture for cluster computing systems that can tackle emerging data processing workloads at scale. Whereas early cluster computing systems, like MapReduce, handled batch processing, our architecture also enables streaming and interactive queries, while keeping MapReduce's scalability and fault tolerance. And whereas most deployed systems only support simple one-pass computations (e.g., SQL queries), ours also extends to the multi-pass algorithms required for complex analytics like machine learning. Finally, unlike the specialized systems proposed for some of these workloads, our architecture allows these computations to be combined, enabling rich new applications that intermix, for example, streaming and batch processing. We achieve these results through a simple extension to MapReduce that adds primitives for data sharing, called Resilient Distributed Datasets (RDDs). We show that this is enough to capture a wide range of workloads. We implement RDDs in the open source Spark system, which we evaluate using synthetic and real workloads. Spark matches or exceeds the performance of specialized systems in many domains, while offering stronger fault tolerance properties and allowing these workloads to be combined. Finally, we examine the generality of RDDs from both a theoretical modeling perspective and a systems perspective. This version of the dissertation makes corrections throughout the text and adds a new section on the evolution of Apache Spark in industry since 2014. In addition, editing, formatting, and links for the references have been added.","language":"en","currency":"USD","id":"1970001062","title":"Frontiers of Multimedia Research","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=mcBIDwAAQBAJ&source=gbs_api","authors":["Shih-Fu Chang"]}]