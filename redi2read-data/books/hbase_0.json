[{"pageCount":556,"thumbnail":"http:\/\/books.google.com\/books\/content?id=nUhiQxUXVpMC&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":17.27,"subtitle":"Random Access to Your Planet-Size Data","description":"If you're looking for a scalable storage solution to accommodate a virtually endless amount of data, this book shows you how Apache HBase can fulfill your needs. As the open source implementation of Google's BigTable architecture, HBase scales to billions of rows and millions of columns, while ensuring that write and read performance remain constant. Many IT executives are asking pointed questions about HBase. This book provides meaningful answers, whether you\u2019re evaluating this non-relational database or planning to put it into practice right away. Discover how tight integration with Hadoop makes scalability with HBase easier Distribute large datasets across an inexpensive cluster of commodity servers Access HBase with native Java clients, or with gateway servers providing REST, Avro, or Thrift APIs Get details on HBase\u2019s architecture, including the storage format, write-ahead log, background processes, and more Integrate HBase with Hadoop's MapReduce framework for massively parallelized data processing jobs Learn how to tune clusters, design schemas, copy tables, import bulk data, decommission nodes, and many other tasks","language":"en","currency":"USD","id":"1449315224","title":"HBase: The Definitive Guide","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=nUhiQxUXVpMC&source=gbs_api","authors":["Lars George"]},{"pageCount":326,"thumbnail":"http:\/\/books.google.com\/books\/content?id=R_CZBQAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":16.54,"subtitle":null,"description":"If you are an administrator or developer who wants to enter the world of Big Data and BigTables and would like to learn about HBase, this is the book for you.","language":"en","currency":"USD","id":"178398595X","title":"Learning HBase","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=R_CZBQAAQBAJ&source=gbs_api","authors":["Shashwat Shriparv"]},{"pageCount":332,"thumbnail":"http:\/\/books.google.com\/books\/content?id=QDZm1juBH1YC&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":18.49,"subtitle":null,"description":"As part of Packt's cookbook series, each recipe offers a practical, step-by-step solution to common problems found in HBase administration. This book is for HBase administrators, developers, and will even help Hadoop administrators. You are not required to have HBase experience, but are expected to have a basic understanding of Hadoop and MapReduce.","language":"en","currency":"USD","id":"1849517150","title":"Hbase Administration Cookbook","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=QDZm1juBH1YC&source=gbs_api","authors":["Yifeng Jiang"]},{"pageCount":252,"thumbnail":"http:\/\/books.google.com\/books\/content?id=yPywDAAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":18.35,"subtitle":"A Guidebook for Successful Development and Design","description":"HBase is a remarkable tool for indexing mass volumes of data, but getting started with this distributed database and its ecosystem can be daunting. With this hands-on guide, you\u2019ll learn how to architect, design, and deploy your own HBase applications by examining real-world solutions. Along with HBase principles and cluster deployment guidelines, this book includes in-depth case studies that demonstrate how large companies solved specific use cases with HBase. Authors Jean-Marc Spaggiari and Kevin O\u2019Dell also provide draft solutions and code examples to help you implement your own versions of those use cases, from master data management (MDM) and document storage to near real-time event processing. You\u2019ll also learn troubleshooting techniques to help you avoid common deployment mistakes. Learn exactly what HBase does, what its ecosystem includes, and how to set up your environment Explore how real-world HBase instances were deployed and put into production Examine documented use cases for tracking healthcare claims, digital advertising, data management, and product quality Understand how HBase works with tools and techniques such as Spark, Kafka, MapReduce, and the Java API Learn how to identify the causes and understand the consequences of the most common HBase issues","language":"en","currency":"USD","id":"1491916109","title":"Architecting HBase Applications","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=yPywDAAAQBAJ&source=gbs_api","authors":["Jean-Marc Spaggiari","Kevin O'Dell"]},{"pageCount":556,"thumbnail":"http:\/\/books.google.com\/books\/content?id=nUhiQxUXVpMC&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":17.27,"subtitle":"Random Access to Your Planet-Size Data","description":"If you're looking for a scalable storage solution to accommodate a virtually endless amount of data, this book shows you how Apache HBase can fulfill your needs. As the open source implementation of Google's BigTable architecture, HBase scales to billions of rows and millions of columns, while ensuring that write and read performance remain constant. Many IT executives are asking pointed questions about HBase. This book provides meaningful answers, whether you\u2019re evaluating this non-relational database or planning to put it into practice right away. Discover how tight integration with Hadoop makes scalability with HBase easier Distribute large datasets across an inexpensive cluster of commodity servers Access HBase with native Java clients, or with gateway servers providing REST, Avro, or Thrift APIs Get details on HBase\u2019s architecture, including the storage format, write-ahead log, background processes, and more Integrate HBase with Hadoop's MapReduce framework for massively parallelized data processing jobs Learn how to tune clusters, design schemas, copy tables, import bulk data, decommission nodes, and many other tasks","language":"en","currency":"USD","id":"1449315224","title":"HBase: The Definitive Guide","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=nUhiQxUXVpMC&source=gbs_api","authors":["Lars George"]},{"pageCount":252,"thumbnail":"http:\/\/books.google.com\/books\/content?id=yPywDAAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":18.35,"subtitle":"A Guidebook for Successful Development and Design","description":"HBase is a remarkable tool for indexing mass volumes of data, but getting started with this distributed database and its ecosystem can be daunting. With this hands-on guide, you\u2019ll learn how to architect, design, and deploy your own HBase applications by examining real-world solutions. Along with HBase principles and cluster deployment guidelines, this book includes in-depth case studies that demonstrate how large companies solved specific use cases with HBase. Authors Jean-Marc Spaggiari and Kevin O\u2019Dell also provide draft solutions and code examples to help you implement your own versions of those use cases, from master data management (MDM) and document storage to near real-time event processing. You\u2019ll also learn troubleshooting techniques to help you avoid common deployment mistakes. Learn exactly what HBase does, what its ecosystem includes, and how to set up your environment Explore how real-world HBase instances were deployed and put into production Examine documented use cases for tracking healthcare claims, digital advertising, data management, and product quality Understand how HBase works with tools and techniques such as Spark, Kafka, MapReduce, and the Java API Learn how to identify the causes and understand the consequences of the most common HBase issues","language":"en","currency":"USD","id":"1491916109","title":"Architecting HBase Applications","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=yPywDAAAQBAJ&source=gbs_api","authors":["Jean-Marc Spaggiari","Kevin O'Dell"]},{"pageCount":326,"thumbnail":"http:\/\/books.google.com\/books\/content?id=R_CZBQAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":16.54,"subtitle":null,"description":"If you are an administrator or developer who wants to enter the world of Big Data and BigTables and would like to learn about HBase, this is the book for you.","language":"en","currency":"USD","id":"178398595X","title":"Learning HBase","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=R_CZBQAAQBAJ&source=gbs_api","authors":["Shashwat Shriparv"]},{"pageCount":151,"thumbnail":"http:\/\/books.google.com\/books\/content?id=P8-GDQAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":16.19,"subtitle":null,"description":"Learn the fundamental foundations and concepts of the Apache HBase (NoSQL) open source database. It covers the HBase data model, architecture, schema design, API, and administration. Apache HBase is the database for the Apache Hadoop framework. HBase is a column family based NoSQL database that provides a flexible schema model. What You'll Learn Work with the core concepts of HBase Discover the HBase data model, schema design, and architecture Use the HBase API and administration Who This Book Is For Apache HBase (NoSQL) database users, designers, developers, and admins.","language":"en","currency":"USD","id":"1484224248","title":"Apache HBase Primer","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=P8-GDQAAQBAJ&source=gbs_api","authors":["Deepak Vohra"]},{"pageCount":350,"thumbnail":"http:\/\/books.google.com\/books\/content?id=0VMoDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":31.19,"subtitle":null,"description":"Exciting projects that will teach you how complex data can be exploited to gain maximum insights About This Book Architect a good HBase cluster for a very large distributed system Get to grips with the concepts of performance tuning with HBase A practical guide full of engaging recipes and attractive screenshots to enhance your system's performance Who This Book Is For This book is intended for developers and architects who want to know all about HBase at a hands-on level. This book is also for big data enthusiasts and database developers who have worked with other NoSQL databases and now want to explore HBase as another futuristic scalable database solution in the big data space. What You Will Learn Configure HBase from a high performance perspective Grab data from various RDBMS\/Flat files into the HBASE systems Understand table design and perform CRUD operations Find out how the communication between the client and server happens in HBase Grasp when to use and avoid MapReduce and how to perform various tasks with it Get to know the concepts of scaling with HBase through practical examples Set up Hbase in the Cloud for a small scale environment Integrate HBase with other tools including ElasticSearch In Detail Apache HBase is a non-relational NoSQL database management system that runs on top of HDFS. It is an open source, disturbed, versioned, column-oriented store and is written in Java to provide random real-time access to big Data. We'll start off by ensuring you have a solid understanding the basics of HBase, followed by giving you a thorough explanation of architecting a HBase cluster as per our project specifications. Next, we will explore the scalable structure of tables and we will be able to communicate with the HBase client. After this, we'll show you the intricacies of MapReduce and the art of performance tuning with HBase. Following this, we'll explain the concepts pertaining to scaling with HBase. Finally, you will get an understanding of how to integrate HBase with other tools such as ElasticSearch. By the end of this book, you will have learned enough to exploit HBase for boost system performance. Style and approach This book is intended for software quality assurance\/testing professionals, software project managers, or software developers with prior experience in using Selenium and Java to test web-based applications. This books also provides examples for C#, Python, and Ruby users.","language":"en","currency":"USD","id":"1783983078","title":"HBase High Performance Cookbook","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=0VMoDwAAQBAJ&source=gbs_api","authors":["Ruchir Choudhry"]},{"pageCount":164,"thumbnail":"http:\/\/books.google.com\/books\/content?id=JJtsBQAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":12.64,"subtitle":null,"description":"This book is intended for developers and Big Data engineers who want to know all about HBase at a hands-on level. For in-depth understanding, it would be helpful to have a bit of familiarity with HDFS and MapReduce programming concepts with no prior experience with HBase or similar technologies. This book is also for Big Data enthusiasts and database developers who have worked with other NoSQL databases and now want to explore HBase as another futuristic, scalable database solution in the Big Data space.","language":"en","currency":"USD","id":"1783987251","title":"HBase Essentials","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=JJtsBQAAQBAJ&source=gbs_api","authors":["Nishant Garg"]},{"pageCount":150,"thumbnail":"http:\/\/books.google.com\/books\/content?id=Q9AGBgAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":11.99,"subtitle":null,"description":"If you are an intermediate NoSQL developer or have a few big data projects under your belt, you will learn how to increase your chances of a successful and useful NoSQL application by mastering the design patterns described in the book. The HBase design patterns apply equally well to Cassandra, MongoDB, and so on.","language":"en","currency":"USD","id":"1783981059","title":"HBase Design Patterns","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=Q9AGBgAAQBAJ&source=gbs_api","authors":["Mark Kerzner","Sujee Maniyam"]},{"pageCount":332,"thumbnail":"http:\/\/books.google.com\/books\/content?id=QDZm1juBH1YC&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":18.49,"subtitle":null,"description":"As part of Packt's cookbook series, each recipe offers a practical, step-by-step solution to common problems found in HBase administration. This book is for HBase administrators, developers, and will even help Hadoop administrators. You are not required to have HBase experience, but are expected to have a basic understanding of Hadoop and MapReduce.","language":"en","currency":"USD","id":"1849517150","title":"Hbase Administration Cookbook","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=QDZm1juBH1YC&source=gbs_api","authors":["Yifeng Jiang"]},{"pageCount":432,"thumbnail":"http:\/\/books.google.com\/books\/content?id=J94WBgAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":48,"subtitle":"Discovering, Analyzing, Visualizing and Presenting Data","description":"Data Science and Big Data Analytics is about harnessing the power of data for new insights. The book covers the breadth of activities and methods and tools that Data Scientists use. The content focuses on concepts, principles and practical applications that are applicable to any industry and technology environment, and the learning is supported and explained with examples that you can replicate using open-source software. This book will help you: Become a contributor on a data science team Deploy a structured lifecycle approach to data analytics problems Apply appropriate analytic techniques and tools to analyzing big data Learn how to tell a compelling story with data to drive business action Prepare for EMC Proven Professional Data Science Certification Corresponding data sets are available from the book\u2019s page at Wiley which you can find on the Wiley site by searching for the ISBN 9781118876138. Get started discovering, analyzing, visualizing, and presenting data in a meaningful way today!","language":"en","currency":"USD","id":"1118876059","title":"Data Science and Big Data Analytics","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=J94WBgAAQBAJ&source=gbs_api","authors":["EMC Education Services"]},{"pageCount":182,"thumbnail":"http:\/\/books.google.com\/books\/content?id=3cEDEAAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":10.92,"subtitle":"HADOOP, HBASE ve HIVE ile çözümlemeler. Veri işleme, kaydetme ve görselleştirme.","description":"ADIM ADIM BIGDATA VE UYGULAMALARI \u2022 HADOOP, HBASE ve HIVE ile ÇÖZÜMLEMELER \u2022 VERİ İŞLEME, KAYDETME ve GÖRSELLEŞTİRME BigData'nın miktarı, oluşma hızı ve çeşitliliği her geçen gün katlanarak artıyor. Tüm kurumların ilgisi, BigData'yı doğru işleyebilmek, işine yarar verileri süzebilmek ve anlamlandırmak üzerine. Peki ama bunca büyük verinin arasında aradığımızı nasıl bulacağız? Büyük Veri kullanımı için farklı yollar mevcut olsa da, hangi uygulamanın bizim çözümümüz için daha uygun olduğunu belirlemek zorundayız. Bu konu için farklı yaklaşımlar gerekmekte olup, bunlar ancak birlikte kullanıldığı zaman gerçek potansiyelleri ortaya çıkmaktadır. Burada kastettiğimiz; Hadoop yanı sıra, NoSQL veritabanı, büyük miktarda veriler için; veri ambarları bileşenleri, MapReduce, YARN ve Spark programlama modelleri ve bu tarz yaklaşımları barındıran mevcut çözümler, veri madenciliği veya Extract-Transform-Load (ETL - ayıklama, dönüştürme, yükleme) süreci gibi BigData mantığıyla uyuşabilecek araçların birlikte kullanılmasıdır. Kitapta, örneklerle birlikte veri üretme ve bu verilerin nasıl işleneceği adım adım anlatılıyor. Bu alandaki en güncel ve stabil program versiyonlarını ve kullanılan son teknolojiler paylaşılıyor. Kitabı bitirdiğinizde BigData\u2019nın nasıl kullanıldığına, arka planda nasıl çalıştığına ve hangi kodlamaların ve teknolojilerin gerektiğine hakim olacaksınız. Kitap, konuları süresince aynı doğrultuda projelerle ilerlediği için, okurken ve uygularken sıkılmayacaksınız. Ayrıca uygulama yaparken bazı yerlerde karşılaşabileceğiniz hatalar da notlar halinde verilerek yazılımda ilerlemeniniz kolaylaştırılıyor. \u2022 BIGDATA TERİMİ \u2022 ENDÜSTRİLERİN BIGDATA\u2019YA BAKIŞI \u2022 HADOOP\u2019A GİRİŞ \u2022 HDFS - HADOOP DAĞITILMIŞ DOSYA SİSTEMİ \u2022 MAPREDUCE \u2022 KÜMELERİ (CLUSTERS) İŞLEMEK \u2022 YARN UYGULAMALARI \u2022 HADOOP EKOSİSTEMİ \u2022 NOSQL \u2022 VERİ TAŞIMA YÖNTEMLERİ \u2022 SQL ve DOSYA SİSTEMLERİNDEN NOSQL veya HDFS\u2019YE AKTARIM \u2022 HBASE \u2022 SQOOP ile VERİTABANINDAN VERİ ÇIKARIMI \u2022 HIVE ile DATA WAREHOUSING \u2022 SORGULAMA OLARAK HIVESQL KULLANIMI \u2022 BIGDATA GÖRSELLEŞTİRME \u2022 BASİT GÖRSELLEŞTİRME BİLEŞENİNİN GELİŞTİRİLMESİ","language":"tr","currency":"USD","id":"605235965X","title":"Adım Adım BigData ve Uygulamaları","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=3cEDEAAAQBAJ&source=gbs_api","authors":["Deniz Herand","Mehmet Işık"]},{"pageCount":322,"thumbnail":"http:\/\/books.google.com\/books\/content?id=T1fTBgAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":18.49,"subtitle":null,"description":"If you are a Big Data enthusiast and wish to use Hadoop v2 to solve your problems, then this book is for you. This book is for Java programmers with little to moderate knowledge of Hadoop MapReduce. This is also a one-stop reference for developers and system admins who want to quickly get up to speed with using Hadoop v2. It would be helpful to have a basic knowledge of software development using Java and a basic working knowledge of Linux.","language":"en","currency":"USD","id":"1783285486","title":"Hadoop MapReduce v2 Cookbook - Second Edition","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=T1fTBgAAQBAJ&source=gbs_api","authors":["Thilina Gunarathne"]},{"pageCount":528,"thumbnail":"http:\/\/books.google.com\/books\/content?id=bKPEwR-Pt6EC&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":19.79,"subtitle":"The Definitive Guide","description":"Hadoop: The Definitive Guide helps you harness the power of your data. Ideal for processing large datasets, the Apache Hadoop framework is an open source implementation of the MapReduce algorithm on which Google built its empire. This comprehensive resource demonstrates how to use Hadoop to build reliable, scalable, distributed systems: programmers will find details for analyzing large datasets, and administrators will learn how to set up and run Hadoop clusters. Complete with case studies that illustrate how Hadoop solves specific problems, this book helps you: Use the Hadoop Distributed File System (HDFS) for storing large datasets, and run distributed computations over those datasets using MapReduce Become familiar with Hadoop's data and I\/O building blocks for compression, data integrity, serialization, and persistence Discover common pitfalls and advanced features for writing real-world MapReduce programs Design, build, and administer a dedicated Hadoop cluster, or run Hadoop in the cloud Use Pig, a high-level query language for large-scale data processing Take advantage of HBase, Hadoop's database for structured and semi-structured data Learn ZooKeeper, a toolkit of coordination primitives for building distributed systems If you have lots of data -- whether it's gigabytes or petabytes -- Hadoop is the perfect solution. Hadoop: The Definitive Guide is the most thorough book available on the subject. \"Now you have the opportunity to learn about Hadoop from a master-not only of the technology, but also of common sense and plain talk.\"-- Doug Cutting, Hadoop Founder, Yahoo!","language":"en","currency":"USD","id":"9780596551360","title":"Hadoop: The Definitive Guide","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=bKPEwR-Pt6EC&source=gbs_api","authors":["Tom White"]},{"pageCount":504,"thumbnail":"http:\/\/books.google.com\/books\/content?id=2brVAAAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":40,"subtitle":null,"description":"The go-to guidebook for deploying Big Data solutions withHadoop Today's enterprise architects need to understand how the Hadoopframeworks and APIs fit together, and how they can be integrated todeliver real-world solutions. This book is a practical, detailedguide to building and implementing those solutions, with code-levelinstruction in the popular Wrox tradition. It covers storing datawith HDFS and Hbase, processing data with MapReduce, and automatingdata processing with Oozie. Hadoop security, running Hadoop withAmazon Web Services, best practices, and automating Hadoopprocesses in real time are also covered in depth. With in-depth code examples in Java and XML and the latest onrecent additions to the Hadoop ecosystem, this complete resourcealso covers the use of APIs, exposing their inner workings andallowing architects and developers to better leverage and customizethem. The ultimate guide for developers, designers, and architectswho need to build and deploy Hadoop applications Covers storing and processing data with various technologies,automating data processing, Hadoop security, and deliveringreal-time solutions Includes detailed, real-world examples and code-levelguidelines Explains when, why, and how to use these tools effectively Written by a team of Hadoop experts in theprogrammer-to-programmer Wrox style Professional Hadoop Solutions is the reference enterprisearchitects and developers need to maximize the power of Hadoop.","language":"en","currency":"USD","id":"1118824180","title":"Professional Hadoop Solutions","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=2brVAAAAQBAJ&source=gbs_api","authors":["Boris Lublinsky","Kevin T. Smith","Alexey Yakubovich"]},{"pageCount":178,"thumbnail":"http:\/\/books.google.com\/books\/content?id=S-ZrBgAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":12.64,"subtitle":null,"description":"If you want to discover one of the latest tools designed to produce stunning Big Data insights, this book features everything you need to get to grips with your data. Whether you are a data architect, developer, or a business strategist, HDInsight adds value in everything from development, administration, and reporting.","language":"en","currency":"USD","id":"1784396664","title":"HDInsight Essentials - Second Edition","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=S-ZrBgAAQBAJ&source=gbs_api","authors":["Rajesh Nadipalli"]},{"pageCount":408,"thumbnail":"http:\/\/books.google.com\/books\/content?id=ISLwAgAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":32.99,"subtitle":null,"description":"Tap the power of Big Data with Microsoft technologies Big Data is here, and Microsoft's new Big Data platform is a valuable tool to help your company get the very most out of it. This timely book shows you how to use HDInsight along with HortonWorks Data Platform for Windows to store, manage, analyze, and share Big Data throughout the enterprise. Focusing primarily on Microsoft and HortonWorks technologies but also covering open source tools, Microsoft Big Data Solutions explains best practices, covers on-premises and cloud-based solutions, and features valuable case studies. Best of all, it helps you integrate these new solutions with technologies you already know, such as SQL Server and Hadoop. Walks you through how to integrate Big Data solutions in your company using Microsoft's HDInsight Server, HortonWorks Data Platform for Windows, and open source tools Explores both on-premises and cloud-based solutions Shows how to store, manage, analyze, and share Big Data through the enterprise Covers topics such as Microsoft's approach to Big Data, installing and configuring HortonWorks Data Platform for Windows, integrating Big Data with SQL Server, visualizing data with Microsoft and HortonWorks BI tools, and more Helps you build and execute a Big Data plan Includes contributions from the Microsoft and HortonWorks Big Data product teams If you need a detailed roadmap for designing and implementing a fully deployed Big Data solution, you'll want Microsoft Big Data Solutions.","language":"en","currency":"USD","id":"1118729552","title":"Microsoft Big Data Solutions","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=ISLwAgAAQBAJ&source=gbs_api","authors":["Adam Jorgensen","James Rowland-Jones","John Welch","Dan Clark","Christopher Price","Brian Mitchell"]},{"pageCount":456,"thumbnail":"http:\/\/books.google.com\/books\/content?id=O_UwBgAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":21,"subtitle":null,"description":"Get up to speed on the nuances of NoSQL databases and what they mean for your organization This easy to read guide to NoSQL databases provides the type of no-nonsense overview and analysis that you need to learn, including what NoSQL is and which database is right for you. Featuring specific evaluation criteria for NoSQL databases, along with a look into the pros and cons of the most popular options, NoSQL For Dummies provides the fastest and easiest way to dive into the details of this incredible technology. You'll gain an understanding of how to use NoSQL databases for mission-critical enterprise architectures and projects, and real-world examples reinforce the primary points to create an action-oriented resource for IT pros. If you're planning a big data project or platform, you probably already know you need to select a NoSQL database to complete your architecture. But with options flooding the market and updates and add-ons coming at a rapid pace, determining what you require now, and in the future, can be a tall task. This is where NoSQL For Dummies comes in! Learn the basic tenets of NoSQL databases and why they have come to the forefront as data has outpaced the capabilities of relational databases Discover major players among NoSQL databases, including Cassandra, MongoDB, MarkLogic, Neo4J, and others Get an in-depth look at the benefits and disadvantages of the wide variety of NoSQL database options Explore the needs of your organization as they relate to the capabilities of specific NoSQL databases Big data and Hadoop get all the attention, but when it comes down to it, NoSQL databases are the engines that power many big data analytics initiatives. With NoSQL For Dummies, you'll go beyond relational databases to ramp up your enterprise's data architecture in no time.","language":"en","currency":"USD","id":"1118905628","title":"NoSQL For Dummies","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=O_UwBgAAQBAJ&source=gbs_api","authors":["Adam Fowler"]},{"pageCount":140,"thumbnail":"http:\/\/books.google.com\/books\/content?id=EaTPDQAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":16.19,"subtitle":"An SQL Driver for HBase","description":"Leverage Phoenix as an ANSI SQL engine built on top of the highly distributed and scalable NoSQL framework HBase. Learn the basics and best practices that are being adopted in Phoenix to enable a high write and read throughput in a big data space. This book includes real-world cases such as Internet of Things devices that send continuous streams to Phoenix, and the book explains how key features such as joins, indexes, transactions, and functions help you understand the simple, flexible, and powerful API that Phoenix provides. Examples are provided using real-time data and data-driven businesses that show you how to collect, analyze, and act in seconds. Pro Apache Phoenix covers the nuances of setting up a distributed HBase cluster with Phoenix libraries, running performance benchmarks, configuring parameters for production scenarios, and viewing the results. The book also shows how Phoenix plays well with other key frameworks in the Hadoop ecosystem such as Apache Spark, Pig, Flume, and Sqoop. You will learn how to: Handle a petabyte data store by applying familiar SQL techniques Store, analyze, and manipulate data in a NoSQL Hadoop echo system with HBase Apply best practices while working with a scalable data store on Hadoop and HBase Integrate popular frameworks (Apache Spark, Pig, Flume) to simplify big data analysis Demonstrate real-time use cases and big data modeling techniques Who This Book Is For Data engineers, Big Data administrators, and architects.","language":"en","currency":"USD","id":"1484223705","title":"Pro Apache Phoenix","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=EaTPDQAAQBAJ&source=gbs_api","authors":["Shakil Akhtar","Ravi Magham"]},{"pageCount":421,"thumbnail":"http:\/\/books.google.com\/books\/content?id=Hz4sDQAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":31.72,"subtitle":"A Definitive Guide to Hadoop-Related Frameworks and Tools","description":"Learn how to use the Apache Hadoop projects, including MapReduce, HDFS, Apache Hive, Apache HBase, Apache Kafka, Apache Mahout, and Apache Solr. From setting up the environment to running sample applications each chapter in this book is a practical tutorial on using an Apache Hadoop ecosystem project. While several books on Apache Hadoop are available, most are based on the main projects, MapReduce and HDFS, and none discusses the other Apache Hadoop ecosystem projects and how they all work together as a cohesive big data development platform. What You Will Learn: Set up the environment in Linux for Hadoop projects using Cloudera Hadoop Distribution CDH 5 Run a MapReduce job Store data with Apache Hive, and Apache HBase Index data in HDFS with Apache Solr Develop a Kafka messaging system Stream Logs to HDFS with Apache Flume Transfer data from MySQL database to Hive, HDFS, and HBase with Sqoop Create a Hive table over Apache Solr Develop a Mahout User Recommender System Who This Book Is For: Apache Hadoop developers. Pre-requisite knowledge of Linux and some knowledge of Hadoop is required.","language":"en","currency":"USD","id":"1484221990","title":"Practical Hadoop Ecosystem","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=Hz4sDQAAQBAJ&source=gbs_api","authors":["Deepak Vohra"]},{"pageCount":208,"thumbnail":"http:\/\/books.google.com\/books\/content?id=4S7WBgAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":14.59,"subtitle":null,"description":"If you are a data analyst, developer, or simply someone who wants to use Hive to explore and analyze data in Hadoop, this is the book for you. Whether you are new to big data or an expert, with this book, you will be able to master both the basic and the advanced features of Hive. Since Hive is an SQL-like language, some previous experience with the SQL language and databases is useful to have a better understanding of this book.","language":"en","currency":"USD","id":"1782175059","title":"Apache Hive Essentials","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=4S7WBgAAQBAJ&source=gbs_api","authors":["Dayong Du"]},{"pageCount":238,"thumbnail":"http:\/\/books.google.com\/books\/content?id=tbOKBAAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":18.35,"subtitle":"Flexible, Scalable, and Reliable Data Streaming","description":"How can you get your data from frontend servers to Hadoop in near real time? With this complete reference guide, you\u2019ll learn Flume\u2019s rich set of features for collecting, aggregating, and writing large amounts of streaming data to the Hadoop Distributed File System (HDFS), Apache HBase, SolrCloud, Elastic Search, and other systems. Using Flume shows operations engineers how to configure, deploy, and monitor a Flume cluster, and teaches developers how to write Flume plugins and custom components for their specific use-cases. You\u2019ll learn about Flume\u2019s design and implementation, as well as various features that make it highly scalable, flexible, and reliable. Code examples and exercises are available on GitHub. Learn how Flume provides a steady rate of flow by acting as a buffer between data producers and consumers Dive into key Flume components, including sources that accept data and sinks that write and deliver it Write custom plugins to customize the way Flume receives, modifies, formats, and writes data Explore APIs for sending data to Flume agents from your own applications Plan and deploy Flume in a scalable and flexible way\u2014and monitor your cluster once it\u2019s running","language":"en","currency":"USD","id":"1491905336","title":"Using Flume","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=tbOKBAAAQBAJ&source=gbs_api","authors":["Hari Shreedharan"]},{"pageCount":168,"thumbnail":"http:\/\/books.google.com\/books\/content?id=Ym9uBgAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":10.69,"subtitle":null,"description":"Whether you are a novice to ZooKeeper or already have some experience, you will be able to master the concepts of ZooKeeper and its usage with ease. This book assumes you to have some prior knowledge of distributed systems and high-level programming knowledge of C, Java, or Python, but no experience with Apache ZooKeeper is required.","language":"en","currency":"USD","id":"1784398322","title":"Apache ZooKeeper Essentials","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=Ym9uBgAAQBAJ&source=gbs_api","authors":["Saurav Haloi"]},{"pageCount":416,"thumbnail":"http:\/\/books.google.com\/books\/content?id=wJApAgAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":18,"subtitle":null,"description":"Let Hadoop For Dummies help harness the power of yourdata and rein in the information overload Big data has become big business, and companies and organizationsof all sizes are struggling to find ways to retrieve valuableinformation from their massive data sets with becoming overwhelmed.Enter Hadoop and this easy-to-understand For Dummiesguide. Hadoop For Dummies helps readers understand thevalue of big data, make a business case for using Hadoop, navigatethe Hadoop ecosystem, and build and manage Hadoop applications andclusters. Explains the origins of Hadoop, its economic benefits, and itsfunctionality and practical applications Helps you find your way around the Hadoop ecosystem, programMapReduce, utilize design patterns, and get your Hadoop cluster upand running quickly and easily Details how to use Hadoop applications for data mining, webanalytics and personalization, large-scale text processing, datascience, and problem-solving Shows you how to improve the value of your Hadoop cluster,maximize your investment in Hadoop, and avoid common pitfalls whenbuilding your Hadoop cluster From programmers challenged with building and maintainingaffordable, scaleable data systems to administrators who must dealwith huge volumes of information effectively and efficiently, thishow-to has something to help you with Hadoop.","language":"en","currency":"USD","id":"1118652207","title":"Hadoop For Dummies","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=wJApAgAAQBAJ&source=gbs_api","authors":["Dirk deRoos"]},{"pageCount":400,"thumbnail":"http:\/\/books.google.com\/books\/content?id=VIkNCgAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":31.81,"subtitle":"Designing Real-World Big Data Applications","description":"Get expert guidance on architecting end-to-end data management solutions with Apache Hadoop. While many sources explain how to use various components in the Hadoop ecosystem, this practical book takes you through architectural considerations necessary to tie those components together into a complete tailored application, based on your particular use case. To reinforce those lessons, the book\u2019s second section provides detailed examples of architectures used in some of the most commonly found Hadoop applications. Whether you\u2019re designing a new Hadoop application, or planning to integrate Hadoop into your existing data infrastructure, Hadoop Application Architectures will skillfully guide you through the process. This book covers: Factors to consider when using Hadoop to store and model data Best practices for moving data in and out of the system Data processing frameworks, including MapReduce, Spark, and Hive Common Hadoop processing patterns, such as removing duplicate records and using windowing analytics Giraph, GraphX, and other tools for large graph processing on Hadoop Using workflow orchestration and scheduling tools such as Apache Oozie Near-real-time stream processing with Apache Storm, Apache Spark Streaming, and Apache Flume Architecture examples for clickstream analysis, fraud detection, and data warehousing","language":"en","currency":"USD","id":"1491900059","title":"Hadoop Application Architectures","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=VIkNCgAAQBAJ&source=gbs_api","authors":["Mark Grover","Ted Malaska","Jonathan Seidman","Gwen Shapira"]},{"pageCount":360,"thumbnail":"http:\/\/books.google.com\/books\/content?id=rC5aDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":40.99,"subtitle":"A Guide to Modern Databases and the NoSQL Movement","description":"Data is getting bigger and more complex by the day, and so are your choices in handling it. Explore some of the most cutting-edge databases available - from a traditional relational database to newer NoSQL approaches - and make informed decisions about challenging data storage problems. This is the only comprehensive guide to the world of NoSQL databases, with in-depth practical and conceptual introductions to seven different technologies: Redis, Neo4J, CouchDB, MongoDB, HBase, Postgres, and DynamoDB. This second edition includes a new chapter on DynamoDB and updated content for each chapter. While relational databases such as MySQL remain as relevant as ever, the alternative, NoSQL paradigm has opened up new horizons in performance and scalability and changed the way we approach data-centric problems. This book presents the essential concepts behind each database alongside hands-on examples that make each technology come alive. With each database, tackle a real-world problem that highlights the concepts and features that make it shine. Along the way, explore five database models - relational, key\/value, columnar, document, and graph - from the perspective of challenges faced by real applications. Learn how MongoDB and CouchDB are strikingly different, make your applications faster with Redis and more connected with Neo4J, build a cluster of HBase servers using cloud services such as Amazon's Elastic MapReduce, and more. This new edition brings a brand new chapter on DynamoDB, updated code samples and exercises, and a more up-to-date account of each database's feature set. Whether you're a programmer building the next big thing, a data scientist seeking solutions to thorny problems, or a technology enthusiast venturing into new territory, you will find something to inspire you in this book. What You Need: You'll need a *nix shell (Mac OS or Linux preferred, Windows users will need Cygwin), Java 6 (or greater), and Ruby 1.8.7 (or greater). Each chapter will list the downloads required for that database.","language":"en","currency":"USD","id":"1680505971","title":"Seven Databases in Seven Weeks","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=rC5aDwAAQBAJ&source=gbs_api","authors":["Luc Perkins","Eric Redmond","Jim Wilson"]},{"pageCount":150,"thumbnail":"http:\/\/books.google.com\/books\/content?id=Ml5uAgAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":12.64,"subtitle":null,"description":"This book is an easy-to-follow, step-by-step tutorial where each chapter takes your knowledge to the next level. The book covers practical knowledge with tips to implement this knowledge in real-world scenarios. A chapter with a real-life example is included to help you understand the concepts in full.Using Cloudera Impala is for those who really want to take advantage of their Hadoop cluster by processing extremely large amounts of raw data in Hadoop at real-time speed. Prior knowledge of Hadoop and some exposure to HIVE and MapReduce is expected.","language":"en","currency":"USD","id":"1783281286","title":"Learning Cloudera Impala","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=Ml5uAgAAQBAJ&source=gbs_api","authors":["Avkash Chauhan"]},{"pageCount":284,"thumbnail":"http:\/\/books.google.com\/books\/content?id=KpZGDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":31.19,"subtitle":null,"description":"Master the intricacies of Apache Storm and develop real-time stream processing applications with ease About This Book Exploit the various real-time processing functionalities offered by Apache Storm such as parallelism, data partitioning, and more Integrate Storm with other Big Data technologies like Hadoop, HBase, and Apache Kafka An easy-to-understand guide to effortlessly create distributed applications with Storm Who This Book Is For If you are a Java developer who wants to enter into the world of real-time stream processing applications using Apache Storm, then this book is for you. No previous experience in Storm is required as this book starts from the basics. After finishing this book, you will be able to develop not-so-complex Storm applications. What You Will Learn Understand the core concepts of Apache Storm and real-time processing Follow the steps to deploy multiple nodes of Storm Cluster Create Trident topologies to support various message-processing semantics Make your cluster sharing effective using Storm scheduling Integrate Apache Storm with other Big Data technologies such as Hadoop, HBase, Kafka, and more Monitor the health of your Storm cluster In Detail Apache Storm is a real-time Big Data processing framework that processes large amounts of data reliably, guaranteeing that every message will be processed. Storm allows you to scale your data as it grows, making it an excellent platform to solve your big data problems. This extensive guide will help you understand right from the basics to the advanced topics of Storm. The book begins with a detailed introduction to real-time processing and where Storm fits in to solve these problems. You'll get an understanding of deploying Storm on clusters by writing a basic Storm Hello World example. Next we'll introduce you to Trident and you'll get a clear understanding of how you can develop and deploy a trident topology. We cover topics such as monitoring, Storm Parallelism, scheduler and log processing, in a very easy to understand manner. You will also learn how to integrate Storm with other well-known Big Data technologies such as HBase, Redis, Kafka, and Hadoop to realize the full potential of Storm. With real-world examples and clear explanations, this book will ensure you will have a thorough mastery of Apache Storm. You will be able to use this knowledge to develop efficient, distributed real-time applications to cater to your business needs. Style and approach This easy-to-follow guide is full of examples and real-world applications to help you get an in-depth understanding of Apache Storm. This book covers the basics thoroughly and also delves into the intermediate and slightly advanced concepts of application development with Apache Storm.","language":"en","currency":"USD","id":"1787120406","title":"Mastering Apache Storm","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=KpZGDwAAQBAJ&source=gbs_api","authors":["Ankit Jain"]},{"pageCount":552,"thumbnail":"http:\/\/books.google.com\/books\/content?id=qRERCgAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":31.81,"subtitle":"Application Development, Table Design, and Best Practices","description":"Get up to speed on Apache Accumulo, the flexible, high-performance key\/value store created by the National Security Agency (NSA) and based on Google\u2019s BigTable data storage system. Written by former NSA team members, this comprehensive tutorial and reference covers Accumulo architecture, application development, table design, and cell-level security. With clear information on system administration, performance tuning, and best practices, this book is ideal for developers seeking to write Accumulo applications, administrators charged with installing and maintaining Accumulo, and other professionals interested in what Accumulo has to offer. You will find everything you need to use this system fully. Get a high-level introduction to Accumulo\u2019s architecture and data model Take a rapid tour through single- and multiple-node installations, data ingest, and query Learn how to write Accumulo applications for several use cases, based on examples Dive into Accumulo internals, including information not available in the documentation Get detailed information for installing, administering, tuning, and measuring performance Learn best practices based on successful implementations in the field Find answers to common questions that every new Accumulo user asks","language":"en","currency":"USD","id":"149194692X","title":"Accumulo","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=qRERCgAAQBAJ&source=gbs_api","authors":["Aaron Cordova","Billie Rinaldi","Michael Wall"]},{"pageCount":83,"thumbnail":"http:\/\/books.google.com\/books\/content?id=BuHEWIjNEysC&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":0,"subtitle":null,"description":"In an age where everything is measurable, understanding big data is an essential. From creating new data-driven products through to increasing operational efficiency, big data has the potential to make your organization both more competitive and more innovative. As this emerging field transitions from the bleeding edge to enterprise infrastructure, it's vital to understand not only the technologies involved, but the organizational and cultural demands of being data-driven. Written by O'Reilly Radar's experts on big data, this anthology describes: The broad industry changes heralded by the big data era What big data is, what it means to your business, and how to start solving data problems The software that makes up the Hadoop big data stack, and the major enterprise vendors' Hadoop solutions The landscape of NoSQL databases and their relative merits How visualization plays an important part in data work","language":"en","currency":"USD","id":"1449329640","title":"Planning for Big Data","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=BuHEWIjNEysC&source=gbs_api","authors":["Edd Wilder-James"]},{"pageCount":176,"thumbnail":"http:\/\/books.google.com\/books\/content?id=DrfNBgAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":10.69,"subtitle":null,"description":"If you have a working knowledge of Hadoop 1.x but want to start afresh with YARN, this book is ideal for you. You will be able to install and administer a YARN cluster and also discover the configuration settings to fine-tune your cluster both in terms of performance and scalability. This book will help you develop, deploy, and run multiple applications\/frameworks on the same shared YARN cluster.","language":"en","currency":"USD","id":"1784397725","title":"YARN Essentials","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=DrfNBgAAQBAJ&source=gbs_api","authors":["Amol Fasale","Nirmal Kumar"]},{"pageCount":398,"thumbnail":"http:\/\/books.google.com\/books\/content?id=88iia_wT_NgC&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":18.49,"subtitle":null,"description":"Data is arriving faster than you can process it and the overall volumes keep growing at a rate that keeps you awake at night. Hadoop can help you tame the data beast. Effective use of Hadoop however requires a mixture of programming, design, and system administration skills. \"Hadoop Beginner's Guide\" removes the mystery from Hadoop, presenting Hadoop and related technologies with a focus on building working systems and getting the job done, using cloud services to do so when it makes sense. From basic concepts and initial setup through developing applications and keeping the system running as the data grows, the book gives the understanding needed to effectively use Hadoop to solve real world problems. Starting with the basics of installing and configuring Hadoop, the book explains how to develop applications, maintain the system, and how to use additional products to integrate with other systems. While learning different ways to develop applications to run on Hadoop the book also covers tools such as Hive, Sqoop, and Flume that show how Hadoop can be integrated with relational databases and log collection. In addition to examples on Hadoop clusters on Ubuntu uses of cloud services such as Amazon, EC2 and Elastic MapReduce are covered.","language":"en","currency":"USD","id":"1849517304","title":"Hadoop Beginner's Guide","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=88iia_wT_NgC&source=gbs_api","authors":["Garry Turkington"]},{"pageCount":207,"thumbnail":"http:\/\/books.google.com\/books\/content?id=8tslDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":31.72,"subtitle":"Building Real-World Big Data Systems on Azure HDInsight Using the Hadoop Ecosystem","description":"Get a jump start on using Azure HDInsight and Hadoop Ecosystem components. As most Hadoop and Big Data projects are written in either Java, Scala, or Python, this book minimizes the effort to learn another language and is written from the perspective of a .NET developer. Hadoop components are covered, including Hive, Pig, HBase, Storm, and Spark on Azure HDInsight, and code samples are written in .NET only. Processing Big Data with Azure HDInsight covers the fundamentals of big data, how businesses are using it to their advantage, and how Azure HDInsight fits into the big data world. This book introduces Hadoop and big data concepts and then dives into creating different solutions with HDInsight and the Hadoop Ecosystem. It covers concepts with real-world scenarios and code examples, making sure you get hands-on experience. The best way to utilize this book is to practice while reading. After reading this book you will be familiar with Azure HDInsight and how it can be utilized to build big data solutions, including batch processing, stream analytics, interactive processing, and storing and retrieving data in an efficient manner. What You'll Learn Understand the fundamentals of HDInsight and Hadoop Work with HDInsight cluster Query with Apache Hive and Apache Pig Store and retrieve data with Apache HBase Stream data processing using Apache Storm Work with Apache Spark Who This Book Is For Software developers, technical architects, data scientists\/analyts, and Hadoop administrators who want to develop on Microsoft\u2019s managed Hadoop offering, HDInsight","language":"en","currency":"USD","id":"1484228693","title":"Processing Big Data with Azure HDInsight","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=8tslDwAAQBAJ&source=gbs_api","authors":["Vinit Yadav"]},{"pageCount":156,"thumbnail":"http:\/\/books.google.com\/books\/content?id=P21jDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":31.81,"subtitle":"Perform Fast Analytics on Fast Data","description":"Fast data ingestion, serving, and analytics in the Hadoop ecosystem have forced developers and architects to choose solutions using the least common denominator\u2014either fast analytics at the cost of slow data ingestion or fast data ingestion at the cost of slow analytics. There is an answer to this problem. With the Apache Kudu column-oriented data store, you can easily perform fast analytics on fast data. This practical guide shows you how. Begun as an internal project at Cloudera, Kudu is an open source solution compatible with many data processing frameworks in the Hadoop environment. In this book, current and former solutions professionals from Cloudera provide use cases, examples, best practices, and sample code to help you get up to speed with Kudu. Explore Kudu\u2019s high-level design, including how it spreads data across servers Fully administer a Kudu cluster, enable security, and add or remove nodes Learn Kudu\u2019s client-side APIs, including how to integrate Apache Impala, Spark, and other frameworks for data manipulation Examine Kudu\u2019s schema design, including basic concepts and primitives necessary to make your project successful Explore case studies for using Kudu for real-time IoT analytics, predictive modeling, and in combination with another storage engine","language":"en","currency":"USD","id":"1491980206","title":"Getting Started with Kudu","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=P21jDwAAQBAJ&source=gbs_api","authors":["Jean-Marc Spaggiari","Mladen Kovacevic","Brock Noland","Ryan Bosshart"]},{"pageCount":306,"thumbnail":"http:\/\/books.google.com\/books\/content?id=sku-BAAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":103.2,"subtitle":"Research Trends and Applications","description":"As an area, Technology Enhanced Learning (TEL) aims to design, develop and test socio-technical innovations that will support and enhance learning practices of individuals and organizations. Information retrieval is a pivotal activity in TEL and the deployment of recommender systems has attracted increased interest during the past years. Recommendation methods, techniques and systems open an interesting new approach to facilitate and support learning and teaching. The goal is to develop, deploy and evaluate systems that provide learners and teachers with meaningful guidance in order to help identify suitable learning resources from a potentially overwhelming variety of choices. Contributions address the following topics: i) user and item data that can be used to support learning recommendation systems and scenarios, ii) innovative methods and techniques for recommendation purposes in educational settings and iii) examples of educational platforms and tools where recommendations are incorporated.","language":"en","currency":"USD","id":"1493905309","title":"Recommender Systems for Technology Enhanced Learning","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=sku-BAAAQBAJ&source=gbs_api","authors":["Nikos Manouselis","Hendrik Drachsler","Katrien Verbert","Olga C. Santos"]},{"pageCount":452,"thumbnail":"http:\/\/books.google.com\/books\/content?id=8JlGDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":31.72,"subtitle":null,"description":"Design, implement, and deliver successful streaming applications, machine learning pipelines and graph applications using Spark SQL API About This Book Learn about the design and implementation of streaming applications, machine learning pipelines, deep learning, and large-scale graph processing applications using Spark SQL APIs and Scala. Learn data exploration, data munging, and how to process structured and semi-structured data using real-world datasets and gain hands-on exposure to the issues and challenges of working with noisy and \"dirty\" real-world data. Understand design considerations for scalability and performance in web-scale Spark application architectures. Who This Book Is For If you are a developer, engineer, or an architect and want to learn how to use Apache Spark in a web-scale project, then this is the book for you. It is assumed that you have prior knowledge of SQL querying. A basic programming knowledge with Scala, Java, R, or Python is all you need to get started with this book. What You Will Learn Familiarize yourself with Spark SQL programming, including working with DataFrame\/Dataset API and SQL Perform a series of hands-on exercises with different types of data sources, including CSV, JSON, Avro, MySQL, and MongoDB Perform data quality checks, data visualization, and basic statistical analysis tasks Perform data munging tasks on publically available datasets Learn how to use Spark SQL and Apache Kafka to build streaming applications Learn key performance-tuning tips and tricks in Spark SQL applications Learn key architectural components and patterns in large-scale Spark SQL applications In Detail In the past year, Apache Spark has been increasingly adopted for the development of distributed applications. Spark SQL APIs provide an optimized interface that helps developers build such applications quickly and easily. However, designing web-scale production applications using Spark SQL APIs can be a complex task. Hence, understanding the design and implementation best practices before you start your project will help you avoid these problems. This book gives an insight into the engineering practices used to design and build real-world, Spark-based applications. The book's hands-on examples will give you the required confidence to work on any future projects you encounter in Spark SQL. It starts by familiarizing you with data exploration and data munging tasks using Spark SQL and Scala. Extensive code examples will help you understand the methods used to implement typical use-cases for various types of applications. You will get a walkthrough of the key concepts and terms that are common to streaming, machine learning, and graph applications. You will also learn key performance-tuning details including Cost Based Optimization (Spark 2.2) in Spark SQL applications. Finally, you will move on to learning how such systems are architected and deployed for a successful delivery of your project. Style and approach This book is a hands-on guide to designing, building, and deploying Spark SQL-centric production applications at scale.","language":"en","currency":"USD","id":"1785887351","title":"Learning Spark SQL","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=8JlGDwAAQBAJ&source=gbs_api","authors":["Aurobindo Sarkar"]},{"pageCount":452,"thumbnail":"http:\/\/books.google.com\/books\/content?id=8JlGDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":31.72,"subtitle":null,"description":"Design, implement, and deliver successful streaming applications, machine learning pipelines and graph applications using Spark SQL API About This Book Learn about the design and implementation of streaming applications, machine learning pipelines, deep learning, and large-scale graph processing applications using Spark SQL APIs and Scala. Learn data exploration, data munging, and how to process structured and semi-structured data using real-world datasets and gain hands-on exposure to the issues and challenges of working with noisy and \"dirty\" real-world data. Understand design considerations for scalability and performance in web-scale Spark application architectures. Who This Book Is For If you are a developer, engineer, or an architect and want to learn how to use Apache Spark in a web-scale project, then this is the book for you. It is assumed that you have prior knowledge of SQL querying. A basic programming knowledge with Scala, Java, R, or Python is all you need to get started with this book. What You Will Learn Familiarize yourself with Spark SQL programming, including working with DataFrame\/Dataset API and SQL Perform a series of hands-on exercises with different types of data sources, including CSV, JSON, Avro, MySQL, and MongoDB Perform data quality checks, data visualization, and basic statistical analysis tasks Perform data munging tasks on publically available datasets Learn how to use Spark SQL and Apache Kafka to build streaming applications Learn key performance-tuning tips and tricks in Spark SQL applications Learn key architectural components and patterns in large-scale Spark SQL applications In Detail In the past year, Apache Spark has been increasingly adopted for the development of distributed applications. Spark SQL APIs provide an optimized interface that helps developers build such applications quickly and easily. However, designing web-scale production applications using Spark SQL APIs can be a complex task. Hence, understanding the design and implementation best practices before you start your project will help you avoid these problems. This book gives an insight into the engineering practices used to design and build real-world, Spark-based applications. The book's hands-on examples will give you the required confidence to work on any future projects you encounter in Spark SQL. It starts by familiarizing you with data exploration and data munging tasks using Spark SQL and Scala. Extensive code examples will help you understand the methods used to implement typical use-cases for various types of applications. You will get a walkthrough of the key concepts and terms that are common to streaming, machine learning, and graph applications. You will also learn key performance-tuning details including Cost Based Optimization (Spark 2.2) in Spark SQL applications. Finally, you will move on to learning how such systems are architected and deployed for a successful delivery of your project. Style and approach This book is a hands-on guide to designing, building, and deploying Spark SQL-centric production applications at scale.","language":"en","currency":"USD","id":"1785887351","title":"Learning Spark SQL","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=8JlGDwAAQBAJ&source=gbs_api","authors":["Aurobindo Sarkar"]},{"pageCount":256,"thumbnail":"http:\/\/books.google.com\/books\/content?id=S69PCwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":31.72,"subtitle":null,"description":"In this fast-paced book on the Docker open standards platform for developing, packaging and running portable distributed applications, Deepak Vorhadiscusses how to build, ship and run applications on any platform such as a PC, the cloud, data center or a virtual machine. He describes how to install and create Docker images. and the advantages off Docker containers.The remainder of the book is devoted to discussing using Docker with important software solutions. He begins by discussing using Docker with a traditional RDBMS using Oracle and MySQL. Next he moves on to NoSQL with chapter on MongoDB Cassandra, and Couchbase. Then he addresses the use of Docker in the Hadoop ecosystem with complete chapters on utilizing not only Hadoop, but Hive, HBase, Sqoop, Kafka, Solr and Spark. What You Will Learn How to install a Docker image How to create a Docker container How to run an Application in a Docker Container Use Docker with Apache Hadoop Ecosystem Use Docker with NoSQL Databases Use Docker with RDBMS Who This Book Is ForApache Hadoop Developers. Database developers. NoSQL Developers.","language":"en","currency":"USD","id":"1484218302","title":"Pro Docker","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=S69PCwAAQBAJ&source=gbs_api","authors":["Deepak Vohra"]},{"pageCount":382,"thumbnail":"http:\/\/books.google.com\/books\/content?id=axOxBgAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":18.49,"subtitle":null,"description":"If you are a system or application developer interested in learning how to solve practical problems using the Hadoop framework, then this book is ideal for you. You are expected to be familiar with the Unix\/Linux command-line interface and have some experience with the Java programming language. Familiarity with Hadoop would be a plus.","language":"en","currency":"USD","id":"1783285524","title":"Learning Hadoop 2","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=axOxBgAAQBAJ&source=gbs_api","authors":["Garry Turkington","Gabriele Modena"]},{"pageCount":94,"thumbnail":"http:\/\/books.google.com\/books\/content?id=bxBnjitgIAYC&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":9.99,"subtitle":"Unlocking Hadoop for Your Relational Database","description":"Integrating data from multiple sources is essential in the age of big data, but it can be a challenging and time-consuming task. This handy cookbook provides dozens of ready-to-use recipes for using Apache Sqoop, the command-line interface application that optimizes data transfers between relational databases and Hadoop. Sqoop is both powerful and bewildering, but with this cookbook\u2019s problem-solution-discussion format, you\u2019ll quickly learn how to deploy and then apply Sqoop in your environment. The authors provide MySQL, Oracle, and PostgreSQL database examples on GitHub that you can easily adapt for SQL Server, Netezza, Teradata, or other relational systems. Transfer data from a single database table into your Hadoop ecosystem Keep table data and Hadoop in sync by importing data incrementally Import data from more than one database table Customize transferred data by calling various database functions Export generated, processed, or backed-up data from Hadoop to your database Run Sqoop within Oozie, Hadoop\u2019s specialized workflow scheduler Load data into Hadoop\u2019s data warehouse (Hive) or database (HBase) Handle installation, connection, and syntax issues common to specific database vendors","language":"en","currency":"USD","id":"1449364586","title":"Apache Sqoop Cookbook","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=bxBnjitgIAYC&source=gbs_api","authors":["Kathleen Ting","Jarek Jarcec Cecho"]},{"pageCount":398,"thumbnail":"http:\/\/books.google.com\/books\/content?id=CCW7BQAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":63.99,"subtitle":"19th International Conference, TAAI 2014, Taipei, Taiwan, November 21-23, 2014, Proceedings","description":"This book constitutes the refereed proceedings of the 19th International Conference on Technologies and Applications of Artificial Intelligence, held in Taipei, Taiwan, in November 2014. The 23 revised full papers, 3 short papers, and 8 workshop papers presented at the international track of the conference were carefully reviewed and selected from overall 93 submissions to the international track, domestic track, and international workshops for inclusion in this volume. The papers feature original research results and practical development experiences among researchers and application developers from the many AI related areas including machine learning, data mining, statistics, computer vision, web intelligence, information retrieval, and computer games.","language":"en","currency":"USD","id":"3319139878","title":"Technologies and Applications of Artificial Intelligence","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=CCW7BQAAQBAJ&source=gbs_api","authors":["Shin-Ming Cheng","Min-Yuh Day"]},{"pageCount":912,"thumbnail":"http:\/\/books.google.com\/books\/content?id=U1RwBQAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":31.72,"subtitle":"Covering 14.10 and 15.04","description":"Ubuntu Unleashed 2015 Edition is filled with unique and advanced information for everyone who wants to make the most of the Linux-based Ubuntu operating system. This new edition has been thoroughly revised and updated by a long-time Ubuntu community leader to reflect the exciting new Ubuntu 14.10 while including tons of information that will continue to apply to future editions. Former Ubuntu Forum administrator Matthew Helmke covers all you need to know about Ubuntu 14.10 installation, configuration, productivity, multimedia, development, system administration, server operations, networking, virtualization, security, DevOps, and more\u2013including intermediate-to-advanced techniques you won\u2019t find in any other book. Helmke presents up-to-the-minute introductions to Ubuntu\u2019s key productivity and Web development tools, programming languages, hardware support, and more. You\u2019ll find new or improved coverage of Ubuntu\u2019s Unity interface, various types of servers, software repositories, database options, virtualization and cloud services, development tools, monitoring, troubleshooting, Ubuntu\u2019s push into mobile and other touch screen devices, and much more. Detailed information on how to\u2026 Configure and customize the Unity desktop Get started with multimedia and productivity applications, including LibreOffice Manage Linux services, users, and software packages Administer and run Ubuntu from the command line Automate tasks and use shell scripting Provide secure remote access and configure a secure VPN Manage kernels and modules Administer file, print, email, proxy, LDAP, DNS, and HTTP servers (Apache, Nginx, or alternatives) Learn about new options for managing large numbers of servers Work with databases (both SQL and the newest NoSQL alternatives) Get started with virtualization Build a private cloud with Juju and Charms Learn the basics about popular programming languages including Python, PHP, Perl, and new alternatives such as Go and Rust Learn about Ubuntu\u2019s work toward usability on touch-screen and phone devices Ubuntu 14.10 on DVD DVD includes the full Ubuntu 14.10 distribution for 64 bit computers (most desktop and notebooks systems today) as well as the complete LibreOffice office suite and hundreds of additional programs and utilities. Free Kick Start Chapter! Purchase this book and receive a free Ubuntu 15.04 Kick Start chapter after Ubuntu 15.04 is released. See inside back cover for details","language":"en","currency":"USD","id":"0133794067","title":"Ubuntu Unleashed 2015 Edition","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=U1RwBQAAQBAJ&source=gbs_api","authors":["Matthew Helmke"]},{"pageCount":812,"thumbnail":"http:\/\/books.google.com\/books\/content?id=RZC7BQAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":87.2,"subtitle":"14th International Conference, WAIM 2013, Beidaihe, China, June 14-16, 2013. Proceedings","description":"This book constitutes the refereed proceedings of the 14th International Conference on Web-Age Information Management, WAIM 2013, held in Beidaihe, China, in June 2013. The 47 revised full papers presented together with 29 short papers and 5 keynotes were carefully reviewed and selected from a total of 248 submissions. The papers are organized in topical sections on data mining; information integration and heterogeneous systems; big data; spatial and temporal databases; information extraction; new hardware and miscellaneous; query processing and optimization; social network and graphs; information retrieval; workflow systems and service computing; recommender systems; security, privacy, and trust; semantic Web and ontology.","language":"en","currency":"USD","id":"3642385621","title":"Web-Age Information Management","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=RZC7BQAAQBAJ&source=gbs_api","authors":["Jianyong Wang","Hui Xiong","Yoshiharu Ishikawa","Jianliang Xu","Junfeng Zhou"]},{"pageCount":58,"thumbnail":"http:\/\/books.google.com\/books\/content?id=qHdFQsFnc0YC&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":11.99,"subtitle":null,"description":"Filled with practical, step-by-step instructions and clear explanations for the most important and useful tasks. Instant Apache Sqoop is full of step-by-step instructions and practical examples along with challenges to test and improve your knowledge.This book is great for developers who are looking to get a good grounding in how to effectively and efficiently move data between RDBMS and the Hadoop ecosystem. It's assumed that you will have some experience in Hadoop already as well as some familiarity with HBase and Hive.","language":"en","currency":"USD","id":"1782165770","title":"Instant Apache Sqoop","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=qHdFQsFnc0YC&source=gbs_api","authors":["Ankit Jain"]},{"pageCount":104,"thumbnail":"http:\/\/books.google.com\/books\/content?id=DRqkBwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":12.75,"subtitle":null,"description":"If you\u2019re a business team leader, CIO, business analyst, or developer interested in how Apache Hadoop and Apache HBase-related technologies can address problems involving large-scale data in cost-effective ways, this book is for you. Using real-world stories and situations, authors Ted Dunning and Ellen Friedman show Hadoop newcomers and seasoned users alike how NoSQL databases and Hadoop can solve a variety of business and research issues. You\u2019ll learn about early decisions and pre-planning that can make the process easier and more productive. If you\u2019re already using these technologies, you\u2019ll discover ways to gain the full range of benefits possible with Hadoop. While you don\u2019t need a deep technical background to get started, this book does provide expert guidance to help managers, architects, and practitioners succeed with their Hadoop projects. Examine a day in the life of big data: India\u2019s ambitious Aadhaar project Review tools in the Hadoop ecosystem such as Apache\u2019s Spark, Storm, and Drill to learn how they can help you Pick up a collection of technical and strategic tips that have helped others succeed with Hadoop Learn from several prototypical Hadoop use cases, based on how organizations have actually applied the technology Explore real-world stories that reveal how MapR customers combine use cases when putting Hadoop and NoSQL to work, including in production","language":"en","currency":"USD","id":"1491928913","title":"Real-World Hadoop","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=DRqkBwAAQBAJ&source=gbs_api","authors":["Ted Dunning","Ellen Friedman"]},{"pageCount":120,"thumbnail":"http:\/\/books.google.com\/books\/content?id=PdqcAQAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":13.94,"subtitle":null,"description":"This book will be a basic, step-by-step tutorial, which will help readers take advantage of all that Spark has to offer.Fastdata Processing with Spark is for software developers who want to learn how to write distributed programs with Spark. It will help developers who have had problems that were too much to be dealt with on a single computer. No previous experience with distributed programming is necessary. This book assumes knowledge of either Java, Scala, or Python.","language":"en","currency":"USD","id":"1782167072","title":"Fast Data Processing With Spark","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=PdqcAQAAQBAJ&source=gbs_api","authors":["Holden Karau"]},{"pageCount":336,"thumbnail":"http:\/\/books.google.com\/books\/content?id=XPkAEFXo7VgC&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":18,"subtitle":null,"description":"Find the right big data solution for your business ororganization Big data management is one of the major challenges facingbusiness, industry, and not-for-profit organizations. Data setssuch as customer transactions for a mega-retailer, weather patternsmonitored by meteorologists, or social network activity can quicklyoutpace the capacity of traditional data management tools. If youneed to develop or manage big data solutions, you'll appreciate howthese four experts define, explain, and guide you through this newand often confusing concept. You'll learn what it is, why itmatters, and how to choose and implement solutions that work. Effectively managing big data is an issue of growing importanceto businesses, not-for-profit organizations, government, and ITprofessionals Authors are experts in information management, big data, and avariety of solutions Explains big data in detail and discusses how to select andimplement a solution, security concerns to consider, data storageand presentation issues, analytics, and much more Provides essential information in a no-nonsense,easy-to-understand style that is empowering Big Data For Dummies cuts through the confusion and helpsyou take charge of big data solutions for your organization.","language":"en","currency":"USD","id":"1118644174","title":"Big Data For Dummies","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=XPkAEFXo7VgC&source=gbs_api","authors":["Judith S. Hurwitz","Alan Nugent","Fern Halper","Marcia Kaufman"]},{"pageCount":288,"thumbnail":"http:\/\/books.google.com\/books\/content?id=CO1FDAAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":16.19,"subtitle":"An Introduction for Data Scientists","description":"Ready to use statistical and machine-learning techniques across large data sets? This practical guide shows you why the Hadoop ecosystem is perfect for the job. Instead of deployment, operations, or software development usually associated with distributed computing, you\u2019ll focus on particular analyses you can build, the data warehousing techniques that Hadoop provides, and higher order data workflows this framework can produce. Data scientists and analysts will learn how to perform a wide range of techniques, from writing MapReduce and Spark applications with Python to using advanced modeling and data management with Spark MLlib, Hive, and HBase. You\u2019ll also learn about the analytical processes and data systems available to build and empower data products that can handle\u2014and actually require\u2014huge amounts of data. Understand core concepts behind Hadoop and cluster computing Use design patterns and parallel analytical algorithms to create distributed data analysis jobs Learn about data management, mining, and warehousing in a distributed context using Apache Hive and HBase Use Sqoop and Apache Flume to ingest data from relational databases Program complex Hadoop and Spark applications with Apache Pig and Spark DataFrames Perform machine learning techniques such as classification, clustering, and collaborative filtering with Spark\u2019s MLlib","language":"en","currency":"USD","id":"1491913754","title":"Data Analytics with Hadoop","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=CO1FDAAAQBAJ&source=gbs_api","authors":["Benjamin Bengfort","Jenny Kim"]},{"pageCount":333,"thumbnail":"http:\/\/books.google.com\/books\/content?id=EY1jDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":9.95,"subtitle":null,"description":"The book contains the latest trend in IT industry 'BigData and Hadoop'. It explains how big is 'Big Data' and why everybody is trying to implement this into their IT project.It includes research work on various topics, theoretical and practical approach, each component of the architecture is described along with current industry trends.Big Data and Hadoop have taken together are a new skill as per the industry standards. Readers will get a compact book along with the industry experience and would be a reference to help readers.KEY FEATURES Overview Of Big Data, Basics of Hadoop, Hadoop Distributed File System, HBase, MapReduce, HIVE: The Dataware House Of Hadoop, PIG: The Higher Level Programming Environment, SQOOP: Importing Data From Heterogeneous Sources, Flume, Ozzie, Zookeeper & Big Data Stream Mining, Chapter-wise Questions & Previous Years Questions","language":"en","currency":"USD","id":"9387284832","title":"BIG DATA AND HADOOP","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=EY1jDwAAQBAJ&source=gbs_api","authors":["Mayank Bhusan"]},{"pageCount":624,"thumbnail":"http:\/\/books.google.com\/books\/content?id=-II73rBDXCYC&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":51.19,"subtitle":null,"description":"The award-winning and highly influential Software Architecture in Practice, Third Edition, has been substantially revised to reflect the latest developments in the field. In a real-world setting, the book once again introduces the concepts and best practices of software architecture\u2014how a software system is structured and how that system\u2019s elements are meant to interact. Distinct from the details of implementation, algorithm, and data representation, an architecture holds the key to achieving system quality, is a reusable asset that can be applied to subsequent systems, and is crucial to a software organization\u2019s business strategy. The authors have structured this edition around the concept of architecture influence cycles. Each cycle shows how architecture influences, and is influenced by, a particular context in which architecture plays a critical role. Contexts include technical environment, the life cycle of a project, an organization\u2019s business profile, and the architect\u2019s professional practices. The authors also have greatly expanded their treatment of quality attributes, which remain central to their architecture philosophy\u2014with an entire chapter devoted to each attribute\u2014and broadened their treatment of architectural patterns. If you design, develop, or manage large software systems (or plan to do so), you will find this book to be a valuable resource for getting up to speed on the state of the art. Totally new material covers Contexts of software architecture: technical, project, business, and professional Architecture competence: what this means both for individuals and organizations The origins of business goals and how this affects architecture Architecturally significant requirements, and how to determine them Architecture in the life cycle, including generate-and-test as a design philosophy; architecture conformance during implementation; architecture and testing; and architecture and agile development Architecture and current technologies, such as the cloud, social networks, and end-user devices","language":"en","currency":"USD","id":"013294278X","title":"Software Architecture in Practice","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=-II73rBDXCYC&source=gbs_api","authors":["Len Bass","Paul Clements","Rick Kazman"]},{"pageCount":144,"thumbnail":"http:\/\/books.google.com\/books\/content?id=BnbJAgAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":0,"subtitle":null,"description":"This IBM® Redbooks® publication describes the integration of IBM Platform Symphony® with IBM BigInsightsTM. It includes IBM Platform LSF® implementation scenarios that use IBM System x® technologies. This IBM Redbooks publication is written for consultants, technical support staff, IT architects, and IT specialists who are responsible for providing solutions and support for IBM Platform Computing solutions. This book explains how the IBM Platform Computing solutions and the IBM System x platform can help to solve customer challenges and to maximize systems throughput, capacity, and management. It examines the tools, utilities, documentation, and other resources that are available to help technical teams provide solutions and support for IBM Platform Computing solutions in a System x environment. In addition, this book includes a well-defined and documented deployment model within a System x environment. It provides a planned foundation for provisioning and building large scale parallel high-performance computing (HPC) applications, cluster management, analytics workloads, and grid applications.","language":"en","currency":"USD","id":"0738437883","title":"IBM Platform Computing Integration Solutions","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=BnbJAgAAQBAJ&source=gbs_api","authors":["Dino Quintero","Ricardo Dobelin Barros","Ashraf Gomaa","José Higino","Archana Kumar","Majid Ouassir","Adam Parker","Joanna Wong","IBM Redbooks"]},{"pageCount":34,"thumbnail":"http:\/\/books.google.com\/books\/content?id=Y4WMBAAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":0,"subtitle":null,"description":"Learn about Cloudera Impala--an open source project that's opening up the Apache Hadoop software stack to a wide audience of database analysts, users, and developers. The Impala massively parallel processing (MPP) engine makes SQL queries of Hadoop data simple enough to be accessible to analysts familiar with SQL and to users of business intelligence tools--and it\u2019s fast enough to be used for interactive exploration and experimentation.","language":"en","currency":"USD","id":"149194949X","title":"Cloudera Impala","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=Y4WMBAAAQBAJ&source=gbs_api","authors":["John Russell"]},{"pageCount":238,"thumbnail":"http:\/\/books.google.com\/books\/content?id=tbOKBAAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":18.35,"subtitle":"Flexible, Scalable, and Reliable Data Streaming","description":"How can you get your data from frontend servers to Hadoop in near real time? With this complete reference guide, you\u2019ll learn Flume\u2019s rich set of features for collecting, aggregating, and writing large amounts of streaming data to the Hadoop Distributed File System (HDFS), Apache HBase, SolrCloud, Elastic Search, and other systems. Using Flume shows operations engineers how to configure, deploy, and monitor a Flume cluster, and teaches developers how to write Flume plugins and custom components for their specific use-cases. You\u2019ll learn about Flume\u2019s design and implementation, as well as various features that make it highly scalable, flexible, and reliable. Code examples and exercises are available on GitHub. Learn how Flume provides a steady rate of flow by acting as a buffer between data producers and consumers Dive into key Flume components, including sources that accept data and sinks that write and deliver it Write custom plugins to customize the way Flume receives, modifies, formats, and writes data Explore APIs for sending data to Flume agents from your own applications Plan and deploy Flume in a scalable and flexible way\u2014and monitor your cluster once it\u2019s running","language":"en","currency":"USD","id":"1491905336","title":"Using Flume","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=tbOKBAAAQBAJ&source=gbs_api","authors":["Hari Shreedharan"]},{"pageCount":326,"thumbnail":"http:\/\/books.google.com\/books\/content?id=r4ZcDgAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":31.19,"subtitle":null,"description":"A handy reference guide for data analysts and data scientists to help to obtain value from big data analytics using Spark on Hadoop clusters About This Book This book is based on the latest 2.0 version of Apache Spark and 2.7 version of Hadoop integrated with most commonly used tools. Learn all Spark stack components including latest topics such as DataFrames, DataSets, GraphFrames, Structured Streaming, DataFrame based ML Pipelines and SparkR. Integrations with frameworks such as HDFS, YARN and tools such as Jupyter, Zeppelin, NiFi, Mahout, HBase Spark Connector, GraphFrames, H2O and Hivemall. Who This Book Is For Though this book is primarily aimed at data analysts and data scientists, it will also help architects, programmers, and practitioners. Knowledge of either Spark or Hadoop would be beneficial. It is assumed that you have basic programming background in Scala, Python, SQL, or R programming with basic Linux experience. Working experience within big data environments is not mandatory. What You Will Learn Find out and implement the tools and techniques of big data analytics using Spark on Hadoop clusters with wide variety of tools used with Spark and Hadoop Understand all the Hadoop and Spark ecosystem components Get to know all the Spark components: Spark Core, Spark SQL, DataFrames, DataSets, Conventional and Structured Streaming, MLLib, ML Pipelines and Graphx See batch and real-time data analytics using Spark Core, Spark SQL, and Conventional and Structured Streaming Get to grips with data science and machine learning using MLLib, ML Pipelines, H2O, Hivemall, Graphx, SparkR and Hivemall. In Detail Big Data Analytics book aims at providing the fundamentals of Apache Spark and Hadoop. All Spark components \u2013 Spark Core, Spark SQL, DataFrames, Data sets, Conventional Streaming, Structured Streaming, MLlib, Graphx and Hadoop core components \u2013 HDFS, MapReduce and Yarn are explored in greater depth with implementation examples on Spark + Hadoop clusters. It is moving away from MapReduce to Spark. So, advantages of Spark over MapReduce are explained at great depth to reap benefits of in-memory speeds. DataFrames API, Data Sources API and new Data set API are explained for building Big Data analytical applications. Real-time data analytics using Spark Streaming with Apache Kafka and HBase is covered to help building streaming applications. New Structured streaming concept is explained with an IOT (Internet of Things) use case. Machine learning techniques are covered using MLLib, ML Pipelines and SparkR and Graph Analytics are covered with GraphX and GraphFrames components of Spark. Readers will also get an opportunity to get started with web based notebooks such as Jupyter, Apache Zeppelin and data flow tool Apache NiFi to analyze and visualize data. Style and approach This step-by-step pragmatic guide will make life easy no matter what your level of experience. You will deep dive into Apache Spark on Hadoop clusters through ample exciting real-life examples. Practical tutorial explains data science in simple terms to help programmers and data analysts get started with Data Science","language":"en","currency":"USD","id":"1785889702","title":"Big Data Analytics","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=r4ZcDgAAQBAJ&source=gbs_api","authors":["Venkat Ankam"]},{"pageCount":332,"thumbnail":"http:\/\/books.google.com\/books\/content?id=-zp7DwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":40.79,"subtitle":"Query and Analyze Distributed Data Sources with SQL","description":"Get up to speed with Apache Drill, an extensible distributed SQL query engine that reads massive datasets in many popular file formats such as Parquet, JSON, and CSV. Drill reads data in HDFS or in cloud-native storage such as S3 and works with Hive metastores along with distributed databases such as HBase, MongoDB, and relational databases. Drill works everywhere: on your laptop or in your largest cluster. In this practical book, Drill committers Charles Givre and Paul Rogers show analysts and data scientists how to query and analyze raw data using this powerful tool. Data scientists today spend about 80% of their time just gathering and cleaning data. With this book, you\u2019ll learn how Drill helps you analyze data more effectively to drive down time to insight. Use Drill to clean, prepare, and summarize delimited data for further analysis Query file types including logfiles, Parquet, JSON, and other complex formats Query Hadoop, relational databases, MongoDB, and Kafka with standard SQL Connect to Drill programmatically using a variety of languages Use Drill even with challenging or ambiguous file formats Perform sophisticated analysis by extending Drill\u2019s functionality with user-defined functions Facilitate data analysis for network security, image metadata, and machine learning","language":"en","currency":"USD","id":"1492032751","title":"Learning Apache Drill","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=-zp7DwAAQBAJ&source=gbs_api","authors":["Charles Givre","Paul Rogers"]},{"pageCount":247,"thumbnail":"http:\/\/books.google.com\/books\/content?id=pTfpDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":67.99,"subtitle":"9th International Conference, CLOSER 2019, Heraklion, Crete, Greece, May 2\u20134, 2019, Revised Selected Papers","description":"This book constitutes extended, revised and selected papers from the 9th International Conference on Cloud Computing and Services Science, CLOSER 2019, held in Heraklion, Greece, in May 2019.The 11 papers presented in this volume were carefully reviewed and selected from a total of 102 submissions. CLOSER 2019 focuses on the emerging area of Cloud Computing, inspired by some latest advances that concern the infrastructure, operations, and available servicesthrough the global network.","language":"en","currency":"USD","id":"3030494322","title":"Cloud Computing and Services Science","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=pTfpDwAAQBAJ&source=gbs_api","authors":["Donald Ferguson","Víctor Méndez Muñoz","Claus Pahl","Markus Helfert"]},{"pageCount":316,"thumbnail":"http:\/\/books.google.com\/books\/content?id=DeTO4xbC-eoC&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":18.35,"subtitle":"Modern Data Access for Enterprise Java","description":"You can choose several data access frameworks when building Java enterprise applications that work with relational databases. But what about big data? This hands-on introduction shows you how Spring Data makes it relatively easy to build applications across a wide range of new data access technologies such as NoSQL and Hadoop. Through several sample projects, you\u2019ll learn how Spring Data provides a consistent programming model that retains NoSQL-specific features and capabilities, and helps you develop Hadoop applications across a wide range of use-cases such as data analysis, event stream processing, and workflow. You\u2019ll also discover the features Spring Data adds to Spring\u2019s existing JPA and JDBC support for writing RDBMS-based data access layers. Learn about Spring\u2019s template helper classes to simplify the use ofdatabase-specific functionality Explore Spring Data\u2019s repository abstraction and advanced query functionality Use Spring Data with Redis (key\/value store), HBase(column-family), MongoDB (document database), and Neo4j (graph database) Discover the GemFire distributed data grid solution Export Spring Data JPA-managed entities to the Web as RESTful web services Simplify the development of HBase applications, using a lightweight object-mapping framework Build example big-data pipelines with Spring Batch and Spring Integration","language":"en","currency":"USD","id":"1449331882","title":"Spring Data","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=DeTO4xbC-eoC&source=gbs_api","authors":["Mark Pollack","Oliver Gierke","Thomas Risberg","Jon Brisbin","Michael Hunger"]},{"pageCount":308,"thumbnail":"http:\/\/books.google.com\/books\/content?id=irZTDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":17.19,"subtitle":"Get up and running with the fundamentals and functionalities of seven of the most popular NoSQL databases","description":"A beginner's guide to get you up and running with Cassandra, DynamoDB, HBase, InfluxDB, MongoDB, Neo4j, and Redis Key Features Covers the basics of 7 NoSQL databases and how they are used in the enterprises Quick introduction to MongoDB, DynamoDB, Redis, Cassandra, Neo4j, InfluxDB, and HBase Includes effective techniques for database querying and management Book Description This is the golden age of open source NoSQL databases. With enterprises having to work with large amounts of unstructured data and moving away from expensive monolithic architecture, the adoption of NoSQL databases is rapidly increasing. Being familiar with the popular NoSQL databases and knowing how to use them is a must for budding DBAs and developers. This book introduces you to the different types of NoSQL databases and gets you started with seven of the most popular NoSQL databases used by enterprises today. We start off with a brief overview of what NoSQL databases are, followed by an explanation of why and when to use them. The book then covers the seven most popular databases in each of these categories: MongoDB, Amazon DynamoDB, Redis, HBase, Cassandra, InfluxDB, and Neo4j. The book doesn't go into too much detail about each database but teaches you enough to get started with them. By the end of this book, you will have a thorough understanding of the different NoSQL databases and their functionalities, empowering you to select and use the right database according to your needs. What you will learn Understand how MongoDB provides high-performance, high-availability, and automatic scaling Interact with your Neo4j instances via database queries, Python scripts, and Java application code Get familiar with common querying and programming methods to interact with Redis Study the different types of problems Cassandra can solve Work with HBase components to support common operations such as creating tables and reading\/writing data Discover data models and work with CRUD operations using DynamoDB Discover what makes InfluxDB a great choice for working with time-series data Who this book is for If you are a budding DBA or a developer who wants to get started with the fundamentals of NoSQL databases, this book is for you. Relational DBAs who want to get insights into the various offerings of popular NoSQL databases will also find this book to be very useful.","language":"en","currency":"USD","id":"1787127141","title":"Seven NoSQL Databases in a Week","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=irZTDwAAQBAJ&source=gbs_api","authors":["Xun (Brian) Wu","Sudarshan Kadambi","Devram Kandhare","Aaron Ploetz"]},{"pageCount":108,"thumbnail":"http:\/\/books.google.com\/books\/content?id=tra2TBrEMcgC&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":13.29,"subtitle":"Distributed Log Collection for Hadoop","description":"A starter guide that covers Apache Flume in detail.Apache Flume: Distributed Log Collection for Hadoop is intended for people who are responsible for moving datasets into Hadoop in a timely and reliable manner like software engineers, database administrators, and data warehouse administrators","language":"en","currency":"USD","id":"1782167927","title":"Apache Flume","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=tra2TBrEMcgC&source=gbs_api","authors":["Steve Hoffman"]},{"pageCount":104,"thumbnail":"http:\/\/books.google.com\/books\/content?id=DRqkBwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":12.75,"subtitle":null,"description":"If you\u2019re a business team leader, CIO, business analyst, or developer interested in how Apache Hadoop and Apache HBase-related technologies can address problems involving large-scale data in cost-effective ways, this book is for you. Using real-world stories and situations, authors Ted Dunning and Ellen Friedman show Hadoop newcomers and seasoned users alike how NoSQL databases and Hadoop can solve a variety of business and research issues. You\u2019ll learn about early decisions and pre-planning that can make the process easier and more productive. If you\u2019re already using these technologies, you\u2019ll discover ways to gain the full range of benefits possible with Hadoop. While you don\u2019t need a deep technical background to get started, this book does provide expert guidance to help managers, architects, and practitioners succeed with their Hadoop projects. Examine a day in the life of big data: India\u2019s ambitious Aadhaar project Review tools in the Hadoop ecosystem such as Apache\u2019s Spark, Storm, and Drill to learn how they can help you Pick up a collection of technical and strategic tips that have helped others succeed with Hadoop Learn from several prototypical Hadoop use cases, based on how organizations have actually applied the technology Explore real-world stories that reveal how MapR customers combine use cases when putting Hadoop and NoSQL to work, including in production","language":"en","currency":"USD","id":"1491928913","title":"Real-World Hadoop","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=DRqkBwAAQBAJ&source=gbs_api","authors":["Ted Dunning","Ellen Friedman"]},{"pageCount":96,"thumbnail":"http:\/\/books.google.com\/books\/content?id=SM-Z_Hhn3EkC&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":14.59,"subtitle":null,"description":"This book will be a step-by-step tutorial, which practically teaches working with big data on SQL Server through sample examples in increasing complexity.Microsoft SQL Server 2012 with Hadoop is specifically targeted at readers who want to cross-pollinate their Hadoop skills with SQL Server 2012 business intelligence and data analytics. A basic understanding of traditional RDBMS technologies and query processing techniques is essential.","language":"en","currency":"USD","id":"178217799X","title":"Microsoft SQL Server 2012 with Hadoop","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=SM-Z_Hhn3EkC&source=gbs_api","authors":["Debarchan Sarkar"]},{"pageCount":66,"thumbnail":"http:\/\/books.google.com\/books\/content?id=fDerAgAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":0,"subtitle":null,"description":"Organizations are looking for ways to get more out of their already strained IT infrastructure as they face new technological and economic pressures. They are also trying to satisfy a broad set of users (internal and external to the enterprise) who demand improvements in their quality of service (QoS), regardless of increases in the number of users and applications. Cloud computing offers attractive opportunities to reduce costs, accelerate development, and increase the flexibility of the IT infrastructure, applications, and services. Infrastructure as a service (IaaS) is the typical starting point for most organizations when moving to a cloud-computing environment. IaaS can be used for the delivery of resources such as compute, storage, and network services through a self-service portal. With IaaS, IT services are delivered as a subscription service, eliminating up-front costs and driving down ongoing support costs. Businesses can improve their competitive position by moving to these cloud-based technologies. This IBM® RedpaperTM discusses IBM solutions for managed service providers (MSPs). This paper is for IT professionals who are involved in managed and cloud services solution planning.","language":"en","currency":"USD","id":"0738450987","title":"IBM PureFlex System Solutions for Managed Service Providers","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=fDerAgAAQBAJ&source=gbs_api","authors":["Ilya Krutov","IBM Redbooks"]},{"pageCount":272,"thumbnail":"http:\/\/books.google.com\/books\/content?id=VjDcBAAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":15.39,"subtitle":"Using Social MDM to Drive Deep Customer Insight","description":"Drive Powerful Business Value by Extending MDM to Social, Mobile, Local, and Transactional Data Enterprises have long relied on Master Data Management (MDM) to improve customer-related processes. But MDM was designed primarily for structured data. Today, crucial information is increasingly captured in unstructured, transactional, and social formats: from tweets and Facebook posts to call center transcripts. Even with tools like Hadoop, extracting usable insight is difficult\u2014often, because it\u2019s so difficult to integrate new and legacy data sources. In Beyond Big Data, five of IBM\u2019s leading data management experts introduce powerful new ways to integrate social, mobile, location, and traditional data. Drawing on pioneering experience with IBM\u2019s enterprise customers, they show how Social MDM can help you deepen relationships, improve prospect targeting, and fully engage customers through mobile channels. Business leaders and practitioners will discover powerful new ways to combine social and master data to improve performance and uncover new opportunities. Architects and other technical leaders will find a complete reference architecture, in-depth coverage of relevant technologies and use cases, and domain-specific best practices for their own projects. Coverage Includes How Social MDM extends fundamental MDM concepts and techniques Architecting Social MDM: components, functions, layers, and interactions Identifying high value relationships: person to product and person to organization Mapping Social MDM architecture to specific products and technologies Using Social MDM to create more compelling customer experiences Accelerating your transition to highly-targeted, contextual marketing Incorporating mobile data to improve employee productivity Avoiding privacy and ethical pitfalls throughout your ecosystem Previewing Semantic MDM and other emerging trends","language":"en","currency":"USD","id":"0133509818","title":"Beyond Big Data","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=VjDcBAAAQBAJ&source=gbs_api","authors":["Martin Oberhofer","Eberhard Hechler","Ivan Milman","Scott Schumacher","Dan Wolfson"]},{"pageCount":636,"thumbnail":"http:\/\/books.google.com\/books\/content?id=1qd9DwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":61.59,"subtitle":"A Guide to Enterprise Hadoop at Scale","description":"There\u2019s a lot of information about big data technologies, but splicing these technologies into an end-to-end enterprise data platform is a daunting task not widely covered. With this practical book, you\u2019ll learn how to build big data infrastructure both on-premises and in the cloud and successfully architect a modern data platform. Ideal for enterprise architects, IT managers, application architects, and data engineers, this book shows you how to overcome the many challenges that emerge during Hadoop projects. You\u2019ll explore the vast landscape of tools available in the Hadoop and big data realm in a thorough technical primer before diving into: Infrastructure: Look at all component layers in a modern data platform, from the server to the data center, to establish a solid foundation for data in your enterprise Platform: Understand aspects of deployment, operation, security, high availability, and disaster recovery, along with everything you need to know to integrate your platform with the rest of your enterprise IT Taking Hadoop to the cloud: Learn the important architectural aspects of running a big data platform in the cloud while maintaining enterprise security and high availability","language":"en","currency":"USD","id":"1491969229","title":"Architecting Modern Data Platforms","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=1qd9DwAAQBAJ&source=gbs_api","authors":["Jan Kunigk","Ian Buss","Paul Wilkinson","Lars George"]},{"pageCount":350,"thumbnail":"http:\/\/books.google.com\/books\/content?id=n8FffirFaQIC&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":18.35,"subtitle":"Data Warehouse and Query Language for Hadoop","description":"Need to move a relational database application to Hadoop? This comprehensive guide introduces you to Apache Hive, Hadoop\u2019s data warehouse infrastructure. You\u2019ll quickly learn how to use Hive\u2019s SQL dialect\u2014HiveQL\u2014to summarize, query, and analyze large datasets stored in Hadoop\u2019s distributed filesystem. This example-driven guide shows you how to set up and configure Hive in your environment, provides a detailed overview of Hadoop and MapReduce, and demonstrates how Hive works within the Hadoop ecosystem. You\u2019ll also find real-world case studies that describe how companies have used Hive to solve unique problems involving petabytes of data. Use Hive to create, alter, and drop databases, tables, views, functions, and indexes Customize data formats and storage options, from files to external databases Load and extract data from tables\u2014and use queries, grouping, filtering, joining, and other conventional query methods Gain best practices for creating user defined functions (UDFs) Learn Hive patterns you should use and anti-patterns you should avoid Integrate Hive with other data processing programs Use storage handlers for NoSQL databases and other datastores Learn the pros and cons of running Hive on Amazon\u2019s Elastic MapReduce","language":"en","currency":"USD","id":"1449326978","title":"Programming Hive","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=n8FffirFaQIC&source=gbs_api","authors":["Edward Capriolo","Dean Wampler","Jason Rutherglen"]},{"pageCount":293,"thumbnail":"http:\/\/books.google.com\/books\/content?id=k1NSDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":0,"subtitle":"4th Asian Conference, SCFA 2018, Singapore, March 26-29, 2018, Proceedings","description":"It constitutes the refereed proceedings of the 4th Asian Supercomputing Conference, SCFA 2018, held in Singapore in March 2018. Supercomputing Frontiers will be rebranded as Supercomputing Frontiers Asia (SCFA), which serves as the technical programme for SCA18. The technical programme for SCA18 consists of four tracks: Application, Algorithms & Libraries Programming System Software Architecture, Network\/Communications & Management Data, Storage & Visualisation The 20 papers presented in this volume were carefully reviewed nd selected from 60 submissions.","language":"en","currency":"USD","id":"3319699539","title":"Supercomputing Frontiers","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=k1NSDwAAQBAJ&source=gbs_api","authors":["Rio Yokota","Weigang Wu"]},{"pageCount":448,"thumbnail":"http:\/\/books.google.com\/books\/content?id=5b6zCgAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":48,"subtitle":null,"description":"Deliver continuous access to timely and accurate BI across your enterprise using the detailed information in this Oracle Press guide. Through clear explanations and practical examples, a team of Oracle experts shows how to assimilate data from disparate sources into a single, unified view. Find out how to transform data in real time, handle replication and migration, and deploy Oracle Data Integrator and Oracle GoldenGate. Oracle Data Integration: Tools for Harnessing Data offers complete coverage of the latest \u201Cbig data\u201D hardware and software solutions. · Efficiently move data both inside and outside an Oracle environment · Map sources to database fields using Data Merge and ETL · Export schema through transportable tablespaces and Oracle Data Pump · Capture and apply changes across heterogeneous systems with Oracle GoldenGate · Seamlessly exchange information between databases using Oracle Data Integrator · Correct errors and maximize quality through data cleansing and validation · Plan and execute successful Oracle Database migrations and replications · Handle high-volume transactions with Oracle Big Data Appliance, Oracle NoSQL, and third-party utilities","language":"en","currency":"USD","id":"0071841660","title":"Oracle Data Integration: Tools for Harnessing Data","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=5b6zCgAAQBAJ&source=gbs_api","authors":["Michelle Malcher","Bobby Curtis","Chris Lawless"]},{"pageCount":112,"thumbnail":"http:\/\/books.google.com\/books\/content?id=mi_WBgAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":12.64,"subtitle":null,"description":"This book is for readers who want to know more about Apache Kafka at a hands-on level; the key audience is those with software development experience but no prior exposure to Apache Kafka or similar technologies. It is also useful for enterprise application developers and big data enthusiasts who have worked with other publisher-subscriber-based systems and want to explore Apache Kafka as a futuristic solution.","language":"en","currency":"USD","id":"1784390275","title":"Learning Apache Kafka - Second Edition","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=mi_WBgAAQBAJ&source=gbs_api","authors":["Nishant Garg"]},{"pageCount":104,"thumbnail":"http:\/\/books.google.com\/books\/content?id=FMGEBAAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":32.99,"subtitle":null,"description":"Master's Thesis from the year 2014 in the subject Computer Science - Applied, grade: 82.00, , course: M.Tech CS&E, language: English, abstract: Hadoop and Map reduce today are facing huge amounts of data and are moving towards ubiquitous for big data storage and processing. This has made it an essential feature to evaluate and characterize the Hadoop file system and its deployment through extensive benchmarking. We have other benchmarking tools widely available with us today that are capable of analyzing the performance of the Hadoop system but they are made to either run in a single node system or are created for assessing the storage device that is attached and its basic characteristics as top speed and other hardware related details or manufacturer\u2019s details. For this, the tool used is HiBench that is an essential part of Hadoop and is comprehensive benchmark suit that consist of a complete deposit of Hadoop applications having micro bench marks & real time applications for the purpose of benchmarking the performance of Hadoop on the available type of storage device (i.e. HDD and SSD) and machine configuration. This is helpful to optimize the performance and improve the support towards the limitations of Hadoop system. In this research work we will analyze and characterize the performance of external sorting algorithm in Hadoop (MapReduce) with SSD and HDD that are connected with various Interconnect technologies like 10GigE, IPoIB and RDBAIB. In addition, we will also demonstrate that the traditional servers and old Cloud systems can be upgraded by software and hardware up gradations to perform at par with the modern technologies to handle these loads, without spending ruthlessly on up gradations or complete changes in the system with the use of Modern storage devices and interconnect networking systems. This in turn reduces the power consumption drastically and allows smoother running of large scale servers with low latency and high throughput allowing use of the utmost power of the processors for the big data flowing in the network.","language":"en","currency":"USD","id":"3656721610","title":"High-Performance Persistent Storage System for BigData Analysis","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=FMGEBAAAQBAJ&source=gbs_api","authors":["Piyush Saxena"]},{"pageCount":352,"thumbnail":"http:\/\/books.google.com\/books\/content?id=TAxlDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":31.81,"subtitle":"The What, Where, When, and How of Large-Scale Data Processing","description":"Streaming data is a big deal in big data these days. As more and more businesses seek to tame the massive unbounded data sets that pervade our world, streaming systems have finally reached a level of maturity sufficient for mainstream adoption. With this practical guide, data engineers, data scientists, and developers will learn how to work with streaming data in a conceptual and platform-agnostic way. Expanded from Tyler Akidau\u2019s popular blog posts \"Streaming 101\" and \"Streaming 102\", this book takes you from an introductory level to a nuanced understanding of the what, where, when, and how of processing real-time data streams. You\u2019ll also dive deep into watermarks and exactly-once processing with co-authors Slava Chernyak and Reuven Lax. You\u2019ll explore: How streaming and batch data processing patterns compare The core principles and concepts behind robust out-of-order data processing How watermarks track progress and completeness in infinite datasets How exactly-once data processing techniques ensure correctness How the concepts of streams and tables form the foundations of both batch and streaming data processing The practical motivations behind a powerful persistent state mechanism, driven by a real-world example How time-varying relations provide a link between stream processing and the world of SQL and relational algebra","language":"en","currency":"USD","id":"1491983825","title":"Streaming Systems","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=TAxlDwAAQBAJ&source=gbs_api","authors":["Tyler Akidau","Slava Chernyak","Reuven Lax"]},{"pageCount":206,"thumbnail":"http:\/\/books.google.com\/books\/content?id=_GlGCgAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":14.59,"subtitle":null,"description":"Hadoop offers distributed processing of large datasets across clusters and is designed to scale up from a single server to thousands of machines, with a very high degree of fault tolerance. It enables computing solutions that are scalable, cost-effective, flexible, and fault tolerant to back up very large data sets from hardware failures. Starting off with the basics of Hadoop administration, this book becomes increasingly exciting with the best strategies of backing up distributed storage databases. You will gradually learn about the backup and recovery principles, discover the common failure points in Hadoop, and facts about backing up Hive metadata. A deep dive into the interesting world of Apache HBase will show you different ways of backing up data and will compare them. Going forward, you'll learn the methods of defining recovery strategies for various causes of failures, failover recoveries, corruption, working drives, and metadata. Also covered are the concepts of Hadoop matrix and MapReduce. Finally, you'll explore troubleshooting strategies and techniques to resolve failures.","language":"en","currency":"USD","id":"1783289058","title":"Hadoop Backup and Recovery Solutions","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=_GlGCgAAQBAJ&source=gbs_api","authors":["Gaurav Barot","Chintan Mehta","Amij Patel"]},{"pageCount":66,"thumbnail":"http:\/\/books.google.com\/books\/content?id=LRZIBAAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":9.99,"subtitle":null,"description":"Finding Data Anomalies You Didn't Know to Look For Anomaly detection is the detective work of machine learning: finding the unusual, catching the fraud, discovering strange activity in large and complex datasets. But, unlike Sherlock Holmes, you may not know what the puzzle is, much less what \u201Csuspects\u201D you\u2019re looking for. This O\u2019Reilly report uses practical examples to explain how the underlying concepts of anomaly detection work. From banking security to natural sciences, medicine, and marketing, anomaly detection has many useful applications in this age of big data. And the search for anomalies will intensify once the Internet of Things spawns even more new types of data. The concepts described in this report will help you tackle anomaly detection in your own project. Use probabilistic models to predict what\u2019s normal and contrast that to what you observe Set an adaptive threshold to determine which data falls outside of the normal range, using the t-digest algorithm Establish normal fluctuations in complex systems and signals (such as an EKG) with a more adaptive probablistic model Use historical data to discover anomalies in sporadic event streams, such as web traffic Learn how to use deviations in expected behavior to trigger fraud alerts","language":"en","currency":"USD","id":"1491914173","title":"Practical Machine Learning: A New Look at Anomaly Detection","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=LRZIBAAAQBAJ&source=gbs_api","authors":["Ted Dunning","Ellen Friedman"]},{"pageCount":206,"thumbnail":"http:\/\/books.google.com\/books\/content?id=EfqoCwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":22.39,"subtitle":null,"description":"Build mesmerizing visualizations, analytics, and logs from your data using Elasticsearch, Logstash, and Kibana About This Book Solve all your data analytics problems with the ELK stack Explore the power of Kibana4 search and visualizations built over Elasticsearch queries and learn about the features and plugins of Logstash Develop a complete data pipeline using the ELK stack Who This Book Is For If you are a developer or DevOps engineer interested in building a system that provides amazing insights and business metrics out of data sources, of various formats and types, using the open source technology stack that ELK provides, then this book is for you. Basic knowledge of Unix or any programming language will be helpful to make the most out of this book. What You Will Learn Install, configure, and run Elasticsearch, Logstash, and Kibana Understand the need for log analytics and the current challenges in log analysis Build your own data pipeline using the ELK stack Familiarize yourself with the key features of Logstash and the variety of input, filter, and output plugins it provides Build your own custom Logstash plugin Create actionable insights using charts, histograms, and quick search features in Kibana4 Understand the role of Elasticsearch in the ELK stack In Detail The ELK stack\u2014Elasticsearch, Logstash, and Kibana, is a powerful combination of open source tools. Elasticsearch is for deep search and data analytics. Logstash is for centralized logging, log enrichment, and parsing. Kibana is for powerful and beautiful data visualizations. In short, the Elasticsearch ELK stack makes searching and analyzing data easier than ever before. This book will introduce you to the ELK (Elasticsearch, Logstash, and Kibana) stack, starting by showing you how to set up the stack by installing the tools, and basic configuration. You'll move on to building a basic data pipeline using the ELK stack. Next, you'll explore the key features of Logstash and its role in the ELK stack, including creating Logstash plugins, which will enable you to use your own customized plugins. The importance of Elasticsearch and Kibana in the ELK stack is also covered, along with various types of advanced data analysis, and a variety of charts, tables ,and maps. Finally, by the end of the book you will be able to develop full-fledged data pipeline using the ELK stack and have a solid understanding of the role of each of the components. Style and approach This book is a step-by-step guide, complete with various examples to solve your data analytics problems by using the ELK stack to explore and visualize data.","language":"en","currency":"USD","id":"1785886703","title":"Learning ELK Stack","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=EfqoCwAAQBAJ&source=gbs_api","authors":["Saurabh Chhajed"]},{"pageCount":106,"thumbnail":"http:\/\/books.google.com\/books\/content?id=6AkPqcRZ328C&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":9.99,"subtitle":"Continuous Streaming Computation with Twitter's Cluster Technology","description":"Even as big data is turning the world upside down, the next phase of the revolution is already taking shape: real-time data analysis. This hands-on guide introduces you to Storm, a distributed, JVM-based system for processing streaming data. Through simple tutorials, sample Java code, and a complete real-world scenario, you\u2019ll learn how to build fast, fault-tolerant solutions that process results as soon as the data arrives. Discover how easy it is to set up Storm clusters for solving various problems, including continuous data computation, distributed remote procedure calls, and data stream processing. Learn how to program Storm components: spouts for data input and bolts for data transformation Discover how data is exchanged between spouts and bolts in a Storm topology Make spouts fault-tolerant with several commonly used design strategies Explore bolts\u2014their life cycle, strategies for design, and ways to implement them Scale your solution by defining each component\u2019s level of parallelism Study a real-time web analytics system built with Node.js, a Redis server, and a Storm topology Write spouts and bolts with non-JVM languages such as Python, Ruby, and Javascript","language":"en","currency":"USD","id":"1449324045","title":"Getting Started with Storm","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=6AkPqcRZ328C&source=gbs_api","authors":["Jonathan Leibiusky","Gabriel Eisbruch","Dario Simonassi"]},{"pageCount":440,"thumbnail":"http:\/\/books.google.com\/books\/content?id=x99mnGARqlYC&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":31.19,"subtitle":null,"description":"You've heard the hype about Hadoop: it runs petabyte\u2013scale data mining tasks insanely fast, it runs gigantic tasks on clouds for absurdly cheap, it's been heavily committed to by tech giants like IBM, Yahoo!, and the Apache Project, and it's completely open-source (thus free). But what exactly is it, and more importantly, how do you even get a Hadoop cluster up and running? From Apress, the name you've come to trust for hands\u2013on technical knowledge, Pro Hadoop brings you up to speed on Hadoop. You learn the ins and outs of MapReduce; how to structure a cluster, design, and implement the Hadoop file system; and how to build your first cloud\u2013computing tasks using Hadoop. Learn how to let Hadoop take care of distributing and parallelizing your software\u2014you just focus on the code, Hadoop takes care of the rest. Best of all, you'll learn from a tech professional who's been in the Hadoop scene since day one. Written from the perspective of a principal engineer with down\u2013in\u2013the\u2013trenches knowledge of what to do wrong with Hadoop, you learn how to avoid the common, expensive first errors that everyone makes with creating their own Hadoop system or inheriting someone else's. Skip the novice stage and the expensive, hard\u2013to\u2013fix mistakes...go straight to seasoned pro on the hottest cloud\u2013computing framework with Pro Hadoop. Your productivity will blow your managers away.","language":"en","currency":"USD","id":"1430219432","title":"Pro Hadoop","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=x99mnGARqlYC&source=gbs_api","authors":["Jason Venner"]},{"pageCount":250,"thumbnail":"http:\/\/books.google.com\/books\/content?id=io44nAL61JYC&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":31.19,"subtitle":"Building Effective Algorithms and Analytics for Hadoop and Other Systems","description":"Until now, design patterns for the MapReduce framework have been scattered among various research papers, blogs, and books. This handy guide brings together a unique collection of valuable MapReduce patterns that will save you time and effort regardless of the domain, language, or development framework you\u2019re using. Each pattern is explained in context, with pitfalls and caveats clearly identified to help you avoid common design mistakes when modeling your big data architecture. This book also provides a complete overview of MapReduce that explains its origins and implementations, and why design patterns are so important. All code examples are written for Hadoop. Summarization patterns: get a top-level view by summarizing and grouping data Filtering patterns: view data subsets such as records generated from one user Data organization patterns: reorganize data to work with other systems, or to make MapReduce analysis easier Join patterns: analyze different datasets together to discover interesting relationships Metapatterns: piece together several patterns to solve multi-stage problems, or to perform several analytics in the same job Input and output patterns: customize the way you use Hadoop to load or store data \"A clear exposition of MapReduce programs for common data processing patterns\u2014this book is indespensible for anyone using Hadoop.\" --Tom White, author of Hadoop: The Definitive Guide","language":"en","currency":"USD","id":"1449341985","title":"MapReduce Design Patterns","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=io44nAL61JYC&source=gbs_api","authors":["Donald Miner","Adam Shook"]},{"pageCount":254,"thumbnail":"http:\/\/books.google.com\/books\/content?id=_yuqyIZl33EC&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":18.49,"subtitle":null,"description":"A Cookbook with plenty of practical recipes for different uses of Storm.If you are a Java developer with basic knowledge of real-time processing and would like to learn Storm to process unbounded streams of data in real time, then this book is for you.","language":"en","currency":"USD","id":"178216443X","title":"Storm Real-Time Processing Cookbook","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=_yuqyIZl33EC&source=gbs_api","authors":["Quinton Anderson"]},{"pageCount":322,"thumbnail":"http:\/\/books.google.com\/books\/content?id=dXwzDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":37.12,"subtitle":"Real-Time Data and Stream Processing at Scale","description":"Every enterprise application creates data, whether it\u2019s log messages, metrics, user activity, outgoing messages, or something else. And how to move all of this data becomes nearly as important as the data itself. If you\u2019re an application architect, developer, or production engineer new to Apache Kafka, this practical guide shows you how to use this open source streaming platform to handle real-time data feeds. Engineers from Confluent and LinkedIn who are responsible for developing Kafka explain how to deploy production Kafka clusters, write reliable event-driven microservices, and build scalable stream-processing applications with this platform. Through detailed examples, you\u2019ll learn Kafka\u2019s design principles, reliability guarantees, key APIs, and architecture details, including the replication protocol, the controller, and the storage layer. Understand publish-subscribe messaging and how it fits in the big data ecosystem. Explore Kafka producers and consumers for writing and reading messages Understand Kafka patterns and use-case requirements to ensure reliable data delivery Get best practices for building data pipelines and applications with Kafka Manage Kafka in production, and learn to perform monitoring, tuning, and maintenance tasks Learn the most critical metrics among Kafka\u2019s operational measurements Explore how Kafka\u2019s stream delivery capabilities make it a perfect source for stream processing systems","language":"en","currency":"USD","id":"1491936118","title":"Kafka: The Definitive Guide","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=dXwzDwAAQBAJ&source=gbs_api","authors":["Neha Narkhede","Gwen Shapira","Todd Palino"]},{"pageCount":416,"thumbnail":"http:\/\/books.google.com\/books\/content?id=wJApAgAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":18,"subtitle":null,"description":"Let Hadoop For Dummies help harness the power of yourdata and rein in the information overload Big data has become big business, and companies and organizationsof all sizes are struggling to find ways to retrieve valuableinformation from their massive data sets with becoming overwhelmed.Enter Hadoop and this easy-to-understand For Dummiesguide. Hadoop For Dummies helps readers understand thevalue of big data, make a business case for using Hadoop, navigatethe Hadoop ecosystem, and build and manage Hadoop applications andclusters. Explains the origins of Hadoop, its economic benefits, and itsfunctionality and practical applications Helps you find your way around the Hadoop ecosystem, programMapReduce, utilize design patterns, and get your Hadoop cluster upand running quickly and easily Details how to use Hadoop applications for data mining, webanalytics and personalization, large-scale text processing, datascience, and problem-solving Shows you how to improve the value of your Hadoop cluster,maximize your investment in Hadoop, and avoid common pitfalls whenbuilding your Hadoop cluster From programmers challenged with building and maintainingaffordable, scaleable data systems to administrators who must dealwith huge volumes of information effectively and efficiently, thishow-to has something to help you with Hadoop.","language":"en","currency":"USD","id":"1118652207","title":"Hadoop For Dummies","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=wJApAgAAQBAJ&source=gbs_api","authors":["Dirk deRoos"]},{"pageCount":564,"thumbnail":"http:\/\/books.google.com\/books\/content?id=8QG6BQAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":127.2,"subtitle":"7th IFIP WG 5.14 International Conference, CCTA 2013, Beijing, China, September 18-20, 2013, Revised Selected Papers","description":"The two-volume set IFIP AICT 419 and 420 constitutes the refereed post-conference proceedings of the 7th IFIP TC 5, WG 5.14 International Conference on Computer and Computing Technologies in Agriculture, CCTA 2013, held in Beijing, China, in September 2013. The 115 revised papers presented were carefully selected from numerous submissions. They cover a wide range of interesting theories and applications of information technology in agriculture, including Internet of things and cloud computing; simulation models and decision-support systems for agricultural production; smart sensor, monitoring, and control technology; traceability and e-commerce technology; computer vision, computer graphics, and virtual reality; the application of information and communication technology in agriculture; and universal information service technology and service systems development in rural areas.","language":"en","currency":"USD","id":"3642543413","title":"Computer and Computing Technologies in Agriculture VII","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=8QG6BQAAQBAJ&source=gbs_api","authors":["Daoliang Li","Yingyi Chen"]},{"pageCount":176,"thumbnail":"http:\/\/books.google.com\/books\/content?id=l-BxBgAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":10.69,"subtitle":null,"description":"This book is for programmers and developers who want to improve the performance of their R programs by making them run faster with large data sets or who are trying to solve a pesky performance problem.","language":"en","currency":"USD","id":"1783989270","title":"R High Performance Programming","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=l-BxBgAAQBAJ&source=gbs_api","authors":["Aloysius Lim","William Tjhi"]},{"pageCount":112,"thumbnail":"http:\/\/books.google.com\/books\/content?id=mi_WBgAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":12.64,"subtitle":null,"description":"This book is for readers who want to know more about Apache Kafka at a hands-on level; the key audience is those with software development experience but no prior exposure to Apache Kafka or similar technologies. It is also useful for enterprise application developers and big data enthusiasts who have worked with other publisher-subscriber-based systems and want to explore Apache Kafka as a futuristic solution.","language":"en","currency":"USD","id":"1784390275","title":"Learning Apache Kafka - Second Edition","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=mi_WBgAAQBAJ&source=gbs_api","authors":["Nishant Garg"]},{"pageCount":111,"thumbnail":"http:\/\/books.google.com\/books\/content?id=mCS7BQAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":151.2,"subtitle":null,"description":"Big data is an essential key to build a smart world as a meaning of the streaming, continuous integration of large volume and high velocity data covering from all sources to final destinations. The big data range from data mining, data analysis and decision making, by drawing statistical rules and mathematical patterns through systematical or automatically reasoning. The big data helps serve our life better, clarify our future and deliver greater value. We can discover how to capture and analyze data. Readers will be guided to processing system integrity and implementing intelligent systems. With intelligent systems, we deal with the fundamental data management and visualization challenges in effective management of dynamic and large-scale data, and efficient processing of real-time and spatio-temporal data. Advanced intelligent systems have led to managing the data monitoring, data processing and decision-making in realistic and effective way. Considering a big size of data, variety of data and frequent changes of data, the intelligent systems basically challenge new data management tasks for integration, visualization, querying and analysis. Connected with powerful data analysis, the intelligent systems will provide a paradigm shift from conventional store and process systems. This book focuses on taking a full advantage of big data and intelligent systems processing. It consists of 11 contributions that feature extraction of minority opinion, method for reusing an application, assessment of scientific and innovative projects, multi-voxel pattern analysis, exploiting No-SQL DB, materialized view, TF-IDF criterion, latent Dirichlet allocation, technology forecasting, small world network, and classification & regression tree structure. This edition is published in original, peer reviewed contributions covering from initial design to final prototypes and authorization.","language":"en","currency":"USD","id":"3319055275","title":"Soft Computing in Big Data Processing","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=mCS7BQAAQBAJ&source=gbs_api","authors":["Keon Myung Lee","Seung-Jong Park","Jee-Hyong Lee"]},{"pageCount":58,"thumbnail":"http:\/\/books.google.com\/books\/content?id=qHdFQsFnc0YC&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":11.99,"subtitle":null,"description":"Filled with practical, step-by-step instructions and clear explanations for the most important and useful tasks. Instant Apache Sqoop is full of step-by-step instructions and practical examples along with challenges to test and improve your knowledge.This book is great for developers who are looking to get a good grounding in how to effectively and efficiently move data between RDBMS and the Hadoop ecosystem. It's assumed that you will have some experience in Hadoop already as well as some familiarity with HBase and Hive.","language":"en","currency":"USD","id":"1782165770","title":"Instant Apache Sqoop","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=qHdFQsFnc0YC&source=gbs_api","authors":["Ankit Jain"]},{"pageCount":192,"thumbnail":"http:\/\/books.google.com\/books\/content?id=o6jtBgAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":14.59,"subtitle":null,"description":"If you are a professional or enthusiast who has a basic understanding of graphs or has basic knowledge of Neo4j operations, this is the book for you. Although it is targeted at an advanced user base, this book can be used by beginners as it touches upon the basics. So, if you are passionate about taming complex data with the help of graphs and building high performance applications, you will be able to get valuable insights from this book.","language":"en","currency":"USD","id":"1783555165","title":"Neo4j High Performance","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=o6jtBgAAQBAJ&source=gbs_api","authors":["Sonal Raj"]},{"pageCount":300,"thumbnail":"http:\/\/books.google.com\/books\/content?id=knUDHEa-dP8C&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":18.49,"subtitle":null,"description":"Individual self-contained code recipes. Solve specific problems using individual recipes, or work through the book to develop your capabilities. If you are a big data enthusiast and striving to use Hadoop to solve your problems, this book is for you. Aimed at Java programmers with some knowledge of Hadoop MapReduce, this is also a comprehensive reference for developers and system admins who want to get up to speed using Hadoop.","language":"en","currency":"USD","id":"1849517290","title":"Hadoop MapReduce Cookbook","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=knUDHEa-dP8C&source=gbs_api","authors":["Srinath Perera"]},{"pageCount":483,"thumbnail":"http:\/\/books.google.com\/books\/content?id=6xpRBAAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":70.19,"subtitle":"25th International Conference, DEXA 2014, Munich, Germany, September 1-4, 2014. Proceedings","description":"This two volume set LNCS 8644 and LNCS 8645 constitutes the refereed proceedings of the 25th International Conference on Database and Expert Systems Applications, DEXA 2014, held in Munich, Germany, September 1-4, 2014. The 37 revised full papers presented together with 46 short papers, and 2 keynote talks, were carefully reviewed and selected from 159 submissions. The papers discuss a range of topics including: data quality; social web; XML keyword search; skyline queries; graph algorithms; information retrieval; XML; security; semantic web; classification and clustering; queries; social computing; similarity search; ranking; data mining; big data; approximations; privacy; data exchange; data integration; web semantics; repositories; partitioning; and business applications.","language":"en","currency":"USD","id":"3319100858","title":"Database and Expert Systems Applications","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=6xpRBAAAQBAJ&source=gbs_api","authors":["Hendrik Decker","Lenka Lhotská","Sebastian Link","Marcus Spies","Roland R. Wagner"]},{"pageCount":104,"thumbnail":"http:\/\/books.google.com\/books\/content?id=xRAQAgAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":42.74,"subtitle":null,"description":"Die escape GmbH betreibt ein MySQL basiertes Dataware-House in das Daten aus verschiedenen Webpräsenzen fließen, um dort ausgewertet zu werden. Nach Jahren des erfolgreichen Betriebs nimmt mit der ständig steigenden Menge an gespeicherten Daten die Leistung des Systems allerdings ab. Die Laufzeiten für Auswertungen steigen und die Agilität sinkt. Kleine Optimierungen und Veränderungen des Systems können das Unbrauchbarwerden hinauszögern, als aber aus Gründen der Leistung auf einen Teil der Abfragen verzichtet werden muss, wird schließlich klar, dass nur eine grundlegende Veränderung des Systems den langfristigen Betrieb sicherstellen kann. Aus diesem Grund wurde nach Technologien gesucht, deren Fähigkeiten die Leistung des bestehenden Dataware-Houses verbessern können. Dies führte zu Hadoop.","language":"de","currency":"USD","id":"384288740X","title":"Big Data mit Hadoop und Hive: Untersuchung der Migration einer MySQL-basierten Monitoring & Data Warehouse Lösung nach Hadoop","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=xRAQAgAAQBAJ&source=gbs_api","authors":["Jonas Kress"]},{"pageCount":400,"thumbnail":"http:\/\/books.google.com\/books\/content?id=heoXAwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":17.27,"subtitle":"Moving beyond MapReduce and Batch Processing with Apache Hadoop 2","description":"\u201CThis book is a critically needed resource for the newly released Apache Hadoop 2.0, highlighting YARN as the significant breakthrough that broadens Hadoop beyond the MapReduce paradigm.\u201D \u2014From the Foreword by Raymie Stata, CEO of Altiscale The Insider\u2019s Guide to Building Distributed, Big Data Applications with Apache Hadoop™ YARN Apache Hadoop is helping drive the Big Data revolution. Now, its data processing has been completely overhauled: Apache Hadoop YARN provides resource management at data center scale and easier ways to create distributed applications that process petabytes of data. And now in Apache Hadoop™ YARN, two Hadoop technical leaders show you how to develop new applications and adapt existing code to fully leverage these revolutionary advances. YARN project founder Arun Murthy and project lead Vinod Kumar Vavilapalli demonstrate how YARN increases scalability and cluster utilization, enables new programming models and services, and opens new options beyond Java and batch processing. They walk you through the entire YARN project lifecycle, from installation through deployment. You\u2019ll find many examples drawn from the authors\u2019 cutting-edge experience\u2014first as Hadoop\u2019s earliest developers and implementers at Yahoo! and now as Hortonworks developers moving the platform forward and helping customers succeed with it. Coverage includes YARN\u2019s goals, design, architecture, and components\u2014how it expands the Apache Hadoop ecosystem Exploring YARN on a single node Administering YARN clusters and Capacity Scheduler Running existing MapReduce applications Developing a large-scale clustered YARN application Discovering new open source frameworks that run under YARN","language":"en","currency":"USD","id":"0133441911","title":"Apache Hadoop YARN","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=heoXAwAAQBAJ&source=gbs_api","authors":["Arun Murthy","Vinod Vavilapalli","Douglas Eadline","Joseph Niemiec","Jeff Markham"]},{"pageCount":256,"thumbnail":"http:\/\/books.google.com\/books\/content?id=ekfkEfjS_vcC&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":14.75,"subtitle":null,"description":"The Essential Guide to Protecting Your Business Information Written by Oracle ACE Director and MySQL expert Ronald Bradford, Effective MySQL: Backup and Recovery covers all the options with detailed descriptions and syntax examples to ensure an appropriate backup and recovery plan can be developed. Featuring a side-by-side evaluation of the various backup strategies and complementary recovery implementations, this Oracle Press book helps you to protect your MySQL data from a wide range of disaster situations. Learn how different backup strategies affect locking and system availability Identify the importance of static backup options and point-in-time requirements Recognize the important business factors to determine your optimal data protection requirements Understand the benefits of using MySQL replication for leveraging different backup strategies Understand the benefits and risks of implementing solutions with MySQL in the cloud Identify key configuration variables that affect data durability and performance Find out about the types of possible disasters and develop a robust plan to address them Optimize your backup approach with compression, streaming, incremental, and parallel options","language":"en","currency":"USD","id":"0071788581","title":"Effective MySQL Backup and Recovery","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=ekfkEfjS_vcC&source=gbs_api","authors":["Ronald Bradford"]},{"pageCount":640,"thumbnail":"http:\/\/books.google.com\/books\/content?id=LauMDwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":37.67,"subtitle":"with Big Data and Artificial Intelligence Case Studies","description":"The professional programmer\u2019s Deitel® guide to Python® with introductory artificial intelligence case studies Written for programmers with a background in another high-level language, Python for Programmers uses hands-on instruction to teach today\u2019s most compelling, leading-edge computing technologies and programming in Python\u2013one of the world\u2019s most popular and fastest-growing languages. Please read the Table of Contents diagram inside the front cover and the Preface for more details. In the context of 500+, real-world examples ranging from individual snippets to 40 large scripts and full implementation case studies, you\u2019ll use the interactive IPython interpreter with code in Jupyter Notebooks to quickly master the latest Python coding idioms. After covering Python Chapters 1-5 and a few key parts of Chapters 6-7, you\u2019ll be able to handle significant portions of the hands-on introductory AI case studies in Chapters 11-16, which are loaded with cool, powerful, contemporary examples. These include natural language processing, data mining Twitter® for sentiment analysis, cognitive computing with IBM® Watson™, supervised machine learning with classification and regression, unsupervised machine learning with clustering, computer vision through deep learning and convolutional neural networks, deep learning with recurrent neural networks, big data with Hadoop®, Spark™ and NoSQL databases, the Internet of Things and more. You\u2019ll also work directly or indirectly with cloud-based services, including Twitter, Google Translate™, IBM Watson, Microsoft® Azure®, OpenMapQuest, PubNub and more. Features 500+ hands-on, real-world, live-code examples from snippets to case studies IPython + code in Jupyter® Notebooks Library-focused: Uses Python Standard Library and data science libraries to accomplish significant tasks with minimal code Rich Python coverage: Control statements, functions, strings, files, JSON serialization, CSV, exceptions Procedural, functional-style and object-oriented programming Collections: Lists, tuples, dictionaries, sets, NumPy arrays, pandas Series & DataFrames Static, dynamic and interactive visualizations Data experiences with real-world datasets and data sources Intro to Data Science sections: AI, basic stats, simulation, animation, random variables, data wrangling, regression AI, big data and cloud data science case studies: NLP, data mining Twitter®, IBM® Watson™, machine learning, deep learning, computer vision, Hadoop®, Spark™, NoSQL, IoT Open-source libraries: NumPy, pandas, Matplotlib, Seaborn, Folium, SciPy, NLTK, TextBlob, spaCy, Textatistic, Tweepy, scikit-learn®, Keras and more Accompanying code examples are available here: http:\/\/ptgmedia.pearsoncmg.com\/imprint_downloads\/informit\/bookreg\/9780135224335\/9780135224335_examples.zip. Register your product for convenient access to downloads, updates, and\/or corrections as they become available. See inside book for more information.","language":"en","currency":"USD","id":"0135231345","title":"Python for Programmers","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=LauMDwAAQBAJ&source=gbs_api","authors":["Paul J. Deitel","Harvey Deitel"]},{"pageCount":140,"thumbnail":"http:\/\/books.google.com\/books\/content?id=f1v2Vpuh8ZQC&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":11.99,"subtitle":null,"description":"A step-by-step tutorial-based approach.This book is of great help for agile teams who are already using or planning to use the GreenHopper tooling system to execute agile projects. It suits all roles in an agile project including system administrators, stakeholders, product owners, scrum masters, and team members. Fundamental knowledge of JIRA is essential.","language":"en","currency":"USD","id":"1849699747","title":"Agile Project Management with GreenHopper 6 Blueprints","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=f1v2Vpuh8ZQC&source=gbs_api","authors":["Jaibeer Malik"]},{"pageCount":298,"thumbnail":"http:\/\/books.google.com\/books\/content?id=TQqSwRScVhoC&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":31.81,"subtitle":"A Guide for Developers and Administrators","description":"If you\u2019ve been asked to maintain large and complex Hadoop clusters, this book is a must. Demand for operations-specific material has skyrocketed now that Hadoop is becoming the de facto standard for truly large-scale data processing in the data center. Eric Sammer, Principal Solution Architect at Cloudera, shows you the particulars of running Hadoop in production, from planning, installing, and configuring the system to providing ongoing maintenance. Rather than run through all possible scenarios, this pragmatic operations guide calls out what works, as demonstrated in critical deployments. Get a high-level overview of HDFS and MapReduce: why they exist and how they work Plan a Hadoop deployment, from hardware and OS selection to network requirements Learn setup and configuration details with a list of critical properties Manage resources by sharing a cluster across multiple groups Get a runbook of the most common cluster maintenance tasks Monitor Hadoop clusters\u2014and learn troubleshooting with the help of real-world war stories Use basic tools and techniques to handle backup and catastrophic failure","language":"en","currency":"USD","id":"144932729X","title":"Hadoop Operations","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=TQqSwRScVhoC&source=gbs_api","authors":["Eric Sammer"]},{"pageCount":165,"thumbnail":"http:\/\/books.google.com\/books\/content?id=GxFYuVZHG60C&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":36,"subtitle":null,"description":"Our world is being revolutionized by data-driven methods: access to large amounts of data has generated new insights and opened exciting new opportunities in commerce, science, and computing applications. Processing the enormous quantities of data necessary for these advances requires large clusters, making distributed computing paradigms more crucial than ever. MapReduce is a programming model for expressing distributed computations on massive datasets and an execution framework for large-scale data processing on clusters of commodity servers. The programming model provides an easy-to-understand abstraction for designing scalable algorithms, while the execution framework transparently handles many system-level details, ranging from scheduling to synchronization to fault tolerance. This book focuses on MapReduce algorithm design, with an emphasis on text processing algorithms common in natural language processing, information retrieval, and machine learning. We introduce the notion of MapReduce design patterns, which represent general reusable solutions to commonly occurring problems across a variety of problem domains. This book not only intends to help the reader \"think in MapReduce\", but also discusses limitations of the programming model as well. This volume is a printed version of a work that appears in the Synthesis Digital Library of Engineering and Computer Science. Synthesis Lectures provide concise, original presentations of important research and development topics, published quickly, in digital and print formats. For more information visit www.morganclaypool.com","language":"en","currency":"USD","id":"1608453421","title":"Data-intensive Text Processing with MapReduce","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=GxFYuVZHG60C&source=gbs_api","authors":["Jimmy Lin","Chris Dyer"]},{"pageCount":176,"thumbnail":"http:\/\/books.google.com\/books\/content?id=C7j3DwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":15,"subtitle":"An Innocent's Guide to the Tech Inside","description":"What is \u201Cthe cloud\u201D? Is it here or there? Should it be allowed? Should I even care? Have you ever imagined the internet as a giant Rube Goldberg machine? Or the fast-evolving cloud computing space as a literal jungle filled with prehistoric beasts? Does a data breach look like a neo-noir nightmare full of turned-up coat collars and rain-soaked alleys? Wouldn\u2019t all these vital concepts be easier to understand if they looked as interesting as they are? And wouldn\u2019t they be more memorable if we could explain them in rhyme? Whether you\u2019re a kid or an adult, the answer is: YES! The medicine in this spoonful of sugar is a sneaky-informative tour through the past, present and future of cloud computing, from mainframes to serverless and from the Internet of Things to artificial intelligence. Forrest is a professional explainer whose highly-rated conference talks and viral cartoon graphics have been teaching engineers to cloud for years. He knows that a picture is worth a thousand words. But he has plenty of words, too. Your hotel key, your boarding pass, The card you swipe to pay for gas, The smart TV atop the bar, The entertainment in your car, Your doorbell, toothbrush, thermostat, The vacuum that attacked your cat, They all connect the cloud and you. Maybe they shouldn't, but they do. As a graduation gift (call it \u201COh the Places You\u2019ll Go\u201D for engineering students), a cubicle conversation starter, or just a delightfully nerdy bedtime story for your kids, \u201CThe Read-Aloud Cloud\u201D will be the definitive introduction to the technologies that everyone uses and nobody understands. You can even read it silently if you want. But good luck with that.","language":"en","currency":"USD","id":"1119677645","title":"The Read Aloud Cloud","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=C7j3DwAAQBAJ&source=gbs_api","authors":["Forrest Brazeal"]},{"pageCount":848,"thumbnail":"http:\/\/books.google.com\/books\/content?id=oKiLDQAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":31.19,"subtitle":"Managing Spark, YARN, and MapReduce","description":"This is the eBook of the printed book and may not include any media, website access codes, or print supplements that may come packaged with the bound book. The Comprehensive, Up-to-Date Apache Hadoop Administration Handbook and Reference \u201CSam Alapati has worked with production Hadoop clusters for six years. His unique depth of experience has enabled him to write the go-to resource for all administrators looking to spec, size, expand, and secure production Hadoop clusters of any size.\u201D \u2014Paul Dix, Series Editor In Expert Hadoop® Administration, leading Hadoop administrator Sam R. Alapati brings together authoritative knowledge for creating, configuring, securing, managing, and optimizing production Hadoop clusters in any environment. Drawing on his experience with large-scale Hadoop administration, Alapati integrates action-oriented advice with carefully researched explanations of both problems and solutions. He covers an unmatched range of topics and offers an unparalleled collection of realistic examples. Alapati demystifies complex Hadoop environments, helping you understand exactly what happens behind the scenes when you administer your cluster. You\u2019ll gain unprecedented insight as you walk through building clusters from scratch and configuring high availability, performance, security, encryption, and other key attributes. The high-value administration skills you learn here will be indispensable no matter what Hadoop distribution you use or what Hadoop applications you run. Understand Hadoop\u2019s architecture from an administrator\u2019s standpoint Create simple and fully distributed clusters Run MapReduce and Spark applications in a Hadoop cluster Manage and protect Hadoop data and high availability Work with HDFS commands, file permissions, and storage management Move data, and use YARN to allocate resources and schedule jobs Manage job workflows with Oozie and Hue Secure, monitor, log, and optimize Hadoop Benchmark and troubleshoot Hadoop","language":"en","currency":"USD","id":"0134703383","title":"Expert Hadoop 2 Administration","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=oKiLDQAAQBAJ&source=gbs_api","authors":["Sam R. Alapati"]},{"pageCount":120,"thumbnail":"http:\/\/books.google.com\/books\/content?id=GTnoAgAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":12.64,"subtitle":null,"description":"This book is an example-based tutorial that deals with Optimizing Hadoop for MapReduce job performance. If you are a Hadoop administrator, developer, MapReduce user, or beginner, this book is the best choice available if you wish to optimize your clusters and applications. Having prior knowledge of creating MapReduce applications is not necessary, but will help you better understand the concepts and snippets of MapReduce class template code.","language":"en","currency":"USD","id":"1783285664","title":"Optimizing Hadoop for MapReduce","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=GTnoAgAAQBAJ&source=gbs_api","authors":["Khaled Tannir"]},{"pageCount":456,"thumbnail":"http:\/\/books.google.com\/books\/content?id=fB6s_Z6g0gIC&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":41.07,"subtitle":"WORK EFFECT LEG CODE _p1","description":"Get more out of your legacy systems: more performance, functionality, reliability, and manageability Is your code easy to change? Can you get nearly instantaneous feedback when you do change it? Do you understand it? If the answer to any of these questions is no, you have legacy code, and it is draining time and money away from your development efforts. In this book, Michael Feathers offers start-to-finish strategies for working more effectively with large, untested legacy code bases. This book draws on material Michael created for his renowned Object Mentor seminars: techniques Michael has used in mentoring to help hundreds of developers, technical managers, and testers bring their legacy systems under control. The topics covered include Understanding the mechanics of software change: adding features, fixing bugs, improving design, optimizing performance Getting legacy code into a test harness Writing tests that protect you against introducing new problems Techniques that can be used with any language or platform\u2014with examples in Java, C++, C, and C# Accurately identifying where code changes need to be made Coping with legacy systems that aren't object-oriented Handling applications that don't seem to have any structure This book also includes a catalog of twenty-four dependency-breaking techniques that help you work with program elements in isolation and make safer changes.","language":"en","currency":"USD","id":"0132931753","title":"Working Effectively with Legacy Code","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=fB6s_Z6g0gIC&source=gbs_api","authors":["Michael Feathers"]},{"pageCount":246,"thumbnail":"http:\/\/books.google.com\/books\/content?id=OWQdAgAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":16.19,"subtitle":"Distributed Process Coordination","description":"Building distributed applications is difficult enough without having to coordinate the actions that make them work. This practical guide shows how Apache ZooKeeper helps you manage distributed systems, so you can focus mainly on application logic. Even with ZooKeeper, implementing coordination tasks is not trivial, but this book provides good practices to give you a head start, and points out caveats that developers and administrators alike need to watch for along the way. In three separate sections, ZooKeeper contributors Flavio Junqueira and Benjamin Reed introduce the principles of distributed systems, provide ZooKeeper programming techniques, and include the information you need to administer this service. Learn how ZooKeeper solves common coordination tasks Explore the ZooKeeper API\u2019s Java and C implementations and how they differ Use methods to track and react to ZooKeeper state changes Handle failures of the network, application processes, and ZooKeeper itself Learn about ZooKeeper\u2019s trickier aspects dealing with concurrency, ordering, and configuration Use the Curator high-level interface for connection management Become familiar with ZooKeeper internals and administration tools","language":"en","currency":"USD","id":"1449361269","title":"ZooKeeper","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=OWQdAgAAQBAJ&source=gbs_api","authors":["Flavio Junqueira","Benjamin Reed"]},{"pageCount":368,"thumbnail":"http:\/\/books.google.com\/books\/content?id=sAh5DQAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":18.35,"subtitle":"Dataflow Scripting with Hadoop","description":"For many organizations, Hadoop is the first step for dealing with massive amounts of data. The next step? Processing and analyzing datasets with the Apache Pig scripting platform. With Pig, you can batch-process data without having to create a full-fledged application, making it easy to experiment with new datasets. Updated with use cases and programming examples, this second edition is the ideal learning tool for new and experienced users alike. You\u2019ll find comprehensive coverage on key features such as the Pig Latin scripting language and the Grunt shell. When you need to analyze terabytes of data, this book shows you how to do it efficiently with Pig. Delve into Pig\u2019s data model, including scalar and complex data types Write Pig Latin scripts to sort, group, join, project, and filter your data Use Grunt to work with the Hadoop Distributed File System (HDFS) Build complex data processing pipelines with Pig\u2019s macros and modularity features Embed Pig Latin in Python for iterative processing and other advanced tasks Use Pig with Apache Tez to build high-performance batch and interactive data processing applications Create your own load and store functions to handle data formats and storage mechanisms","language":"en","currency":"USD","id":"1491937041","title":"Programming Pig","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=sAh5DQAAQBAJ&source=gbs_api","authors":["Alan Gates","Daniel Dai"]},{"pageCount":324,"thumbnail":"http:\/\/books.google.com\/books\/content?id=GpoKZncgCxsC&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api","price":16.54,"subtitle":null,"description":"Over 150 recipes to design and optimize large scale Apache Cassandra deployments.","language":"en","currency":"USD","id":"1849515131","title":"Cassandra High Performance Cookbook","infoLink":"https:\/\/play.google.com\/store\/books\/details?id=GpoKZncgCxsC&source=gbs_api","authors":["Edward Capriolo"]}]